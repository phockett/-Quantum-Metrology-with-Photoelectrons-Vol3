%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,table,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Frontmatter}}

\usepackage{sphinxmessages}


\nonstopmode   % 23/03/23 added to skip current Qutip build issues, but should be careful with this, and fix properly! See https://tex.stackexchange.com/questions/140845/how-can-i-ignore-latex-error-while-compiling
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
% make phantomsection empty inside figures, see https://sphinxcontrib-bibtex.readthedocs.io/en/latest/usage.html#latex-backend-fails-with-citations-in-figure-captions
\usepackage{etoolbox}
% \AtBeginEnvironment{figure}{\renewcommand{\phantomsection}{}}  % Doesn't fix - old version?
\AtBeginEnvironment{figure}{\pretocmd{\hyperlink}{\protect}{}{}}  % WORKING From https://github.com/mcmtroffaes/sphinxcontrib-bibtex/issues/276#issuecomment-1102154800, see also https://github.com/executablebooks/jupyter-book/issues/1710#issuecomment-1331323071
%
% ****** MORE MATHS RENDER TESTS, all failing.
% Trying to fix `\bar{\varUpsilon}` gives `! Internal error: bad native font flag in `map_char_to_glyph'`
% WORK AROUND, use \bar{\varUpsilon_{}} instead.
% ** Fix hat issues, from https://tex.stackexchange.com/a/70498 - FAILS
% \def\acc@hat{\mbox{\raisebox{-1.27ex}[0ex][0ex]{\^{}}}}
% \renewcommand*\hat[1]{\placeaccent{\acc@hat}{#1}}
% ** Testing more maths stuff, from https://tex.stackexchange.com/questions/578375/mathcal-incompatible-with-unicode-math
% \usepackage{unicode-math}
% \setmathfont{XITS Math}[Scale = MatchUppercase ]
% \setmathfont{Latin Modern Math}[range = {cal,bfcal},Scale = MatchUppercase ]
% ** Similar from https://tex.stackexchange.com/questions/227033/why-cant-i-use-my-font-with-unicode-math
% \usepackage{unicode-math}
% \setmathfont{Latin Modern Math}
% \usepackage{mathspec}
% \setmathfont(Latin,Digits,Greek){Latin Modern Sans}
% \setmathrm{Latin Modern Sans}
% ** Per https://github.com/wspr/unicode-math/issues/400 
% \usepackage[mathbf=sym]{unicode-math}
% ** Per https://tex.stackexchange.com/questions/159785/caveats-of-newtxmath-and-fontspec-together
% \usepackage[no-math]{fontspec}
% \usepackage[libertine]{newtxmath}


        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Quantum Metrology with Photoelectrons Vol. 3 *Analysis methodologies*}
\date{Oct 26, 2023}
\release{}
\author{Paul Hockett with Varun Makhija}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{intro::doc}}


\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{Quantum Metrology with Photoelectrons Vol. 3: \sphinxstyleemphasis{Analysis methodologies}}
\end{DUlineblock}

\sphinxAtStartPar
By Paul Hockett with Varun Makhija

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large About the books}
\end{DUlineblock}

\sphinxAtStartPar
Photoionization is an interferometric process, in which multiple paths can contribute to the final continuum photoelectron wavefunction. At the simplest level, interferences between different final angular momentum states are manifest in the energy and angle resolved photoelectron spectra: metrology schemes making use of these interferograms are thus phase\sphinxhyphen{}sensitive, and provide a powerful route to detailed understanding of photoionization. In these cases, the continuum wavefunction (and underlying scattering dynamics) can be characterised. At a more complex level, such measurements can also provide a powerful probe for other processes of interest, leading to a more general class of quantum metrology built on phase\sphinxhyphen{}sensitive photoelectron imaging.  Since the turn of the century, the increasing availability of photoelectron imaging experiments, along with the increasing sophistication of experimental techniques, and the availability of computational resources for analysis and numerics, has allowed for significant developments in such photoelectron metrology.

\noindent{\hspace*{\fill}\sphinxincludegraphics{{mock_covers_3vol_230823}.png}\hspace*{\fill}}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Volume I covers the core physics of photoionization, including a range of computational examples. The material is presented as both reference and tutorial, and should appeal to readers of all levels. ISBN 978\sphinxhyphen{}1\sphinxhyphen{}6817\sphinxhyphen{}4684\sphinxhyphen{}5, \sphinxurl{http://iopscience.iop.org/book/978-1-6817-4684-5} (IOP Press, 2018)

\item {} 
\sphinxAtStartPar
Volume II explores applications, and the development of quantum metrology schemes based on photoelectron measurements. The material is more technical, and will appeal more to the specialist reader. ISBN 978\sphinxhyphen{}1\sphinxhyphen{}6817\sphinxhyphen{}4688\sphinxhyphen{}3, \sphinxurl{http://iopscience.iop.org/book/978-1-6817-4688-3} (IOP Press, 2018)

\end{itemize}

\sphinxAtStartPar
Additional online resources for Vols. I \& II can be found on \sphinxhref{https://osf.io/q2v3g/wiki/home/}{OSF} and \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons}{Github}.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Volume III in the series continues this exploration, with a focus on numerical analysis techniques, forging a closer link between experimental and theoretical results, and making the methodologies discussed directly accessible via new software. The book is due for publication by IOP in 2023; this volume is also open\sphinxhyphen{}source, with a live HTML version at \sphinxurl{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3/} and source available at \sphinxurl{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}.

\end{itemize}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Technical details}
\end{DUlineblock}

\sphinxAtStartPar
This repository contains:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{doc\sphinxhyphen{}source}} the source documents (mainly Jupyter Notebooks in Python)

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{notes}} additional notes for the book,

\item {} 
\sphinxAtStartPar
gh\sphinxhyphen{}pages branch contains the current HTML build, available at \sphinxurl{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3/}

\end{itemize}

\sphinxAtStartPar
The project has been setup to use the \sphinxhref{https://jupyterbook.org/}{Jupyter Book} build\sphinxhyphen{}chain (which uses Sphinx on the back\sphinxhyphen{}end) to generate HTML and Latex outputs for publication from source Jupyter notebooks \& markdown files.

\sphinxAtStartPar
The work \sphinxstyleemphasis{within} the book will make use of the \sphinxhref{https://pemtk.readthedocs.io/en/latest/about.html}{Photoelectron Metrology Toolkit} platform for working with experimental \& theoretical data.

\sphinxAtStartPar
For further technical details, \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3/part1/platform\_intro\_070723.html}{see Chpt. 2 in the book}.

\sphinxAtStartPar
\sphinxincludegraphics{{ccdcf3feb912fb992ab79da89d86a2521bfe1c21}.png}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Running code examples}
\end{DUlineblock}

\sphinxAtStartPar
Each Jupyter notebook (\sphinxcode{\sphinxupquote{*.ipynb}}) can be treated as a stand\sphinxhyphen{}alone computational document. These can be run/used/modified independently with an appropriately setup python environment, for details \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3/part1/platform\_intro\_070723.html\#installation-and-environment-set-up}{see Chpt. 2 in the book}.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Docker builds}
\end{DUlineblock}

\sphinxAtStartPar
Docker images, including the full book source and all required packages, are \sphinxhref{https://hub.docker.com/r/epsproc/quantum-met-vol3}{available from Docker hub}, simply run \sphinxcode{\sphinxupquote{docker pull epsproc/quantum\sphinxhyphen{}met\sphinxhyphen{}vol3}} to pull a copy, then \sphinxcode{\sphinxupquote{docker run epsproc/quantum\sphinxhyphen{}met\sphinxhyphen{}vol3}} to run with default settings (which uses port 8888 for JupyterLab). The Jupyter Lab interface will be available at \sphinxurl{http://localhost:8888}, with default password \sphinxcode{\sphinxupquote{qm3}}. (To specify a port at run time, add \sphinxcode{\sphinxupquote{\sphinxhyphen{}p <newPort>:8888}} to the run command, e.g. \sphinxcode{\sphinxupquote{docker run \sphinxhyphen{}p 9999:8888 epsproc/quantum\sphinxhyphen{}met\sphinxhyphen{}vol3}} to set port to 9999.)

\sphinxAtStartPar
The Docker images contain the book source, along with all required packages and Jupyter Lab (based on the \sphinxhref{https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html}{Jupyter Docker Stacks Scipy image}). Book source files are available in the container at \sphinxcode{\sphinxupquote{github/Quantum\sphinxhyphen{}Metrology\sphinxhyphen{}with\sphinxhyphen{}Photoelectrons\sphinxhyphen{}Vol3/}}. For more details on the Jupyter Lab base container, see the \sphinxhref{https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html}{Jupyter Docker Stacks website}.

\sphinxAtStartPar
For the source Dockerfiles and additional notes, \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3/tree/main/docker}{see \sphinxcode{\sphinxupquote{/docker}} in the QM3 github repository}.

\sphinxAtStartPar
Archived versions can also be found on Zenodo, \sphinxhref{https://doi.org/10.5281/zenodo.8286020}{DOI: 10.5281/zenodo.8286020}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Building the book}
\end{DUlineblock}

\sphinxAtStartPar
The full book can also be built from source in a suitably configured environment (\sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3/part1/platform\_intro\_070723.html\#installation-and-environment-set-up}{see Chpt. 2 in the book}):
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Clone this repository

\item {} 
\sphinxAtStartPar
Run \sphinxcode{\sphinxupquote{pip install \sphinxhyphen{}r requirements.txt}} (it is recommended you do this within a virtual environment)

\item {} 
\sphinxAtStartPar
(Optional) Edit the books source files located in the \sphinxcode{\sphinxupquote{doc\sphinxhyphen{}source/}} directory

\item {} 
\sphinxAtStartPar
Run \sphinxcode{\sphinxupquote{jupyter\sphinxhyphen{}book clean doc\sphinxhyphen{}source/}} to remove any existing builds

\item {} 
\sphinxAtStartPar
Run \sphinxcode{\sphinxupquote{jupyter\sphinxhyphen{}book build doc\sphinxhyphen{}source/}}

\end{enumerate}

\sphinxAtStartPar
A fully\sphinxhyphen{}rendered HTML version of the book will be built in \sphinxcode{\sphinxupquote{doc\sphinxhyphen{}source/\_build/html/}}.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Credits}
\end{DUlineblock}

\sphinxAtStartPar
This project is created using the open source \sphinxhref{https://jupyterbook.org/}{Jupyter Book project} and the \sphinxhref{https://github.com/executablebooks/cookiecutter-jupyter-book}{executablebooks/cookiecutter\sphinxhyphen{}jupyter\sphinxhyphen{}book template}.

\sphinxAtStartPar
To add: build env \& main software packages (see automation for this…)

\sphinxstepscope


\part{Frontmatter}

\sphinxstepscope


\chapter{About the authors}
\label{\detokenize{frontmatter/about_the_authors:about-the-authors}}\label{\detokenize{frontmatter/about_the_authors::doc}}
\sphinxAtStartPar
Paul Hockett and Varun Makhija’s interests span a gamut of topics in atomic, molecular and optical (AMO) and quantum physics, at the intersection of spectroscopy, photoionization, (ultrafast) optics, molecular control and dynamics, and metrology. Paul’s recent work has focussed on photoelectron metrology, with the main aims of matrix element retrieval, as outlined in this series (\sphinxstyleemphasis{Quantum metrology with photoelectron}) of books. Varun’s work has focussed primarily on rotational wavepacket methodologies and reconstruction, and application of these techniques to molecular systems, including full excited state density matrix reconstruction and applications in photoelectron metrology.

\sphinxAtStartPar
Paul is a research scientist at the National Research Council of Canada, Ottawa, Canada, 

https://orcid.org/0000\sphinxhyphen{}0001\sphinxhyphen{}9561\sphinxhyphen{}8433


\sphinxAtStartPar
Varun is a faculty member at the University of Mary Washington, Virginia, USA, 

https://orcid.org/0000\sphinxhyphen{}0002\sphinxhyphen{}4975\sphinxhyphen{}4888


\sphinxstepscope


\chapter{Abstract}
\label{\detokenize{frontmatter/abstract:abstract}}\label{\detokenize{frontmatter/abstract::doc}}
\sphinxAtStartPar
The overall aim of Quantum Metrology with Photoelectrons Vol. 3 is to expand, explore, and illustrate, new computational developments in quantum metrology with photoelectrons: specifically, the application of new python\sphinxhyphen{}based tools to tackle problems in photoionization matrix element retrieval. Part I details the topic, theory and computational methods; Part II provides further numerical details and case\sphinxhyphen{}studies.

\sphinxAtStartPar
The book itself is fully open\sphinxhyphen{}source, and written as a set of Jupyter Notebooks. All the material herein is available directly to readers via a Github repository \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}. Any example script, page, chapter \sphinxhyphen{} up to and including the full book \sphinxhyphen{} can be executed and modified by readers to further explore the topic interactively, and provide a foundation which can be adapted to apply the methodology to new problems. Further details can be found in \hyperref[\detokenize{part1/main_intro_060723:sec-intro-context}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-intro-context}}}.

\sphinxstepscope


\chapter{A note on book versions, formats and conventions}
\label{\detokenize{frontmatter/book_versions_note:a-note-on-book-versions-formats-and-conventions}}\label{\detokenize{frontmatter/book_versions_note:chpt-book-versions}}\label{\detokenize{frontmatter/book_versions_note::doc}}

\section{Versions}
\label{\detokenize{frontmatter/book_versions_note:versions}}
\sphinxAtStartPar
This book exists in multiple formats, which are not all equal:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Jupyter notebooks. The original form, interactive computational notebooks includes text, executable code and full outputs. Source notebooks are available via \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}.

\item {} 
\sphinxAtStartPar
HTML pages. Compiled from the notebooks, include interactive figures and most computational outputs. The HTML version is available at \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)}.

\item {} 
\sphinxAtStartPar
PDF and hard\sphinxhyphen{}copy. Standard static outputs, compiled from the notebooks. In this form some computational outputs are truncated or omitted for brevity and readability. Since some formats may not support hyperlinks, URLs to external references are also usually included in the bibliography \sphinxhyphen{} note that these may not always be the \sphinxstyleemphasis{full} URLs linked in the main text, and may only list the main index page of a given site in some cases. Some figures may also be omitted.

\end{enumerate}


\section{Conventions}
\label{\detokenize{frontmatter/book_versions_note:conventions}}
\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
In many cases where there is significant truncation of the presentation in the PDF, a note like this may be included.

\sphinxAtStartPar
E.g. \sphinxstyleemphasis{Full tabulations of the parameters available in HTML or notebook formats only.}
\end{sphinxadmonition}
\end{sphinxShadowBox}

\sphinxAtStartPar
Code (Python) appears in formatted cells, with comments, and outputs below the cell:

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Example comment in code}
\PYG{n}{value} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{o}{*}\PYG{l+m+mi}{3}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{This is a code cell, value=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{value}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
This is a code cell, value=9
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
In HTML and PDF formats some code cells that appear in the source notebooks may be hidden or removed, or have outputs hidden or removed. This is usually for brevity \sphinxhyphen{} e.g. to remove additional code\sphinxhyphen{}only examples that are only useful when working directly on the code, or repeated code \sphinxhyphen{} or to hide additional formatting commands required only for Jupyter Book builds. All code cells are annotated to indicate their contents.

\sphinxAtStartPar
Code\sphinxhyphen{}related terms in the text, e.g. the names of functions, packages etc., usually appear as in\sphinxhyphen{}line blocks, e.g. \sphinxcode{\sphinxupquote{Numpy}}, and may additionally be linked to relevant web resources, e.g. \sphinxhref{https://numpy.org/}{\sphinxcode{\sphinxupquote{Numpy}}}.

\sphinxAtStartPar
For more details on the aims, tools and build\sphinxhyphen{}chain, see \hyperref[\detokenize{part1/main_intro_060723:sec-intro-technical-notes}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-intro-technical-notes}}}.


\section{Formatting}
\label{\detokenize{frontmatter/book_versions_note:formatting}}
\sphinxAtStartPar
In some cases additional formatting is required for defining Jupter Notebook to HTML and PDF outputs (via the Jupyter Book build\sphinxhyphen{}chain, see \hyperref[\detokenize{part1/main_intro_060723:sec-intro-technical-notes}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-intro-technical-notes}}}), in particular \sphinxhref{https://jupyterbook.org/en/stable/content/executable/output-insert.html}{the \sphinxcode{\sphinxupquote{glue}} command} is used for formatting figure outputs with captions. In general use these are not required, but will transparently display figures when executed in the Jupyter Lab environment. Note that glued tables from \sphinxcode{\sphinxupquote{Pandas}} DataFrames are not nicely rendered in the HTML format, but interactive HTML output is usually include too, although this may be hidden in the cell above the glued table.


\section{Numerics}
\label{\detokenize{frontmatter/book_versions_note:numerics}}\label{\detokenize{frontmatter/book_versions_note:sec-numerics-disclaimer}}
\sphinxAtStartPar
At the time of writing the main code\sphinxhyphen{}bases used in this work (see \hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:chpt-platformintro}}} are still in active development, bugs, inconsistencies and errors cannot, therefore, be ruled out in the numerical examples. However, the case for 1D alignment and reconstruction has been well\sphinxhyphen{}tested in the past (e.g. Refs. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}, \hyperlink{cite.backmatter/bibliography:id685}{2}, \hyperlink{cite.backmatter/bibliography:id686}{3}{]}), so is expected to be accurate; cases with 3D alignment are presented in a provisional context, with caveats as above, although the general methodology as demonstrated is robust.

\sphinxstepscope


\part{Part I \sphinxhyphen{} Theory \& software}

\sphinxstepscope


\chapter{Introduction}
\label{\detokenize{part1/main_intro_060723:introduction}}\label{\detokenize{part1/main_intro_060723:chpt-intro}}\label{\detokenize{part1/main_intro_060723::doc}}
\sphinxAtStartPar
The overall aim of \sphinxstyleemphasis{Quantum Metrology with Photoelectrons Vol. 3} is to expand, explore, and illustrate, new computational developments in quantum metrology with photoelectrons: specifically, the application of new python\sphinxhyphen{}based tools to tackle problems in matrix element retrieval. The book itself is written as a set of Jupyter Notebooks, hence all the material herein is available directly to readers, and can be run locally to further explore the topic interactively, and provide a foundation which can be adapted to apply the methodology to new problems.

\sphinxAtStartPar
Whilst this volume aims to provide a self\sphinxhyphen{}contained text, and focuses on computational examples which may be used without extensive background knowledge, a brief contextual introduction is presented here (\hyperref[\detokenize{part1/main_intro_060723:sec-topical-intro}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-topical-intro}}} below), and the  necessary core physics,as well as some recent extensions, is also presented herein (\hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chapter \ref{\detokenize{part1/theory_100723:chpt-theory}}}). The unfamiliar reader is referred to \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]} for a more detailed introduction to the physics, and as a more general gateway to the literature. Following the topical introduction, the remainder of Part I introduces the main computational and software tools (\hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{Chapter \ref{\detokenize{part1/platform_intro_070723:chpt-platformintro}}}), recent theory developments (\hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chapter \ref{\detokenize{part1/theory_100723:chpt-theory}}}), and concludes with a general overview for approaching matrix element retrieval numerically (\hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chapter \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}).

\sphinxAtStartPar
Part II details the application of these tools to a few specific cases, including a general guide to setting up and running the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} fitting routines (see \hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{Chapter \ref{\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}}} for an outline), then proceeding with a (relatively) simple homonuclear diatomic example (\hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{Chapter \ref{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}}), and escalating in complexity to a the most general polyatomic asymmetric top case.


\section{Topical introduction: from quantum metrology to a generalised bootstrapping protocol}
\label{\detokenize{part1/main_intro_060723:topical-introduction-from-quantum-metrology-to-a-generalised-bootstrapping-protocol}}\label{\detokenize{part1/main_intro_060723:sec-topical-intro}}
\sphinxAtStartPar
There are two core topics at the heart of this work, specifically photoelectron spectroscopy (and associated experimental, theoretical and analysis methodologies) and quantum metrology in general. To briefly (re)introduce these topics, and contextually frame the work discussed herein, some brief comments from \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]} are reproduced below; the reader is referred to the introductory chapters of \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]} for a lengthier treatment, and \sphinxhref{https://vimeo.com/223603377}{an introductory video to \sphinxstyleemphasis{Phase\sphinxhyphen{}sensitive Photoelectron Metrology} can be found online} (see also Refs. {[}\hyperlink{cite.backmatter/bibliography:id674}{6}, \hyperlink{cite.backmatter/bibliography:id676}{7}, \hyperlink{cite.backmatter/bibliography:id670}{8}{]} for further introductory presentation videos, materials and resources around the topic).


\subsection{Quantum metrology with photoelectrons}
\label{\detokenize{part1/main_intro_060723:quantum-metrology-with-photoelectrons}}
\sphinxAtStartPar
To set the general context, consider quantum metrology in general…
\begin{quote}

\sphinxAtStartPar
Quantum metrology can be loosely defined as any class of experiment which provides detailed information on quantum mechanical properties (phases, coherences, entanglement etc.) of a system. To stay with the spirit of modern metrology, this definition can further be refined to measurements which provide high\sphinxhyphen{}resolution quantum information; a clear contemporary example is therefore experimental methodologies which provide full quantum state reconstruction (e.g. quantum tomography), and/or make use of quantum mechanical properties as a tool for measurement (e.g. atom interferometry). Traditional high\sphinxhyphen{}resolution spectroscopies may also fit within this definition in some cases, although in the majority of cases high\sphinxhyphen{}resolution spectroscopic measurements provide transition line\sphinxhyphen{}strengths and energies, but lack sufficient information for a full determination or reconstruction of the underlying quantum state.

\sphinxAtStartPar
{[}…{]}

\sphinxAtStartPar
…at what point does a measurement of a quantum mechanical system become quantum metrology? A pragmatic view on this is that the complete quantum state of the system must be capable of \sphinxstyleemphasis{unique definition from the experimental measurement(s)}. This is pragmatic in the sense that it leaves the door open for both \sphinxstyleemphasis{inferred} and \sphinxstyleemphasis{direct} reconstruction techniques. In the former case, the experimental data informs the theory and analysis, but is not directly ‘analysed’ or ‘inverted’ to provide or reconstruct the full quantum information; in the latter case one obtains the desired quantum mechanical information from the measurement in a more ‘direct’ fashion (which may, admittedly, still remain as a rather convoluted process, depending on the level of theoretical input required). Traditional spectroscopies again provide a touchstone here \sphinxhyphen{} high\sphinxhyphen{}resolution spectroscopy measurements can be compared with models or ab initio computations to provide quantum mechanical details of a system, but typically do not directly provide this information from a set of measurements alone. In this sense they fit a pragmatic definition of quantum metrology, but not a more specific definition of quantum metrology as a (somewhat) direct empirical technique.

\sphinxAtStartPar
{[}…{]}

\sphinxAtStartPar
In summary, while quantum metrology can come in many flavours, at heart it might be considered as any set of measurements (and associated analysis methodologies) which provide detailed (quantitative) quantum mechanical information on a given system of interest \sphinxhyphen{} ideally with little or no restriction on the complexity of the system \sphinxhyphen{} and it is discussed in this spirit herein.

\begin{flushright}
---\sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}, Chpt. 1
\end{flushright}
\end{quote}

\sphinxAtStartPar
And, for the specific case of photoionization…
\begin{quote}

\sphinxAtStartPar
… both \sphinxstyleemphasis{ab initio} methods and \sphinxstyleemphasis{high\sphinxhyphen{}dimensionality measurements} (combined with detailed \sphinxstyleemphasis{analysis methodologies}) can nonetheless provide detailed information on the photoionization dynamics. Although the simple analogy with Young’s double\sphinxhyphen{}slit {[}i.e. basic two\sphinxhyphen{}path interferometry{]} fails, the resulting photoelectron flux, measured spatially, remains, in essence, a self\sphinxhyphen{}referencing angular interferogram of the continuum wavefunction. In a more abstract sense, the basic interferometer paradigm can be extended to the general ‘photoionization interferometer’, one just has to keep in mind that there are now potentially many, many channels. In the most basic sense, the energy and angle resolved interferograms \sphinxhyphen{} the photoelectron flux as a function of energy and angle \(I(E,\theta,\phi)\) \sphinxhyphen{} which may be measured, are nothing more than an interferometric measurement sensitive to the relative phases of the different angular momentum components.

\sphinxAtStartPar
{[}…{]}

\sphinxAtStartPar
In the photoionization community, the angular interferograms (which will usually be considered at a single energy \(E\)) are photoelectron angular distributions ({\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}), and have long been used as a means to learn about the process of photoionization. In this context, {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} measured for a range of experimental parameters can provide a dataset with sufficient information content to determine the magnitudes and phases of the photoelectron wavefunction, hence the photoionization dynamics may be reconstructed from the measurements in favourable cases. This class of measurement is traditionally termed a \sphinxstyleemphasis{complete photoionization experiment}, although the exact nature of the completeness may vary. The phase\sphinxhyphen{}sensitivity of photoelectron interferograms have also been used in complementary fashions in other contexts, including as a means to probe the phase\sphinxhyphen{}shift induced by a specific prepared pathway, and control in multipath schemes, and in many other regimes.

\sphinxAtStartPar
{[}…{]}

\sphinxAtStartPar
… the combination of a phase\sphinxhyphen{}sensitive quantum mechanical observable \sphinxhyphen{} photoelectron interferograms \sphinxhyphen{} with modern experimental and computational techniques provides the tools required for a full quantum metrology based on this class of measurement. Following the above discussion and definitions, a full metrology technique is one which allows both the \sphinxstyleemphasis{intrinsic} and \sphinxstyleemphasis{extrinsic/dynamic} quantum mechanical properties of the system under study to be obtained/reconstructed from a measurement, or set of measurements. In the simplest case, one might seek to understand just the intrinsic photoionization dynamics of a scattering system (e.g. the magnitudes and phases of the various pathways {[}…{]}), while in more complex cases the intrinsic properties are part of a probe process for additional properties or dynamics of the system {[}…{]}. In all cases, the key is measurement (and possibly control) with a high information\sphinxhyphen{}content technique, and a detailed understanding of the processes involved.

\begin{flushright}
---\sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}, Chpt. 1
\end{flushright}
\end{quote}

\sphinxAtStartPar
In summary, the focus of the work presented herein is the quantitative analysis of phase\sphinxhyphen{}sensitive observables from photoionization, specifically photoelectron angular distributions ({\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}) as a function of energy, angle and time, which will be denoted \(I(\epsilon,t,\theta,\phi)\) in general herein. These \sphinxstyleemphasis{photoelectron interferograms} are introducted in more detail (including examples) in \hyperref[\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{concepts_fig_draft_010417_withAxes}.png}
\caption{Conceptual outline for the generalised {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} for {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, including retrieval of {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} properties, via a set of time\sphinxhyphen{}resolved measurements and suitable post\sphinxhyphen{}processing scheme. In the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}, a set of laser pulses creates and probes an aligned distribution of molecules, and photoelectron images are measured (as a function of time, hence molecular alignment). The experimental data is analyzed through a multi\sphinxhyphen{}step “bootstrap” protocol to obtain matrix elements, which constitute a complete description of the photoionization event. These can further be used to obtain {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} observables, for any polarization geometry. Note the coordinates show will be used throughout the book, with the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} z\sphinxhyphen{}axis defined relative to the laser field (E) polarization, and the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} defined with the molecular axis aligned along the z\sphinxhyphen{}axis (and polarization geometries for the laser field (E) referenced to this axis) \sphinxhyphen{} see also \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}}} for a more detailed frame definition.}\label{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}\end{figure}


\subsection{Generalised geometric metrology protocols}
\label{\detokenize{part1/main_intro_060723:generalised-geometric-metrology-protocols}}\label{\detokenize{part1/main_intro_060723:sec-main-intro-bootstrapping}}
\sphinxAtStartPar
In order to develop a quantitative form of photoelectron spectroscopy, hence analyse photoelectron interferograms in the context of quantum metrology in general, a number of techniques have previously been investigated (see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]}). In general, any applicable technique involves the manipulation or control of parameters which affect the observables in analytically\sphinxhyphen{}defined (or otherwise well\sphinxhyphen{}characterised) ways; measurements over a set of suitable experimental or control parameters then provide the high information\sphinxhyphen{}content dataset required for a full characterisation of the system at hand. Typically, “geometric” (angular\sphinxhyphen{}momentum) properties of the system provide a suitable set of control parameters, and a number of experimental methodologies with different flavours of these parameters have been demonstrated (see \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}). The main, outstanding, issue with previous techniques was the system\sphinxhyphen{}specific nature of many of the applications: ideally, one would like to make use of a generalised protocol, which is independent of the particulars of the system under study, hence does not require, for example, specific spectroscopic properties to be known and/or be experimentally accessible.

\sphinxAtStartPar
The main aim of the work in the current volume is the further development, deployment and demonstrations of, such a scheme. The focus is on one specific \sphinxstyleemphasis{high information\sphinxhyphen{}content} technique: the \sphinxstyleemphasis{generalised} {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}, which makes use of experiments using rotational wavepackets ({\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}}) as a (geometric) control dimension, and time\sphinxhyphen{}resolved photoelectron measurements as a high\sphinxhyphen{}dimensionality, phase\sphinxhyphen{}sensitive observable; the combination of these measurements with a quantitative analysis methodology provides a (relatively) general route to a full quantum metrology with photoelectrons (a.k.a. complete photoionization experiments, a.k.a. quantum state reconstruction/quantum tomography). A brief introduction to the technique is given below, with theoretical and numerical techniques and demonstrations forming the remainder of this book; interested readers can find a longer topical introduction in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} (in particular Chpt. 11), and see also Ref. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]} for an experimental demonstration, and Refs. {[}\hyperlink{cite.backmatter/bibliography:id685}{2}, \hyperlink{cite.backmatter/bibliography:id686}{3}{]} for a recent review in the context of molecular frame reconstruction.

\sphinxAtStartPar
As defined in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}:
\begin{quote}

\sphinxAtStartPar
For the analysis of the data {[}time\sphinxhyphen{}resolved photoelectron images from a rotationally\sphinxhyphen{}excited system{]}, a ‘bootstrapping’ fitting approach was developed. This methodology {[}… is illustrated conceptually in \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}}, and outlined in more detail in \hyperref[\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}]{Fig.\@ \ref{\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}}} …{]} is comprised of two stages (potentially split into multiple steps) which allow for the separation of the two sets of unknowns (rotational and ionization dynamics), and provides a way to gradually bootstrap to the complete {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} results via stages of analysis of increasing complexity. The nature of the fitting at each stage also provides a flexible methodology which can be used to carefully sample the solution hyperspace in order to ensure unique results, and fit with variable information content (experimental measurements) based on computational time and desired precision, based on a similar Monte\sphinxhyphen{}Carlo sampling manner to the methodologies already discussed {[}…{]}. In all cases, the underlying physics provides stringent limits on the form of the fitting functions, hence the fitting procedure at each stage is expected to be somewhat reliable by construction. Further analysis of the results, including comparison with experimental parameters, additional data not used in the analysis, and \sphinxstyleemphasis{ab initio} calculations all provide additional means of cross\sphinxhyphen{}checking and verifying the extracted physical parameters.

\sphinxAtStartPar
In terms of information content, the bootstrapping procedure gradually increases both the experimental information content \sphinxhyphen{} the number of geometric configurations of the photoionization interferometer \sphinxhyphen{} and the level of physical information included (hence fitted/extracted) in the analysis. In the first step, {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} {[}i.e. molecular alignment properties{]} are determined without the need for accurate treatment of the ionization probe {[}\hyperlink{cite.backmatter/bibliography:id773}{10}{]}; in the second step this information is used as part of the calculation to determine the ionization dynamics. In the sub\sphinxhyphen{}steps to determine the ionization dynamics, the experimental information content included in the analysis is gradually increased: the initial coarse steps in this procedure provide a base\sphinxhyphen{}line high information content, without the necessity for many temporal points, via the selection of highly distinct molecular axis distributions, while latter sub\sphinxhyphen{}steps allow for fine\sphinxhyphen{}tuning of the data by gradually coupling additional time\sphinxhyphen{}steps {[}or other constraints{]} into the analysis.

\begin{flushright}
---\sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}, Chpt. 11
\end{flushright}
\end{quote}

\sphinxAtStartPar
The protocol as presented relies on certain steps to be experimentally realisable, and theoretically calculable:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Molecular alignment. Experimentally, this can be induced in any system with a strong (typically \(>10^{12}\)\textasciitilde{}Wcm\(^{-2}\)), short (few hundred femtosecond timescale or shorter) infra\sphinxhyphen{}red laser pulse, which (impulsively) creates a rotational wavepacket in the system. The exact nature of the wavepacket is laser pulse(s) and system dependent, but the technique is general.

\item {} 
\sphinxAtStartPar
Time\sphinxhyphen{}resolved photoelectron measurements. Experimentally, this requires \sphinxhyphen{} at minumum \sphinxhyphen{} a pump\sphinxhyphen{}probe type configuration, with the alignment pulse as the pump, and a time\sphinxhyphen{}delayed ionization pulse. This is a typical experimental configuration in many ultrafast laser labs, with pulses typically in the atto\sphinxhyphen{} or femto\sphinxhyphen{}second regime. Measurements may be made by any angle\sphinxhyphen{}resolved technique; photoelectron imaging (via velocity\sphinxhyphen{}map imaging, {\hyperref[\detokenize{backmatter/glossary:term-VMI}]{\sphinxtermref{\DUrole{xref,std,std-term}{VMI}}}}) is currently the most accessible and widespread method.

\item {} 
\sphinxAtStartPar
Data analysis. This provides the bridge from high information\sphinxhyphen{}content measurements to a full quantum
metrology (system characterisation). For the generalised bootstrapping approach this requires:
\begin{itemize}
\item {} 
\sphinxAtStartPar
In order to characterise the rotational wavepacket created, alignment calculations of the system must be possible \sphinxhyphen{} such computations are increasingly tractable, if not already (somewhat) routine for a number of groups, although quite challenging and computational expensive for asymmetric top systems. These calculations are required in order to determine the rotational wavepacket ({\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}}) quantitatively, and in order to determine the corresponding {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} from/for the experiment. {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} computation is beyond the scope of the current work, but their use in the bootstrapping protocol is discussed in \hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chapter \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}.

\item {} 
\sphinxAtStartPar
To characterise the \sphinxstyleemphasis{intrinsic} photoionization dynamics, a set of appropriate geometric basis functions must be computed, and combined with a sufficiently large dataset to enable extraction of the photoionization matrix elements via a fitting procedure. This is the main focus of Part II herein.

\item {} 
\sphinxAtStartPar
(Optional) In cases with \sphinxstyleemphasis{extrinsic} dynamics, these may further be analysed once the \sphinxstyleemphasis{intrinsic} dynamics have been characterised (or as part of that characterisation); this may, however, remain qualitative or semi\sphinxhyphen{}quantitative, depending on the system dynamics and complexity. This aspect of photoelectron metrology is beyond the scope of the current work, see discussion in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} for more discussion; recent examples of such work may be found in Refs. {[}\hyperlink{cite.backmatter/bibliography:id774}{11}, \hyperlink{cite.backmatter/bibliography:id797}{12}{]}, which investigated coherent electronic dynamics and complete quantum tomography of such a case.

\end{itemize}

\end{enumerate}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{3}
\item {} 
\sphinxAtStartPar
(Optional) \sphinxstyleemphasis{Ab initio} computations may also be performed to compare with any or all of the previous steps; comparison with step 3 is particularly powerful, since one can compare fundamental quantum mechanical properties, as opposed to comparisons between measured and simulated observables, which may be integrated over many degrees of freedom of the system.

\end{enumerate}

\sphinxAtStartPar
As detailed in the following section (\hyperref[\detokenize{part1/main_intro_060723:sec-intro-context}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-intro-context}}}), the main aims herein are the development of the methodology and toolkit to address the data analysis requirement (step 3), and to test this methodology for a range of example cases.


\section{Context \& aims for Vol. 3}
\label{\detokenize{part1/main_intro_060723:context-aims-for-vol-3}}\label{\detokenize{part1/main_intro_060723:sec-intro-context}}

\subsection{Scientific aims}
\label{\detokenize{part1/main_intro_060723:scientific-aims}}
\sphinxAtStartPar
The work in the current volume primarily addresses recent developments towards a generalised bootstrapping protocol (i.e. the analysis of the data obtained by time\sphinxhyphen{}resolved photoelectron imaging measurements \sphinxhyphen{} or similar \sphinxhyphen{} from a rotationally\sphinxhyphen{}excited system), as previously outlined in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} Sect. 12.3; in particular the new \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} has been built with the aim of making the protocol easy to use and apply to any given problem (as distinct from a bespoke/per\sphinxhyphen{}experiment analysis methodology and/or non\sphinxhyphen{}open\sphinxhyphen{}source codebase).

\sphinxAtStartPar
Part I herein includes a full precis of the new codebase (\hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{Chapter \ref{\detokenize{part1/platform_intro_070723:chpt-platformintro}}}), along with the theory (\hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chapter \ref{\detokenize{part1/theory_100723:chpt-theory}}}) and numerics (\hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chapter \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}) implemented towards this end; {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} provides multiple demonstrations of the new code\sphinxhyphen{}base, including the use of the toolkit to investigate more complex systems beyond the simple homonuclear diatomic case demonstrated to date.

\sphinxAtStartPar
Although the analysis herein focuses on the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} case, the techniques and codebase developed are equally applicable to \sphinxstyleemphasis{any methodology or protocol making use of geometric properties as a variable}, and are built with all such problems in mind \sphinxhyphen{} although minor modifications or extensions may be required for specific cases. Examples include other cases discussed in \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]}, e.g. the use of shaped laser pulses or the use of narrow\sphinxhyphen{}band, state\sphinxhyphen{}selected rotational excitation; in all cases the fitting/retrieval of matrix elements is carried out in the same manner, and the only changes required to the methodology are the choice of control variable and the corresponding input experimental or theoretical parameters \sphinxhyphen{} this is discussed further in \hyperref[\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}}}.


\subsection{Technical context and notes}
\label{\detokenize{part1/main_intro_060723:technical-context-and-notes}}\label{\detokenize{part1/main_intro_060723:sec-intro-technical-notes}}
\sphinxAtStartPar
As noted previously, Vol. 3 is somewhat distinct from the previous volumes in the series; although involving computational elements, \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} are more traditional publications. The material presented in this volume aims to continue the exploration of quantum metrology with photoelectrons, with a focus on numerical analysis techniques, forging a closer link between experimental and theoretical results, and making the methodologies discussed directly accessible via a new software platform/ecosystem, \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, introduced in more detail in \hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{Chapter \ref{\detokenize{part1/platform_intro_070723:chpt-platformintro}}}.
In order to fulfill this aim, Vol. 3 is an open source computational/computable document, with code directly available to readers to facilitate code transparency and reuse. This can be broken down as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The book itself is written as a set of \sphinxhref{https://jupyter.org}{Jupyter Notebooks} {[}\hyperlink{cite.backmatter/bibliography:id829}{13}{]}.%
\begin{footnote}[1]\sphinxAtStartFootnote
For more information on the \sphinxhref{https://jupyter.org}{Jupyter Project and ecosystem}, see \sphinxhref{https://jupyter.org}{jupyter.org} and Refs. {[}\hyperlink{cite.backmatter/bibliography:id829}{13}, \hyperlink{cite.backmatter/bibliography:id726}{31}, \hyperlink{cite.backmatter/bibliography:id634}{32}{]}.)
%
\end{footnote}
\begin{itemize}
\item {} 
\sphinxAtStartPar
These are \sphinxcode{\sphinxupquote{.ipynb}} files, usually running a \sphinxhref{https://www.python.org/}{Python kernel} {[}\hyperlink{cite.backmatter/bibliography:id831}{14}{]}, each of which is designed such that it can be modified and used independently.

\item {} 
\sphinxAtStartPar
The full book is compiled from these sections using the \sphinxhref{https://jupyterbook.org/}{Jupyter Book} {[}\hyperlink{cite.backmatter/bibliography:id712}{15}, \hyperlink{cite.backmatter/bibliography:id566}{16}{]} project platform,%
\begin{footnote}[2]\sphinxAtStartFootnote
For more information see \sphinxhref{https://jupyterbook.org}{jupyterbook.org} and Refs. {[}\hyperlink{cite.backmatter/bibliography:id712}{15}, \hyperlink{cite.backmatter/bibliography:id566}{16}{]}.
%
\end{footnote} which includes build tools and specifications for the specific flavour of \sphinxhref{https://mystmd.org/}{Markdown (MyST)} {[}\hyperlink{cite.backmatter/bibliography:id803}{17}{]} used for the written text, and uses \sphinxhref{https://www.sphinx-doc.org}{Sphinx} {[}\hyperlink{cite.backmatter/bibliography:id901}{18}{]} to build HTML and Latex/PDF flavours of the book.

\item {} 
\sphinxAtStartPar
The book source code is available via a Github repository, \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}, which includes all the notebooks (in the \sphinxcode{\sphinxupquote{doc\sphinxhyphen{}source}} directory), as well as installation and build notes for building the book itself.

\item {} 
\sphinxAtStartPar
An HTML version is also available at \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)}, which includes interactive figures.

\end{itemize}

\item {} 
\sphinxAtStartPar
The code examples \sphinxstyleemphasis{within} the book make use the new \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}.
\begin{itemize}
\item {} 
\sphinxAtStartPar
In order to run code examples, a specific python environment (with various additional python packages) is required.

\item {} 
\sphinxAtStartPar
A full introduction to the relevant software tool\sphinxhyphen{}chain, including installation instructions for the codes used \sphinxstyleemphasis{within} the book, can be found in \hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{Chapter \ref{\detokenize{part1/platform_intro_070723:chpt-platformintro}}:} {\hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{\sphinxcrossref{\DUrole{std,std-ref}{Quantum metrology software platform/ecosystem overview}}}}.

\item {} 
\sphinxAtStartPar
For a quick and easy installation, including all requirements, a Docker build  of the platform can also be used, see \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-docker}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-docker}}:} {\hyperref[\detokenize{part1/platform_intro_070723:sect-platform-docker}]{\sphinxcrossref{\DUrole{std,std-ref}{Docker deployments}}}} (see also the \sphinxhref{https://github.com/phockett/open-photoionization-docker-stacks}{Open Photoionization Docker Stacks} {[}\hyperlink{cite.backmatter/bibliography:id687}{19}{]} for more related tools).

\item {} 
\sphinxAtStartPar
Once configured, any code examples from the book can be executed locally by the user/reader, and modified as desired. Each notebook is designed to be run as a stand\sphinxhyphen{}alone computational document.

\end{itemize}

\item {} 
\sphinxAtStartPar
The book can be regarded as, essentially, a manual and introduction to the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, as well as a foundation for those wishing to use (and potentially extend) the platform.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Part I covers all required background material, including details of the theory and numerical methods implemented.

\item {} 
\sphinxAtStartPar
Part II contains various examples of usage for a range of problems, and possible extensions.

\item {} 
\sphinxAtStartPar
Since no specific knowledge of the underlying physics should be required to use the software tools, they will hopefully also provide a suitable platform for new researchers wishing to learn about photoionization in general.

\item {} 
\sphinxAtStartPar
It is, of course, also hoped that established researchers in the field will find the tools useful, and readily adaptable, to related problems of interest.

\item {} 
\sphinxAtStartPar
Further documentation for the software tools (including the full PEMtk API) can be found online in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.

\end{itemize}

\end{enumerate}

\sphinxAtStartPar
Finally, it is of note that whilst readers unfamiliar with the Jupyter and Python ecosystem may find that there is somewhat of a barrier to entry for making use of the platform, it is one that may be worth surmounting given the ubiquity of these tools, and general usefulness in modern scientific/data\sphinxhyphen{}science workflows; readers already making use of these tools in their work should have no difficultly, and the platform adheres to standard practice wherever possible. For an introduction to Python for data science, the \sphinxhref{https://github.com/jakevdp/PythonDataScienceHandbook}{Python Data Science Handbook} provides a solid introduction, and is itself \sphinxhref{https://github.com/jakevdp/PythonDataScienceHandbook}{an open source textbook available via Github} {[}\hyperlink{cite.backmatter/bibliography:id942}{21}, \hyperlink{cite.backmatter/bibliography:id943}{22}{]}.


\subsection{A brief note on open science, open source software and reproducibility}
\label{\detokenize{part1/main_intro_060723:a-brief-note-on-open-science-open-source-software-and-reproducibility}}\label{\detokenize{part1/main_intro_060723:sect-intro-open-science}}
\sphinxAtStartPar
A large part of the motivation for creating new tools, making them open source, and standardized, is down to the nature of the modern scientific endeavour, and the difficulty of reproducibility. In short, many projects now involve a substantial element of analysis making use of in\sphinxhyphen{}house codes, which are often inaccessible to other researchers; the same may apply to the raw datasets used. Whilst this may be justified in some cases, in general it leads to a lack of transparency and portability for the computational and/or data component(s) of research. The Open Science movement, in part, aims to challenge these issues \sphinxhyphen{} see, for further discussion, Refs. {[}\hyperlink{cite.backmatter/bibliography:id519}{23}, \hyperlink{cite.backmatter/bibliography:id786}{24}, \hyperlink{cite.backmatter/bibliography:id809}{25}, \hyperlink{cite.backmatter/bibliography:id904}{26}, \hyperlink{cite.backmatter/bibliography:id906}{27}, \hyperlink{cite.backmatter/bibliography:id595}{28}, \hyperlink{cite.backmatter/bibliography:id697}{29}{]}, or the \sphinxhref{https://en.wikipedia.org/wiki/Open\_science}{Wikipeadia Open Science page} for a brief summary {[}\hyperlink{cite.backmatter/bibliography:id961}{30}{]}.

\sphinxAtStartPar
As noted above, this book is fully open\sphinxhyphen{}source, including the full book source code, the computational libraries used and the datasets illustrated herein, and available via \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}; this is detailed further in \hyperref[\detokenize{part1/platform_intro_070723:chpt-platformintro}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:chpt-platformintro}}}. In order to aid portability and reproducibility, Docker builds are also available: these provide a means to define a full computational platform/stack, from the OS level and up, including all necessary dependencies and version; further details can be found in \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-docker}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-docker}}}.

\sphinxAtStartPar
In general, it is hoped that making such tools more accessible, usable, and interconnected \sphinxhyphen{} as well as making computational data generally available \sphinxhyphen{} will lower the barrier to entry to the field and create a useful foundation for interested researchers to work from.


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{Quantum metrology software platform/ecosystem overview}
\label{\detokenize{part1/platform_intro_070723:quantum-metrology-software-platform-ecosystem-overview}}\label{\detokenize{part1/platform_intro_070723:chpt-platformintro}}\label{\detokenize{part1/platform_intro_070723::doc}}
\sphinxAtStartPar
In recent years, a unified Python codebase/ecosystem/platform has been in development to tackle various aspects of photoionization problems, including \sphinxstyleemphasis{ab initio} computations and experimental data handling, and (generalised) matrix element retrieval methods. The eponymous \sphinxstyleemphasis{Quantum Metrology with Photoelectrons} platform is introduced here, and is used for the analysis herein. The main aim of the platform is to provide a unifying data layer, and analysis routines, for photoelectron metrology, including new methods and tools, as well as a unifying bridge between these and existing tools. \hyperref[\detokenize{part1/platform_intro_070723:qm-platform-diag}]{Fig.\@ \ref{\detokenize{part1/platform_intro_070723:qm-platform-diag}}} provides a general overview of some of the main tools and tasks/layers.

\sphinxAtStartPar
As of late 2022, the new parts of the platform \sphinxhyphen{} primarily the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} library \sphinxhyphen{} implement general data handling for theory and experimental datasets (although not a full experimental analysis toolchain), along with matrix element handling and retrieval, which will be the main topic of this volume.
In the future, it is hoped that the platform will be extended to other theoretical and experimental methods, including full experimental data handling.


\section{Analysis components}
\label{\detokenize{part1/platform_intro_070723:analysis-components}}\label{\detokenize{part1/platform_intro_070723:sect-platform-analysis}}
\sphinxAtStartPar
The two main components of the platform for analysis tasks, as used herein, are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} (PEMtk) codebase aims to provide various general data handling routines for photoionization problems. At the time of writing, simulation of observables and fitting routines are implemented, along with some basic utility functions.
Much of this is detailed herein, and more technical details and ongoing documentation case be found in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.

\item {} 
\sphinxAtStartPar
The \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} aims to provide methods for post\sphinxhyphen{}processing with \sphinxstyleemphasis{ab initio} radial dipole matrix
elements from \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]}, or equivalent matrix elements from other sources (dedicated support for R\sphinxhyphen{}matrix results from \sphinxhref{https://gitlab.com/Uk-amor/RMT/rmt}{the RMT suite} {[}\hyperlink{cite.backmatter/bibliography:id545}{40}, \hyperlink{cite.backmatter/bibliography:id858}{41}{]} is in development, for an overview of \sphinxstyleemphasis{ab initio} methods/packages see Ref. {[}\hyperlink{cite.backmatter/bibliography:id594}{42}{]}).
The core functionality includes the computation of AF and MF observables. Manual computation without known matrix elements is also possible, e.g. for investigating
limiting cases, or data analysis and fitting \sphinxhyphen{} hence these routines also provide the backend functionality for PEMtk fitting routines. Again more technical details can be found in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}.

\end{itemize}

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
As {\hyperref[\detokenize{frontmatter/book_versions_note:sec-numerics-disclaimer}]{\sphinxcrossref{\DUrole{std,std-ref}{noted elsewhere}}}}, many components of the toolkit are still in active development, and some numerical details may change.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{QM_unified_schema_wrapped_280820_gv}.png}
\caption{Quantum metrology with photoelectrons ecosystem overview.}\label{\detokenize{part1/platform_intro_070723:qm-platform-diag}}\end{figure}


\section{Additional tools}
\label{\detokenize{part1/platform_intro_070723:additional-tools}}\label{\detokenize{part1/platform_intro_070723:sect-platform-othertools}}
\sphinxAtStartPar
Other tools listed in \hyperref[\detokenize{part1/platform_intro_070723:qm-platform-diag}]{Fig.\@ \ref{\detokenize{part1/platform_intro_070723:qm-platform-diag}}} include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Quantum chemistry layer. The starting point for \sphinxstyleemphasis{ab initio} computations. Many tools are available, but for the examples herein, all computations made use of \sphinxhref{http://www.msg.ameslab.gov/gamess/}{Gamess (“The General Atomic and Molecular Electronic Structure System”)} {[}\hyperlink{cite.backmatter/bibliography:id622}{43}, \hyperlink{cite.backmatter/bibliography:id633}{44}{]} for electronic structure computations, and inputs to ePolyScat.
\begin{itemize}
\item {} 
\sphinxAtStartPar
For a python\sphinxhyphen{}based approach, various packages are available, e.g. \sphinxhref{https://pyscf.org}{PySCF}, \sphinxhref{https://pyquante.sourceforge.net/}{PyQuante}, \sphinxhref{https://psicode.org}{Psi} can be used for electronic structure calculation, although note that some \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]} routines currently require Gamess files (specifically for visualisation of orbitals).

\item {} 
\sphinxAtStartPar
A range of other python tools are available, including \sphinxhref{https://cclib.github.io/}{cclib} for file handling and conversion, \sphinxhref{https://chemlab.readthedocs.io}{Chemlab} for molecule wavefunction visualisations, see further notes below.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]} is an open\sphinxhyphen{}source tool for numerical computation of electron\sphinxhyphen{}molecule scattering \& photoionization by Lucchese \& coworkers.
\begin{itemize}
\item {} 
\sphinxAtStartPar
All matrix elements used herein were obtained via ePS calculations. For more details see \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat website and manual} {[}\hyperlink{cite.backmatter/bibliography:id767}{39}{]} and Refs. {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}{]}.

\item {} 
\sphinxAtStartPar
A \sphinxhref{https://github.com/phockett/open-photoionization-docker-stacks/tree/main/ePolyScat}{Docker build is available} (via the \sphinxhref{https://github.com/phockett/open-photoionization-docker-stacks}{Open Photoionization Docker Stacks} {[}\hyperlink{cite.backmatter/bibliography:id687}{19}{]} project).

\item {} 
\sphinxAtStartPar
ePS (along with a range of other computational AMO tools) is also available online via the \sphinxhref{https://amosgateway.org/}{AMOS gateway} %
\begin{footnote}[1]\sphinxAtStartFootnote
Formerly known as the AMP gateway.
%
\end{footnote} {[}\hyperlink{cite.backmatter/bibliography:id510}{45}, \hyperlink{cite.backmatter/bibliography:id872}{46}, \hyperlink{cite.backmatter/bibliography:id873}{47}{]}.

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxhref{https://phockett.github.io/ePSdata/about.html}{ePSdata} {[}\hyperlink{cite.backmatter/bibliography:id679}{48}{]} is an open\sphinxhyphen{}data/open\sphinxhyphen{}science collection of ePS + ePSproc results.
\begin{itemize}
\item {} 
\sphinxAtStartPar
ePSdata collects ePS datasets, post\sphinxhyphen{}processed via ePSproc (Python) in \sphinxhref{https://jupyter.org}{Jupyter notebooks}, for a full open\sphinxhyphen{}data/open\sphinxhyphen{}science transparent pipeline.

\end{itemize}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Source notebooks are available on the \sphinxhref{https://github.com/phockett/ePSdata/}{ePSdata} {[}\hyperlink{cite.backmatter/bibliography:id679}{48}{]} \sphinxhref{https://github.com/phockett/ePSdata/}{Github project repository}, and notebooks + datasets via \sphinxhref{https://zenodo.org/search?page=1\&size=20\&q=hockett\&keywords=Data}{ePSdata Zenodo} {[}\hyperlink{cite.backmatter/bibliography:id680}{49}{]}. Each notebook + dataset is given a Zenodo DOI for full traceability, and notebooks are versioned on Github.

\item {} 
\sphinxAtStartPar
Note: ePSdata may also be linked or mirrored on the existing \sphinxhref{https://osf.io/psjxt/}{ePolyScat Collected Results OSF project}, but will effectively supercede those pages.

\item {} 
\sphinxAtStartPar
All results are released under \sphinxhref{https://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative Commons Attribution\sphinxhyphen{}NonCommercial\sphinxhyphen{}ShareAlike 4.0 (CC BY\sphinxhyphen{}NC\sphinxhyphen{}SA 4.0) license}, and are part of an ongoing \sphinxhref{http://femtolab.ca/?p=877}{Open Science initiative}.

\end{itemize}

\end{itemize}


\section{Python ecosystem (backends, libraries and packages)}
\label{\detokenize{part1/platform_intro_070723:python-ecosystem-backends-libraries-and-packages}}\label{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}
\sphinxAtStartPar
The core analysis tools, which constitute the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} platform, are themselves built with the aid of a range of open\sphinxhyphen{}source python packages/libraries which handle various backend functionality. Notably, they make use of the following key packages:
\begin{itemize}
\item {} 
\sphinxAtStartPar
General functionality makes use of the usual “Scientific Python” stack, in particular:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://numpy.org/}{\sphinxcode{\sphinxupquote{Numpy}}} {[}\hyperlink{cite.backmatter/bibliography:id811}{50}{]} for general numerical methods and data types.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://pandas.pydata.org/}{\sphinxcode{\sphinxupquote{pandas}}} {[}\hyperlink{cite.backmatter/bibliography:id819}{51}{]} for statistical methods, and various tabulation and sorting tasks.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://scipy.org/}{\sphinxcode{\sphinxupquote{Scipy}}} {[}\hyperlink{cite.backmatter/bibliography:id876}{52}{]} for some special functions and computational routines, particularly spherical harmonics and fitting routines (see below).

\end{itemize}

\item {} 
\sphinxAtStartPar
General ND\sphinxhyphen{}array and tensor handling and manipulation makes use of the \sphinxhref{https://docs.xarray.dev}{\sphinxcode{\sphinxupquote{Xarray}} library} {[}\hyperlink{cite.backmatter/bibliography:id698}{53}, \hyperlink{cite.backmatter/bibliography:id975}{54}{]}.

\item {} 
\sphinxAtStartPar
Angular momentum functions
\begin{itemize}
\item {} 
\sphinxAtStartPar
Wigner D and 3js are currently implemented directly, or via the \sphinxhref{https://github.com/moble/spherical\_functions}{Spherical Functions library} {[}\hyperlink{cite.backmatter/bibliography:id540}{55}, \hyperlink{cite.backmatter/bibliography:id542}{56}{]}, and have been tested for consistency with the definitions in Zare (for details see \sphinxhref{https://epsproc.readthedocs.io/en/latest/tests/Spherical\_function\_testing\_Aug\_2019.html}{the ePSproc docs} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}). The Spherical Functions library also uses \sphinxhref{https://github.com/moble/quaternion}{\sphinxcode{\sphinxupquote{quaternion}}} {[}\hyperlink{cite.backmatter/bibliography:id541}{57}, \hyperlink{cite.backmatter/bibliography:id796}{58}{]} which implements a quaternion datatype in Numpy.

\item {} 
\sphinxAtStartPar
Spherical harmonics are defined with the usual physics conventions: orthonormalised, and including the Condon\sphinxhyphen{}Shortley phase. Numerically they are implemented directly or via SciPy’s \sphinxcode{\sphinxupquote{sph\_harm}} function (see \sphinxhref{https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.sph\_harm.html}{the SciPy docs for details} {[}\hyperlink{cite.backmatter/bibliography:id877}{59}{]}. Further manipulation and conversion between different normalisations can be readily implemented with the \sphinxhref{https://shtools.github.io/SHTOOLS/}{\sphinxcode{\sphinxupquote{pySHtools}} library} {[}\hyperlink{cite.backmatter/bibliography:id888}{60}, \hyperlink{cite.backmatter/bibliography:id957}{61}, \hyperlink{cite.backmatter/bibliography:id958}{62}, \hyperlink{cite.backmatter/bibliography:id959}{63}{]}. See \hyperref[\detokenize{part1/theory_observables_intro_100723:sec-theory-sph-harm-intro}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sec-theory-sph-harm-intro}}} for examples.

\item {} 
\sphinxAtStartPar
Symmetry functionality, specifically computing symmetrized harmonics \(X_{hl}^{\Gamma\mu*}(\theta,\phi)\) (see Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}), makes use of \sphinxhref{https://github.com/mcodev31/libmsym}{\sphinxcode{\sphinxupquote{libmsym}}} {[}\hyperlink{cite.backmatter/bibliography:id708}{64}, \hyperlink{cite.backmatter/bibliography:id709}{65}{]} (symmetry coefficients) and \sphinxhref{https://shtools.oca.eu}{\sphinxcode{\sphinxupquote{pySHtools}}} {[}\hyperlink{cite.backmatter/bibliography:id888}{60}, \hyperlink{cite.backmatter/bibliography:id957}{61}, \hyperlink{cite.backmatter/bibliography:id958}{62}, \hyperlink{cite.backmatter/bibliography:id959}{63}{]} (general spherical harmonic handling and conversion).  See \hyperref[\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}}} for examples.

\end{itemize}

\item {} 
\sphinxAtStartPar
Non\sphinxhyphen{}linear optimization (fitting), as used for the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} (to determine {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}):
\begin{itemize}
\item {} 
\sphinxAtStartPar
Fitting is handled via the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]}, which implements and/or wraps a range of non\sphinxhyphen{}linear fitting routines in Python, including classes for handling fitting parameters and outputs. In this work only the Levenberg\sphinxhyphen{}Marquardt least\sphinxhyphen{}squares minimization method has been used, which wraps \sphinxhref{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least\_squares.html}{Scipy’s \sphinxcode{\sphinxupquote{least\_squares}} functionality} {[}\hyperlink{cite.backmatter/bibliography:id877}{59}{]}, hence this is the core numerical minimization routine for the demonstration cases herein. (See \hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chapter \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}} for further discussion of fitting methods.)

\item {} 
\sphinxAtStartPar
Basic parallelization for fitting routines is implemented using the \sphinxhref{https://xyzpy.readthedocs.io/en/latest/}{\sphinxcode{\sphinxupquote{xyzpy}}} library {[}\hyperlink{cite.backmatter/bibliography:id976}{68}{]}, see \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chapter \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}} for further details.

\end{itemize}

\item {} 
\sphinxAtStartPar
For plotting a range of tools can be used, some of which are implemented/wrapped in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, or can be used directly with \sphinxcode{\sphinxupquote{Xarray}} data structures, including:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://matplotlib.org/}{\sphinxcode{\sphinxupquote{Matplotlib}}} {[}\hyperlink{cite.backmatter/bibliography:id779}{69}{]}: basic plotting, including \sphinxhref{https://docs.xarray.dev/en/stable/user-guide/plotting.html}{\sphinxcode{\sphinxupquote{Xarray}} direct plotters}.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://holoviews.org/}{\sphinxcode{\sphinxupquote{Holoviews}}} {[}\hyperlink{cite.backmatter/bibliography:id693}{70}{]}: used for data handling and interactive plotting, Holoviews is a general plotting tool which wraps various backends; \sphinxhref{https://hvplot.holoviz.org/}{\sphinxcode{\sphinxupquote{hvplot}}} {[}\hyperlink{cite.backmatter/bibliography:id699}{71}{]} can also be used to provide additional \sphinxcode{\sphinxupquote{Pandas}} and \sphinxcode{\sphinxupquote{Xarray}} integration for Holoviews. Most of the plots herein use Holoviews.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://bokeh.org/}{\sphinxcode{\sphinxupquote{Bokeh}}} {[}\hyperlink{cite.backmatter/bibliography:id536}{72}{]}: used for interactive plots, implemented in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} via Holoviews wrappers/methods.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://plotly.com/}{\sphinxcode{\sphinxupquote{Plotly}}} {[}\hyperlink{cite.backmatter/bibliography:id827}{73}{]}: used in the the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} and the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} for spherical polar plotting routines.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://seaborn.pydata.org/}{\sphinxcode{\sphinxupquote{Seaborn}}} {[}\hyperlink{cite.backmatter/bibliography:id878}{74}, \hyperlink{cite.backmatter/bibliography:id954}{75}{]}: used for statistical methods and some specialist plots and styles, particularly the \sphinxhref{https://epsproc.readthedocs.io/en/dev/demos/ePSproc\_demo\_matE\_plotting\_Feb2020.html\#Plotting-maps-with-lmPlot}{\sphinxcode{\sphinxupquote{lmPlot}} routine} in \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]}.

\end{itemize}

\item {} 
\sphinxAtStartPar
Some specialist (optional) tools also make use of additional libraries, although these are not required for basic use; in particular:
\begin{itemize}
\item {} 
\sphinxAtStartPar
For 3D orbital visualizations with \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]}: \sphinxhref{https://docs.pyvista.org/}{pyvista} for 3D plotting (which itself is built on VTK), \sphinxhref{https://cclib.github.io/}{cclib} for electronic structure file handling and conversion, and methods based on \sphinxhref{https://chemlab.readthedocs.io}{Chemlab} for molecule wavefunction (orbital) computation from electronic structure files are all used on the backend.

\item {} 
\sphinxAtStartPar
\sphinxhref{https://numba.pydata.org/}{\sphinxcode{\sphinxupquote{Numba}}} {[}\hyperlink{cite.backmatter/bibliography:id810}{76}{]} is used for numerical acceleration in some routines, although remains mainly experimental in \sphinxcode{\sphinxupquote{ePSproc}} at the time of writing (an exception to this is the Spherical Functions library, which does make full use of Numba acceleration).

\end{itemize}

\end{itemize}

\sphinxAtStartPar
Code examples and further comments can be found as and when numerical examples are introduced in the text, particularly in \hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chapter \ref{\detokenize{part1/theory_100723:chpt-theory}}} and \hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chapter \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}.


\section{Installation and environment set\sphinxhyphen{}up}
\label{\detokenize{part1/platform_intro_070723:installation-and-environment-set-up}}\label{\detokenize{part1/platform_intro_070723:sect-installation}}

\subsection{Quick\sphinxhyphen{}start installation}
\label{\detokenize{part1/platform_intro_070723:quick-start-installation}}
\sphinxAtStartPar
For a basic installation, up\sphinxhyphen{}to\sphinxhyphen{}date version of \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} and \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} can be installed directly from Github source using pip:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pip} \PYG{n}{install} \PYG{n}{git}\PYG{o}{+}\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{phockett}\PYG{o}{/}\PYG{n}{ePSproc}\PYG{o}{.}\PYG{n}{git}
\PYG{n}{pip} \PYG{n}{install} \PYG{n}{git}\PYG{o}{+}\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{phockett}\PYG{o}{/}\PYG{n}{PEMtk}\PYG{o}{.}\PYG{n}{git}

\end{sphinxVerbatim}

\sphinxAtStartPar
This should also install the required dependencies, although not all of the optional packages. (Note that \sphinxcode{\sphinxupquote{pip install ePSproc}} will also work, and install the latest release from \sphinxhref{https://pypi.org/project/ePSproc/}{the Pypi repository}, but this may not be fully up\sphinxhyphen{}to\sphinxhyphen{}date compared to the Github source; \sphinxcode{\sphinxupquote{PEMtk}} is not yet available via Pypi.)

\sphinxAtStartPar
For more details and other installation options, see the \sphinxhref{https://epsproc.readthedocs.io/en/latest/etc/installation\_notes\_051120.html}{ePSproc extended installation notes online}, which includes directions for virtual environments (Anaconda, Venv).

\sphinxAtStartPar
To obtain the book source, including all example notebooks, simply use Git:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{phockett}\PYG{o}{/}\PYG{n}{Quantum}\PYG{o}{\PYGZhy{}}\PYG{n}{Metrology}\PYG{o}{\PYGZhy{}}\PYG{k}{with}\PYG{o}{\PYGZhy{}}\PYG{n}{Photoelectrons}\PYG{o}{\PYGZhy{}}\PYG{n}{Vol3}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

\sphinxAtStartPar
Alternatively, the files can be browsed and download via the web from the \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}, which also includes additional setup notes.


\subsection{Docker deployments}
\label{\detokenize{part1/platform_intro_070723:docker-deployments}}\label{\detokenize{part1/platform_intro_070723:sect-platform-docker}}
\sphinxAtStartPar
\sphinxhref{https://www.docker.com/}{Docker} {[}\hyperlink{cite.backmatter/bibliography:id588}{77}{]} provides a useful mechanism for distribution of software as stand\sphinxhyphen{}alone containers (essentially minimal virtual machines), including definitions and versioning for everything from the operating system layer and up. Docker containers are both portable and reproducible, hence excellent tools for open science (see \hyperref[\detokenize{part1/main_intro_060723:sect-intro-open-science}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sect-intro-open-science}}}).

\sphinxAtStartPar
A Docker\sphinxhyphen{}based distribution of various codes for tackling
photoionization problems is available from the \sphinxhref{https://github.com/phockett/open-photoionization-docker-stacks}{Open Photoionization Docker Stacks} {[}\hyperlink{cite.backmatter/bibliography:id687}{19}{]}
project, which aims to make a range of these tools more accessible to
interested researchers, and fully cross\sphinxhyphen{}platform/portable. The project currently includes Docker builds for \sphinxcode{\sphinxupquote{ePSproc}} and \sphinxcode{\sphinxupquote{PEMtk}} (as well as \sphinxcode{\sphinxupquote{ePS}} and other useful tools). These are based on the \sphinxhref{https://jupyter-docker-stacks.readthedocs.io}{Jupyter Docker Stacks project} {[}\hyperlink{cite.backmatter/bibliography:id713}{78}{]}, which includes Jupyter Lab, and also add all the required tools for the work illustrated herein.

\sphinxAtStartPar
A Docker container for this book is \sphinxhref{https://hub.docker.com/r/epsproc/quantum-met-vol3}{also available from the Docker Hub} (and source Dockerfiles via \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}). This container builds on the \sphinxcode{\sphinxupquote{ePSproc}} and \sphinxcode{\sphinxupquote{PEMtk}} container, and additionally includes the source notebooks and build tools (specifically \sphinxhref{https://jupyterbook.org/}{Jupyter Book} {[}\hyperlink{cite.backmatter/bibliography:id712}{15}, \hyperlink{cite.backmatter/bibliography:id566}{16}{]} and related tools) as discussed in  \hyperref[\detokenize{part1/main_intro_060723:sec-intro-technical-notes}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-intro-technical-notes}}}. It is suggested that readers interested in making use of this work start here as the easiest \sphinxhyphen{} and most comprehensive \sphinxhyphen{} methodology for getting the tools up and running. Docker uses simply need to run \sphinxcode{\sphinxupquote{docker pull epsproc/quantum\sphinxhyphen{}met\sphinxhyphen{}vol3}} to obtain a copy, and \sphinxcode{\sphinxupquote{docker run epsproc/quantum\sphinxhyphen{}met\sphinxhyphen{}vol3}} to run \sphinxhyphen{} for further details and notes see the \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3/tree/main/docker}{Docker section} of \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}.


\subsection{Running examples}
\label{\detokenize{part1/platform_intro_070723:running-examples}}
\sphinxAtStartPar
Any of the source notebooks can be run individually in a correctly configured Python/Jupyter environment (readers unfamiliar with Jupyter \sphinxhref{https://jupyter.org}{can find introductory materials online at jupyter.org} {[}\hyperlink{cite.backmatter/bibliography:id829}{13}{]}). Note that the majority of the imports are handled by a setup script, executed at the top of each notebook, for brevity and to ensure a standardized build:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{run} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../scripts/setup\PYGZus{}notebook.py}\PYG{l+s+s1}{\PYGZsq{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
For additional customization this script can be modified as desired. Depending on the build environment the full path to the script may also need to be set (the current code assumes the script will be located in the \sphinxcode{\sphinxupquote{qm3\sphinxhyphen{}repo/doc\sphinxhyphen{}source/scripts}} directory, and notebooks run from their source dirs, e.g. \sphinxcode{\sphinxupquote{qm3\sphinxhyphen{}repo/doc\sphinxhyphen{}source/part1}}).


\section{General platform discussion}
\label{\detokenize{part1/platform_intro_070723:general-platform-discussion}}\label{\detokenize{part1/platform_intro_070723:sect-platform-general}}
\sphinxAtStartPar
Note that, at the time of writing:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Rotational wavepacket simulation is not yet implemented in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, and these must be obtained via other codes. An intial build of the \sphinxhref{https://github.com/jonathanunderwood/limapack}{\sphinxcode{\sphinxupquote{limapack}} suite} {[}\hyperlink{cite.backmatter/bibliography:id940}{79}{]} for rotational wavepacket simulations is currently part of the \sphinxhref{https://github.com/phockett/open-photoionization-docker-stacks}{Open Photoionization Docker Stacks} {[}\hyperlink{cite.backmatter/bibliography:id687}{19}{]}, but has yet to be used in this work.

\item {} 
\sphinxAtStartPar
Fitting:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Fitting methods have not yet been carefully optimized, with only a general non\sphinxhyphen{}linear least squares method implemented. However, other methods should be easy to implement, either via the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} or with other Python libraries or custom codes; optimization making use of \sphinxcode{\sphinxupquote{Numba}} should also be possible.

\item {} 
\sphinxAtStartPar
Only the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} is currently implemented in \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, along with associated analysis routines. However, the routines were written to be general and modular, so modification of the routines to other retrieval schemes should be fairly easy, and usually requires only (a) a function which computes the required basis set (e.g. {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}})  and (b) observables for the problem at hand. Examples are given in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} for the \sphinxstyleemphasis{generalised {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}}, and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} based retrieval is also implemented in the codebase. For further details see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_backends\_demo\_010922.html}{fitting model backends} and \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_demo\_multi-fit\_tests\_130621-MFtests\_120822-tidy-retest.html}{fitting MF and other datasets} pages.

\end{itemize}

\item {} 
\sphinxAtStartPar
The \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} codebase is currently still under heavy development, so readers may wish to consult the ongoing \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} in future for changes and updates.

\item {} 
\sphinxAtStartPar
For specific guides to various aspects of both codebases, see the relevant docs, which include full API guides. Some particular materials of introductory interest include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
A general quick\sphinxhyphen{}start demo can be found in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, \sphinxhref{https://epsproc.readthedocs.io/en/latest/demos/ePSproc\_class\_demo\_161020.html}{specifically the ePSproc class intro page}.

\item {} 
\sphinxAtStartPar
For more details of the data structures used, see the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, specifically the \sphinxhref{https://epsproc.readthedocs.io/en/latest/dataStructures/ePSproc\_dataStructures\_demo\_070622.html}{data structures page}.

\end{itemize}

\end{itemize}

\sphinxAtStartPar
Nonetheless, although both the codebase and methodologies are still under development, a range of numerical methods have been successfully trialled (as illustrated in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} herein), and are now available to other researchers to make use of and build on.


\bigskip\hrule\bigskip


\sphinxstepscope


\chapter{Theory}
\label{\detokenize{part1/theory_100723:theory}}\label{\detokenize{part1/theory_100723:chpt-theory}}\label{\detokenize{part1/theory_100723::doc}}
\sphinxAtStartPar
In this chapter a number of fundamentals are outlined. Only a brief introduction to the necessary physics (which already has a rich literature) is presented, and the emphasis is instead on code and numerical examples. These are intended both to give readers an insight into the physics, and also illustrate aspects of the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} and \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} that can be used for these problems. These methods will form the basis for the numerical reconstruction work presented in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}.

\sphinxAtStartPar
Readers only interested in fitting problems from an experimental perspective may wish to skip most of this section; \hyperref[\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}}:} and \hyperref[\detokenize{part1/theory_info_content_200723:sec-info-content}]{Sect.\@ \ref{\detokenize{part1/theory_info_content_200723:sec-info-content}}:} should provide sufficient background for pure reconstruction problems.

\sphinxstepscope


\section{Photoionization dynamics}
\label{\detokenize{part1/theory_photoionization_dynamics_140723:photoionization-dynamics}}\label{\detokenize{part1/theory_photoionization_dynamics_140723:sec-dynamics-intro}}\label{\detokenize{part1/theory_photoionization_dynamics_140723::doc}}
\sphinxAtStartPar
The core physics of photoionization has been covered extensively in the literature, and only a very brief overview is provided here with sufficient detail to introduce the metrology/reconstruction/retrieval problem; the reader is referred to \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]} (and references therein) for further details and general discussion.

\sphinxAtStartPar
Photoionization can be described by the coupling of an initial state of the system to a particular final state (photoion(s) plus free photoelectron(s)), coupled by an electric field/photon. Very generically, this can be written as a matrix element \(\langle\Psi_f|\hat{\Gamma}(\boldsymbol{\mathbf{E}})|\Psi_i\rangle\), where \(\hat{\Gamma}(\boldsymbol{\mathbf{E}})\) defines the light\sphinxhyphen{}matter coupling operator (depending on the electric field \(\boldsymbol{\mathbf{E}}\)), and \(\Psi_i\), \(\Psi_f\) the total wavefunctions of the initial and final states respectively.

\sphinxAtStartPar
There are many flavours of this fundamental light\sphinxhyphen{}matter interaction, depending on system and coupling. For metrology, the focus is currently on the simplest case of single\sphinxhyphen{}photon absorption, in the weak field (or perturbative), dipolar regime, resulting in a single photoelectron. (For more discussion of various approximations in photoionzation, see Refs. {[}\hyperlink{cite.backmatter/bibliography:id884}{80}, \hyperlink{cite.backmatter/bibliography:id883}{81}{]}.) In this case the core physics is well defined, and tractable (albeit non\sphinxhyphen{}trivial), via the separation of matrix elements into radial (energy) and angular\sphinxhyphen{}momentum (geometric) terms pertaining to couplings between various elements of the problem; the retrieval of such matrix elements is then a well\sphinxhyphen{}defined problem in general, achieved by making use of the analytic geometric terms in combination with fitting methodologies for the unknown radial matrix elements, and this is the approach explored herein. Again, more extensive background and discussion can be found in \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}, and references therein. Note, however, that whilst the general approach taken here is sound, many outstanding questions remain regarding the information content required for such an approach to be successful, and if other limitations prevent a unique set of solutions to be found in a given case (e.g. symmetry restrictions, phase ambiguities) \sphinxhyphen{} such questions are explored further herein, particularly in the case studies presented {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}.

\sphinxAtStartPar
The basic case also provides a strong foundation for extension into more complex light\sphinxhyphen{}matter interactions, in particular cases with shaped laser\sphinxhyphen{}fields (i.e. a time\sphinxhyphen{}dependent coupling \(\hat{\Gamma}(\boldsymbol{\mathbf{E,t}})\)) and multi\sphinxhyphen{}photon processes (which require multiple matrix elements, and/or different approximations). Note, however, that non\sphinxhyphen{}perturbative (strong field) light\sphinxhyphen{}matter interactions are, typically, not amenable to description in a separable picture in this manner. In such cases the laser field, molecular and continuum properties are strongly coupled, and are typically treated numerically in a fully time\sphinxhyphen{}dependent manner (although some separation of terms may work in some cases, depending on the system and interaction(s) at hand).

\sphinxAtStartPar
Underlying the photoelecton observables is the photoelectron continuum state \(\left|\mathbf{k}\right>\), prepared via photoionization. The photoelectron momentum vector is denoted generally by
\(\boldsymbol{\mathbf{k}}=k\mathbf{\hat{k}}\), in the molecular frame ({\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}). The ionization matrix elements associated with this transition provide the set of quantum amplitudes completely defining the final continuum scattering state,
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:continuum-state-vec}
\begin{split}\left|\Psi_f\right> = \sum{\int{\left|\Psi_{+};\bf{k}\right>\left<\Psi_{+};\mathbf{k}|\Psi_f\right> d\bf{k}}},
\end{split}
\end{equation}
\sphinxAtStartPar
where the sum is over states of the molecular ion \(\left|\Psi_{+}\right>\). The number of ionic states accessed depends on the nature of the ionizing pulse and interaction. For the dipolar case,
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:def-dipole-operator}
\begin{split}\hat{\Gamma}(\boldsymbol{\mathbf{E}}) = \hat{\boldsymbol{\mu}}.\boldsymbol{\mathbf{E}}\end{split}
\end{equation}
\sphinxAtStartPar
Hence,
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:matE-dipole}
\begin{split}\left<\Psi_{+};\mathbf{k}|\Psi_f\right> =\langle\Psi_{+};\,\mathbf{k}|\hat{\boldsymbol{\mu}}.\boldsymbol{\mathbf{E}}|\Psi_{i}\rangle
\end{split}
\end{equation}
\sphinxAtStartPar
Where the notation implies a perturbative photoionization event from an initial state \(i\) to a particular ion plus electron state following absorption of a photon \(h\nu\), \(|\Psi_{i}\rangle+h\nu{\rightarrow}|\Psi_{+};\boldsymbol{\mathbf{k}}\rangle\), and \(\hat{\mu}.\boldsymbol{\mathbf{E}}\) is the usual dipole interaction term {[}\hyperlink{cite.backmatter/bibliography:id832}{82}{]}, which includes a sum over all electrons \(s\) defined in position space as \(\mathbf{r_{s}}\):
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:dipole-operator}
\begin{split}\hat{\mu}=-e\sum_{s}\mathbf{r_{s}}
\end{split}
\end{equation}
\sphinxAtStartPar
The position space photoelectron wavefunction is typically expressed as a {\hyperref[\detokenize{backmatter/glossary:term-partial-wave-expansion}]{\sphinxtermref{\DUrole{xref,std,std-term}{partial\sphinxhyphen{}wave expansion}}}}, expanded as (asymptotic) continuum
eignstates of orbital angular momentum, with angular momentum components
\((l,m)\),
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:elwf}
\begin{split}\Psi_\mathbf{k}(\boldsymbol{r})\equiv\left<\boldsymbol{r}|\mathbf{k}\right> = \sum_{lm}Y_{lm}(\mathbf{\hat{k}})\psi_{lm}(\boldsymbol{r},k)
\end{split}
\end{equation}
\sphinxAtStartPar
where \(\boldsymbol{r}\) are MF electronic coordinates and
\(Y_{lm}(\mathbf{\hat{k}})\) are the spherical harmonics. Note the lower\sphinxhyphen{}case notation for the partial wave angular\sphinxhyphen{}momentum components, distinct from upper\sphinxhyphen{}case for the similar terms \((L,M)\) in the observables (\hyperref[\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}}}).

\sphinxAtStartPar
Similarly, the ionization dipole matrix elements can be separated
generally into radial (energy\sphinxhyphen{}dependent or ‘dynamical’ terms) and
geometric (angular momentum) parts (this separation is essentially the
Wigner\sphinxhyphen{}Eckart Theorem, see Ref. {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]} for general discussion),
and written generally as (using notation similar to {[}\hyperlink{cite.backmatter/bibliography:id837}{84}{]}):
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}
\begin{split}\langle\Psi_{+};\,\mathbf{k}|\hat{\boldsymbol{\mu}}.\boldsymbol{\mathbf{E}}|\Psi_{i}\rangle = \sum_{lm}\gamma_{l,m}\mathbf{r}_{k,l,m}
\end{split}
\end{equation}
\sphinxAtStartPar
Provided that the {\hyperref[\detokenize{backmatter/glossary:term-geometric-coupling-parameters}]{\sphinxtermref{\DUrole{xref,std,std-term}{geometric coupling parameters}}}} (the geometric part of the matrix elements) \(\gamma_{l,m}\) \sphinxhyphen{}
which includes the geometric rotations into the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} arising from the dot
product in Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam} and other angular\sphinxhyphen{}momentum coupling terms \sphinxhyphen{} are
known, knowledge of the so\sphinxhyphen{}called {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}
elements, at a given \(k\), thus equates to a full description of the
system dynamics (and, hence, the observables). Determination of these {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} \sphinxhyphen{} which are complex quantities with magnitudes and phases \sphinxhyphen{} is the aim of the reconstruction methodologies discussed herein (see \hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chpt.\@ \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}).

\sphinxAtStartPar
For the simplest treatment, the radial matrix element can be
approximated as a 1\sphinxhyphen{}electron integral involving the initial electronic
state (orbital), and final continuum photoelectron wavefunction:
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam-integral}
\begin{split}\mathbf{r}_{k,l,m}=\int\psi_{lm}^{*}(\boldsymbol{r},k)\boldsymbol{r}\Psi_{i}(\boldsymbol{r})d\boldsymbol{r}
\end{split}
\end{equation}
\sphinxAtStartPar
As noted above, the geometric terms \(\gamma_{l,m}\) are analytical
functions which can be computed for a given case \sphinxhyphen{} minimally requiring
knowledge of the molecular symmetry and polarization geometry, although
other factors may also play a role (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}} for details).

\sphinxAtStartPar
The photoelectron angular distribution ({\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}) at a given \((\epsilon,t)\)
can then be determined by the squared projection of
\(\left|\Psi_f\right>\) onto a specific state
\(\left|\Psi_{+};\bf{k}\right>\); very generally this can be written in terms of the energy and angle\sphinxhyphen{}resolved observable, which arises as the coherent square:
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:matE-sq-general}
\begin{split}
I(\epsilon,\theta,\phi)=\left<\Psi_f|\Psi_{+};\mathbf{k}\right>\left<\Psi_{+};\mathbf{k}|\Psi_f\right>
\end{split}
\end{equation}
\sphinxAtStartPar
Expansion in terms of the components of the matrix elements as detailed above then yields a separation into radial and angular components (see \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}, Sect. 2.1 for a full derivation), which can be written (at a single energy) as (following Eq. 2.45 of \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}):
\begin{equation}\label{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1}
\begin{split}
I(\theta,\phi;\,k)=\sum_{ll'}\sum_{\lambda\lambda'}\sum_{mm'}\gamma_{\alpha\alpha_{+}l\lambda ml'\lambda'm'}\boldsymbol{r}_{kl\lambda}\boldsymbol{r}_{kl'\lambda'}e^{i(\eta_{l\lambda}(k)-\eta_{l'\lambda'}(k))}Y_{lm}(\hat{k})Y_{l'm'}^{*}(\hat{k})
\end{split}
\end{equation}
\sphinxAtStartPar
In this form \(\alpha\) denotes all other quantum numbers required to define the initial state, and \(\alpha_{+}\) the final state of the molecular ion. The {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} \(\boldsymbol{r}_{kl\lambda}\), denote an integral over the radial part of the wavefunctions, in this case labelled by the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} quantum numbers, and the associated scattering phase is given by \(\eta_{l\lambda}(k)\) (i.e. the matrix elements are written in magnitude\sphinxhyphen{}phase form, rather than complex form). The \(\gamma\) term denotes a general set of {\hyperref[\detokenize{backmatter/glossary:term-geometric-coupling-parameters}]{\sphinxtermref{\DUrole{xref,std,std-term}{geometric coupling parameters}}}} arising from the coherent square. A tensor form is also given herein, see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}}, and includes a full breakdown of these terms and details of numerical implementations.

\sphinxAtStartPar
Comparison of Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1} with Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general} indicates that the amplitudes
in Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam} also determine the observable {\hyperref[\detokenize{backmatter/glossary:term-anisotropy-paramters}]{\sphinxtermref{\DUrole{xref,std,std-term}{anisotropy paramters}}}} \(\beta_{L,M}(\epsilon,t)\) (Eq.
\eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}), which basically collect all the terms in Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1} and the product over spherical harmonics, into a resultant set of \((L,M)\) parameters which describe the observable {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}. (Note that the photoelectron energy
\(\epsilon\) and momentum \(k\) are used somewhat interchangeably herein,
with the former usually preferred in reference to observables.) Further discussion of the observables, including computation and form of these observables, can be found in \hyperref[\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}}}.

\sphinxAtStartPar
The radial matrix elements \sphinxhyphen{} hence observables \sphinxhyphen{} are
a sensitive function of molecular geometry and electronic configuration
in general, as they depend on the overlap of the initial and final state wavefunctions, which includes the ionization continuum (scattering wavefunction) of the photoelectron.
Hence, they may be considered to be responsive to molecular
dynamics as well as photoionization dynamics, although they are formally time\sphinxhyphen{}independent in a
Born\sphinxhyphen{}Oppenheimer basis. For further general discussion and examples see
Ref. {[}\hyperlink{cite.backmatter/bibliography:id974}{85}{]} and \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}; discussions of more
complex cases with electronic and nuclear dynamics can be found in Refs.
{[}\hyperlink{cite.backmatter/bibliography:id883}{81}, \hyperlink{cite.backmatter/bibliography:id512}{86}, \hyperlink{cite.backmatter/bibliography:id910}{87}, \hyperlink{cite.backmatter/bibliography:id907}{88}{]}.

\sphinxAtStartPar
Note, also, that in the treatment above there is no time\sphinxhyphen{}dependence
incorporated in the notation; however, a time\sphinxhyphen{}dependent treatment
readily follows, and may be incorporated either as explicit
time\sphinxhyphen{}dependent modulations in the expansion of the wavefunctions for a
given case, or implicitly in the radial matrix elements. Examples of the
former include, e.g. a rotational or vibrational wavepacket, or a
time\sphinxhyphen{}dependent laser field. The rotational wavepacket case is discussed
herein (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}}).

\sphinxAtStartPar
Typically, for reconstruction experiments, a given measurement will be
selected to simplify this as much as possible by, e.g., populating only
a single ionic state (or states for which the corresponding observables
are experimentally energetically\sphinxhyphen{}resolvable), and with a bandwidth
\(d\bf{k}\) which is small enough such that the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} can be
assumed constant over the observation window. Importantly, the angle\sphinxhyphen{}resolved observables are
sensitive to the magnitudes and (relative) phases of these {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} \sphinxhyphen{} as emphasised in the magnitude\sphinxhyphen{}phase form of Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1} \sphinxhyphen{} and can be considered as angular interferograms. It is the interferometric nature of the {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} which enables a phase\sphinxhyphen{}sensitive reconstruction protocol to be pursued.

\sphinxstepscope


\section{Symmetry in photoionization}
\label{\detokenize{part1/theory_symmetry_140723:symmetry-in-photoionization}}\label{\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}}\label{\detokenize{part1/theory_symmetry_140723::doc}}
\sphinxAtStartPar
Symmetry in photoionization is discussed in detail in \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]} (Sect. 2.2.3.3). Herein a brief review is given, with a focus on using symmetry in matrix element retrieval problems. For further details, see \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}; for a more general discussion of symmetry in molecular spectroscopy see the textbook by  Bunker and Jensen {[}\hyperlink{cite.backmatter/bibliography:id548}{89}{]}, and the specific case of photoionization is expanded on in the work of Signorell and Merkt {[}\hyperlink{cite.backmatter/bibliography:id889}{90}{]}. (For application to symmetrized harmonics see \hyperref[\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}}}.)

\sphinxAtStartPar
In general, for the dipole matrix element to be non\sphinxhyphen{}zero the direct product of the initial state, final state and dipole operator symmetries must contain the totally symmetric representation of the molecular symmetry ({\hyperref[\detokenize{backmatter/glossary:term-MS}]{\sphinxtermref{\DUrole{xref,std,std-term}{MS}}}}) group, which is isomorphic to the point group ({\hyperref[\detokenize{backmatter/glossary:term-PG}]{\sphinxtermref{\DUrole{xref,std,std-term}{PG}}}}) in rigid molecules. This general case can be written as:
\begin{equation}\label{equation:part1/theory_symmetry_140723:eq:rovib-selection-symm}
\begin{split}
\Gamma_{rve}^{f}\otimes\Gamma_{dipole}\otimes\Gamma_{rve}^{i}\supset\Gamma^{s}
\end{split}
\end{equation}
\sphinxAtStartPar
Where \(\Gamma_{rve}\) is the rovibronic symmetry of the system (i.e. total symmetry excluding spin), with the \(i/f\) superscript denoting
initial and final states respectively. \(\Gamma^{s}\) is the totally symmetric representation in the appropriate molecular symmetry group,
and \(\Gamma_{dipole}\) is the symmetry of the dipole operator.

\sphinxAtStartPar
For the specific case of photoionization the final state is split into the symmetry species of the ion and the photoelectron {[}\hyperlink{cite.backmatter/bibliography:id889}{90}{]}:
\begin{equation}\label{equation:part1/theory_symmetry_140723:eq:ionization-symm}
\begin{split}
\Gamma^{e}\otimes\Gamma_{rve}^{+}\otimes\Gamma_{dipole}\otimes\Gamma_{rve}^{i}\supset\Gamma^{s}
\end{split}
\end{equation}
\sphinxAtStartPar
This is, essentially, a statement of the limiting case of Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:matE-dipole} (see also alternative forms of Eqs. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}, \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam-integral}), which defines the symmetry requirements for the overlap integral to be non\sphinxhyphen{}zero (although does not indicate that it will be non\sphinxhyphen{}zero for a given system).

\sphinxAtStartPar
In the reconstruction experiments discussed herein, this general form can be often be further simplified. In particular, assuming a full Born\sphinxhyphen{}Oppenheimer separation of dynamics, the problem can be treated within the static {\hyperref[\detokenize{backmatter/glossary:term-PG}]{\sphinxtermref{\DUrole{xref,std,std-term}{PG}}}} of the system, and only the electronic state symmetries need to be taken into account. In practice, this treatment is appropriate for cases with separable rotational wavepackets, and may also be a reasonable approximation for cases with vibronic wavepackets in cases where the nuclear excursions are relatively small and/or can be treated as linear combinations over a set of symmetrized basis functions. Within this approximation the general symmetry requirements can be written as:
\begin{equation}\label{equation:part1/theory_symmetry_140723:eq:ionization-symm-electronic}
\begin{split}
\Gamma^{e(X)}\otimes\Gamma_{e}^{+}\otimes\Gamma_{dipole}\otimes\Gamma_{e}^{i}\supset\Gamma^{s}
\end{split}
\end{equation}
\sphinxAtStartPar
And \(\Gamma^{e(X)}\) indicates that the continuum symmetries are expressed in a basis of symmetrized harmonics (\hyperref[\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}}}). From Eq. \eqref{equation:part1/theory_symmetry_140723:eq:ionization-symm-electronic}, the set of allowed matrix elements for a given ionization event can be expressed, in terms of the allowed set of symmetrized harmonics \(X_{hl}^{\Gamma\mu*}(\theta,\phi)\), or (equivalently) the usual partial wave basis expressed in spherical harmonics \(Y_{l,\lambda}(\theta,\phi)\), and a set of associated symmetrization coefficients \(b_{hl\lambda}^{\Gamma\mu}\).

\sphinxAtStartPar
A brief numerical example is given below, and a more detailed treatment for a range of photoionization cases forms the second half of the book, see \hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{Chapter \ref{\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}}} for details.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Example following symmetrized harmonics demo}

\PYG{c+c1}{\PYGZsh{} Import class}
\PYG{k+kn}{from} \PYG{n+nn}{pemtk}\PYG{n+nn}{.}\PYG{n+nn}{sym}\PYG{n+nn}{.}\PYG{n+nn}{symHarm} \PYG{k+kn}{import} \PYG{n}{symHarm}

\PYG{c+c1}{\PYGZsh{} Compute hamronics for Td, lmax=4}
\PYG{n}{sym} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D2h}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{lmax}\PYG{o}{=}\PYG{l+m+mi}{4}

\PYG{n}{symObj} \PYG{o}{=} \PYG{n}{symHarm}\PYG{p}{(}\PYG{n}{sym}\PYG{p}{,}\PYG{n}{lmax}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Allowed terms and mappings are given in \PYGZsq{}dipoleSyms\PYGZsq{}}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{dipole}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dipoleSyms}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Mapping coeffs to ePSproc dataType = matE
Remapped dims: \PYGZob{}\PYGZsq{}C\PYGZsq{}: \PYGZsq{}Cont\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}: \PYGZsq{}it\PYGZsq{}\PYGZcb{}
Added dim Eke
Added dim Targ
Added dim Total
Added dim mu
Added dim Type
Found dipole symmetries: 
\PYGZob{}\PYGZsq{}B1u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [0], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}z\PYGZsq{}]\PYGZcb{}, \PYGZsq{}B2u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [\PYGZhy{}1, 1], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}y\PYGZsq{}]\PYGZcb{}, \PYGZsq{}B3u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [\PYGZhy{}1, 1], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}x\PYGZsq{}]\PYGZcb{}\PYGZcb{}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZob{}\PYGZsq{}B1u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [0], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}z\PYGZsq{}]\PYGZcb{},
 \PYGZsq{}B2u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [\PYGZhy{}1, 1], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}y\PYGZsq{}]\PYGZcb{},
 \PYGZsq{}B3u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [\PYGZhy{}1, 1], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}x\PYGZsq{}]\PYGZcb{}\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Setting the symmetry for the neutral and ion allows direct products to be computed, }
\PYG{c+c1}{\PYGZsh{} and allowed terms to be determined.}

\PYG{n}{sNeutral} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A1g}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{sIon} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{B2u}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{directProductContinuum}\PYG{p}{(}\PYG{p}{[}\PYG{n}{sNeutral}\PYG{p}{,} \PYG{n}{sIon}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Results are pushed to self.continuum, in dictionary and Pandas DataFrame formats, }
\PYG{c+c1}{\PYGZsh{} and can be manipulated using standard functionality.}
\PYG{c+c1}{\PYGZsh{} The subset of allowed values are also set to a separate DataFrame and list.}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{continuum}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{allowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{PD}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}pandas.io.formats.style.Styler at 0x7f3364d96d40\PYGZgt{}
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\begin{tabular}{lllllll}
\toprule
    &     & allowed &        m &  pol & result &       terms \\
Dipole & Target &         &          &      &        &             \\
\midrule
B1u & B3g &    True &      [0] &  [z] &  [A1g] &  [A1g, B2u] \\
B2u & A1g &    True &  [-1, 1] &  [y] &  [A1g] &  [A1g, B2u] \\
B3u & B1g &    True &  [-1, 1] &  [x] &  [A1g] &  [A1g, B2u] \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Ylm basis table with the Character values limited to those defined }
\PYG{c+c1}{\PYGZsh{} in self.continuum[\PYGZsq{}allowed\PYGZsq{}][\PYGZsq{}PD\PYGZsq{}] Target column}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{n}{symFilter} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllllllll}
\toprule
    &   &   & {} & \multicolumn{5}{l}{b} \\
    &   &   & l &    0 & 1 &    2 & 3 &    4 \\
Character (\$\textbackslash Gamma\$) & SALC (h) & PFIX (\$\textbackslash mu\$) & m &      &   &      &   &      \\
\midrule
A1g & 0 & 0 &  0 &  1.0 &   &      &   &      \\
    & 1 & 0 &  0 &      &   &  1.0 &   &      \\
    & 2 & 0 &  2 &      &   &  1.0 &   &      \\
    & 3 & 0 &  0 &      &   &      &   &  1.0 \\
    & 4 & 0 &  2 &      &   &      &   &  1.0 \\
    & 5 & 0 &  4 &      &   &      &   &  1.0 \\
B1g & 0 & 0 & -2 &      &   &  1.0 &   &      \\
    & 1 & 0 & -4 &      &   &      &   &  1.0 \\
    & 2 & 0 & -2 &      &   &      &   &  1.0 \\
B3g & 0 & 0 & -1 &      &   &  1.0 &   &      \\
    & 1 & 0 & -3 &      &   &      &   &  1.0 \\
    & 2 & 0 & -1 &      &   &      &   &  1.0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxstepscope


\section{Tensor formulation of photoionization}
\label{\detokenize{part1/theory_tensor_formalism_160723:tensor-formulation-of-photoionization}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}\label{\detokenize{part1/theory_tensor_formalism_160723::doc}}
\sphinxAtStartPar
A number of authors have treated {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} and related problems in the context of photoionization theory and matrix element reconstruction (see \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} Chpt. 8 for examples and discussion, a range of review articles can also be found in the literature, e.g. Refs. {[}\hyperlink{cite.backmatter/bibliography:id524}{91}, \hyperlink{cite.backmatter/bibliography:id842}{92}, \hyperlink{cite.backmatter/bibliography:id724}{93}, \hyperlink{cite.backmatter/bibliography:id725}{94}{]}); herein, a geometric tensor based formalism is developed, which is close in spirit to the treatments given by Underwood and co\sphinxhyphen{}workers {[}\hyperlink{cite.backmatter/bibliography:id907}{88}, \hyperlink{cite.backmatter/bibliography:id841}{95}, \hyperlink{cite.backmatter/bibliography:id937}{96}{]}, but further separates various sets of physical parameters into dedicated tensors; this allows for a unified theoretical and numerical treatment, where the latter computes properties as tensor variables which can be further manipulated and investigated to give detailed insights into various aspects of photoionization for the system at hand, and implications/effects for matrix element retrieval in a given case. Furthermore, the tensors can readily be converted to a density matrix representation {[}\hyperlink{cite.backmatter/bibliography:id990}{83}, \hyperlink{cite.backmatter/bibliography:id535}{97}{]}, which is more natural for some quantities, and also emphasizes the link to quantum state tomography and other quantum information techniques. Much of the theoretical background, as well as application to aspects of the current problem, can be found in the textbooks of Blum {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]} and Zare {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]}.

\sphinxAtStartPar
Within this treatment, the observables can be defined in a series of simplified forms, emphasizing the quantities of interest for a given problem. The most general, and simplest, form is given in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-channel-funcs}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-channel-funcs}}}, in terms of {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}, and the remainder of this section (\hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}} \sphinxhyphen{} \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}]{Section \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}}}) gives a detailed breakdown of the various components of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}, and numerical examples.


\subsection{Channel functions}
\label{\detokenize{part1/theory_tensor_formalism_160723:channel-functions}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-channel-funcs}}
\sphinxAtStartPar
A simple form of the equations%
\begin{footnote}[1]\sphinxAtStartFootnote
Cf. the general form of Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1}. See also \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} Chpt. 12 for early discussion and motivation for this formalism.
%
\end{footnote}, amenable to fitting and numerical implementation, is to write the observables in terms of {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}, which define the ionization continuum for a given case and set of parameters \(u\) (e.g. defined for the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}, or defined for a specific experimental configuration),
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}
\begin{split}\beta_{L,M}^{u}=\sum_{\zeta,\zeta'}\varUpsilon_{L,M}^{u,\zeta\zeta'}\mathbb{I}^{\zeta\zeta'}\end{split}
\end{equation}
\sphinxAtStartPar
Where \(\zeta,\zeta'\) collect all the required quantum numbers, and
define all (coherent) pairs of components. The term
\(\mathbb{I}^{\zeta\zeta'}\) denotes the coherent square of the ionization
matrix elements:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta}
\begin{split}\mathbb{I}^{\zeta,\zeta}=I^{\zeta}(\epsilon)I^{\zeta'*}(\epsilon)
\end{split}
\end{equation}
\sphinxAtStartPar
Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns} is effectively a convolution equation (cf. Refs. {[}\hyperlink{cite.backmatter/bibliography:id841}{95}, \hyperlink{cite.backmatter/bibliography:id636}{98}{]}) with channel functions \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\), for a given “experiment” \(u\), summed over all terms \(\zeta,\zeta'\). Aside from the change in notation (which is here chosen to match the formalism of Refs. {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}{]}),
these matrix elements are essentially identical to the simplified {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}
\(\mathbf{r}_{k,l,m}\) defined in Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}, in the case where \(\zeta=\{k,l,m\}\). Similarly, the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} are essentially nothing but a slightly different form of the {\hyperref[\detokenize{backmatter/glossary:term-geometric-coupling-parameters}]{\sphinxtermref{\DUrole{xref,std,std-term}{geometric coupling parameters}}}} of Eqs. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}, \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1}, incorporating all required geometric parameters.
Note, also, that the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} used herein are usually assumed to be symmetrized (unless explicitly stated), i.e. expanded in {\hyperref[\detokenize{backmatter/glossary:term-symmetrized-harmonics}]{\sphinxtermref{\DUrole{xref,std,std-term}{symmetrized harmonics}}}} per Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:symHarm-defn}, but with any additional symmetry parameters \(b_{hl\lambda}^{\Gamma\mu}\) incorporated into the value of the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}.

\sphinxAtStartPar
These complex matrix elements can also be equivalently defined in a magnitude, phase
form:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta-mag-phase}
\begin{split}I^{\zeta}(\epsilon)\equiv\mathbf{r}_{\zeta}\equiv r_{\zeta}e^{i\phi_{\zeta}}\end{split}
\end{equation}
\sphinxAtStartPar
This tensorial form is numerically implemented in the \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]} codebase, and is in contradistinction to standard numerical routines in which the requisite terms are usually computed from vectorial and/or nested summations. The \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} codebase implements {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval based on the tensor formalism, with pre\sphinxhyphen{}computation of all the geometric tensor components ({\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}) prior to a fitting protocol for matrix element analysis, essentially a fit to Eqn. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}, with terms \(I^{\zeta}(\epsilon)\) as the unknowns (in magnitude, phase form per Eqn. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta-mag-phase}). The main computational cost of a tensor\sphinxhyphen{}based approach is that more RAM is required to store the full set of tensor variables; however, the method is computationally efficient since it is inherently parallel (as compared to a traditional, serial loop\sphinxhyphen{}based solution), hence may lead to significantly faster evaluation of observables. Furthermore, the method allows for the computational routines to match the formalism quite closely, and for the investigation of the properties of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} for a given problem in general terms, as well as for specific experimental cases including examination of specific couplings/effects. (Again, this is in contrast to standard nested\sphinxhyphen{}loop routines, which can be somewhat opaque to detailed interpretation, and typically implement the full computation of the observables in one monolithic computational routine; they do, however, have significantly lower RAM requirements since the full multi\sphinxhyphen{}dimensional basis tensors are not required to be stored.) \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}} provides details of the tensor components of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}, and the remainder of this section breaks these down further, including numerical examples, and discussion of their significance for fitting problems in specific cases.


\subsection{Full tensor expansion}
\label{\detokenize{part1/theory_tensor_formalism_160723:full-tensor-expansion}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}
\sphinxAtStartPar
In more detail, the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\) can be given as a set of tensors, defining each aspect of the problem. The following equations illustrate this for the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} and {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} cases, fully expanding the general form of Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns} in terms of the relevant tensors. Further details and numerical examples are given in the following sub\sphinxhyphen{}sections.

\sphinxAtStartPar
For the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:BLM-tensor-MF}
\begin{split}\begin{aligned}
\beta_{L,-M}^{\mu_{i},\mu_{f}}(\epsilon) & = & (-1)^{M}\sum_{P,R',R}{[P]^{\frac{1}{2}}}{E_{P-R}(\hat{e};\mu_{0})}\\
 & \times &\sum_{l,m,\mu}\sum_{l',m',\mu'}(-1)^{(\mu'-\mu_{0})}{\Lambda_{R',R}(R_{\hat{n}};\mu,P,R,R')B_{L,-M}(l,l',m,m')}\\
 & \times & I_{l,m,\mu}^{p_{i}\mu_{i},p_{f}\mu_{f}}(\epsilon)I_{l',m',\mu'}^{p_{i}\mu_{i},p_{f}\mu_{f}*}(\epsilon)\end{aligned}\end{split}
\end{equation}
\sphinxAtStartPar
And the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} as:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:BLM-tensor-AF}
\begin{split}\begin{aligned}
\bar{\beta}_{L,-M}^{\mu_{i},\mu_{f}}(\epsilon,t) & = & (-1)^{M}\sum_{P,R',R}{[P]^{\frac{1}{2}}}{E_{P-R}(\hat{e};\mu_{0})}\\
 & \times &\sum_{l,m,\mu}\sum_{l',m',\mu'}(-1)^{(\mu'-\mu_{0})}{\bar{\Lambda}_{R'}(\mu,P,R')B_{L,S-R'}(l,l',m,m')}\\
 & \times &I_{l,m,\mu}^{p_{i}\mu_{i},p_{f}\mu_{f}}(\epsilon)I_{l',m',\mu'}^{p_{i}\mu_{i},p_{f}\mu_{f}*}(\epsilon)\sum_{K,Q,S}\Delta_{L,M}(K,Q,S)A_{Q,S}^{K}(t)\end{aligned}\end{split}
\end{equation}
\sphinxAtStartPar
In both cases a set of geometric tensor terms are required, these terms provide details of:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({E_{P-R}(\hat{e};\mu_{0})}\): polarization geometry \& coupling with
the electric field.

\item {} 
\sphinxAtStartPar
\(B_{L,M}(l,l',m,m')\): geometric coupling of the partial waves into the \(\beta_{L,M}\) terms (spherical tensors). Note for the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} case the terms may be reindexed by \(M=S-R'\), which allows for the projection dependence on the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} (see below).

\item {} 
\sphinxAtStartPar
\(\Lambda_{R',R}(R_{\hat{n}};\mu,P,R,R')\), \(\bar{\Lambda}_{R'}(\mu,P,R')\): frame couplings and rotations (note slightly different terms for {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} and {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}).

\item {} 
\sphinxAtStartPar
\(\Delta_{L,M}(K,Q,S)\): alignment frame coupling ({\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} only).

\item {} 
\sphinxAtStartPar
\(A_{Q,S}^{K}(t)\): ensemble alignment described as a set of {\hyperref[\detokenize{backmatter/glossary:term-axis-distribution-moments}]{\sphinxtermref{\DUrole{xref,std,std-term}{axis distribution moments}}}} ({\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}, {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} only).  Note for a one\sphinxhyphen{}photon ionization case \sphinxhyphen{} the traditional {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} experiment \sphinxhyphen{} there will only be a single term, \(K=Q=S=0\), with no time\sphinxhyphen{}dependence, which describes an isotropic molecular ensemble. In general only the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} is discussed explicitly herein, but it is of note that this is identical to the traditional {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} definition for this limiting case of an isotropic ensemble.

\item {} 
\sphinxAtStartPar
Square\sphinxhyphen{}brackets are short\sphinxhyphen{}hand for degeneracy terms, e.g. \([P]^{\frac{1}{2}} = (2P+1)^{\frac{1}{2}}\).

\end{itemize}

\sphinxAtStartPar
Finally, \(I_{l,m,\mu}^{p_{i}\mu_{i},p_{f}\mu_{f}}(\epsilon)\) are the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, as a function of energy \(\epsilon\).
As noted above, these {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} are essentially identical to the simplified forms
\(r_{k,l,m}\) defined in Eqn. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}, except now with additional indices to label
symmetry and polarization components defined by a set of {\hyperref[\detokenize{backmatter/glossary:term-partial-waves}]{\sphinxtermref{\DUrole{xref,std,std-term}{partial\sphinxhyphen{}waves}}}}
\(\{l,m\}\), for polarization component \(\mu\) (denoting the photon angular
momentum components) and channels (symmetries) labelled by initial and
final state indexes \((p_{i}\mu_{i},p_{f}\mu_{f})\). The notation here
follows that used by \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]}, and these matrix elements again represent the quantities to be obtained numerically from data analysis, or from an \sphinxhref{https://epsproc.readthedocs.io/en/latest/ePS\_ePSproc\_tutorial/ePS\_tutorial\_080520.html\#Theoretical-background}{ePolyScat (or similar) calculation}.

\sphinxAtStartPar
Following the tensor components detailed above, the full form of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} of Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns} for the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} can be written as:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-MF-defn}
\begin{split}
\begin{aligned}
\varUpsilon_{L,M}^{u,\zeta\zeta'} & = & (-1)^{M}{[P]^{\frac{1}{2}}}E_{P-R}(\hat{e};\mu_{0})(-1)^{(\mu'-\mu_{0})}\Lambda_{R',R}(R_{\hat{n}};\mu,P,R,R')\\
 & \times & B_{L,-M}(l,l',m,m')\end{aligned}
\end{split}
\end{equation}\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-AF-defn}
\begin{split}
\begin{aligned}
\bar{\varUpsilon_{}}_{L,M}^{u,\zeta\zeta'} & = & (-1)^{M}[P]^{\frac{1}{2}}E_{P-R}(\hat{e};\mu_{0})(-1)^{(\mu'-\mu_{0})}\bar{\Lambda}_{R'}(\mu,P,R')\\
 & \times & B_{L,S-R'}(l,l',m,m')\Delta_{L,M}(K,Q,S)A_{Q,S}^{K}(t)\end{aligned}
\end{split}
\end{equation}
\sphinxAtStartPar
Note that, in this case as given, time\sphinxhyphen{}dependence arises purely from the
\(A_{Q,S}^{K}(t)\) terms in the AF case, and the electric field term
currently describes only the photon angular momentum coupling, although
can in principle also describe time\sphinxhyphen{}dependent/shaped fields. Similarly,
a time\sphinxhyphen{}dependent initial state (e.g. a vibrational wavepacket) could
also describe a time\sphinxhyphen{}dependent MF case.

\sphinxAtStartPar
It should be emphasized, however, that the underlying physical
quantities are essentially identical in all the theoretical approaches,
with a set of coupled angular\sphinxhyphen{}momenta defining the {\hyperref[\detokenize{backmatter/glossary:term-geometric-coupling-parameters}]{\sphinxtermref{\DUrole{xref,std,std-term}{geometric coupling parameters}}}} part of
the photoionization problem, despite these differences in the details of
the theory and notation.

\sphinxAtStartPar
The various tensors defined above are implemented as functions in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]}, and further wrapped for fitting cases in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}. In the remainder of this section, numerical examples using these codes are illustrated and explored. Full computational details can be found in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, including \sphinxhref{https://epsproc.readthedocs.io/en/latest/methods/geometric\_method\_dev\_260220\_090420\_tidy.html}{extended discussion of each tensor} and complete function references in the \sphinxhref{https://epsproc.readthedocs.io/en/latest/modules/epsproc.geomFunc.geomCalc.html}{geomCalc submodule documentation}.


\subsection{Frame definitions}
\label{\detokenize{part1/theory_tensor_formalism_160723:frame-definitions}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}
\sphinxAtStartPar
A conceptual overview of the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} and relation to the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}, in the context of the bootstrap reconstruction protocol, can be found in \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}}. A more detailed definition is given in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}}}, as pertains to the use of angular momentum notation and projections. The figure shows the general use of angular momenta and associated projection terms in molecular spectroscopy as an aid to visualising the discussion in the following sections. Note, however, that some alternative notations are used in this volume, in particular specific projection terms may be used for certain physical quantities.

\sphinxAtStartPar
In simple cases, the frame definition for the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} is identical to that of the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}, since it is usually defined by the laser polarization, with the distinction that an aligned molecular ensemble is additionally present. For the limiting case of an isotropic distribution, the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} and (traditional) {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} are identical. However, in cases with non\sphinxhyphen{}linear laser polarization, and/or multiple pulses with different polarization vectors, the situation may be more complicated, and additional {\hyperref[\detokenize{backmatter/glossary:term-frame-rotation}]{\sphinxtermref{\DUrole{xref,std,std-term}{frame rotation}}}}(s) may be required (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}}} inset). In such cases the reference frame may be chosen as the final ionizing laser pulse polarization, or as a symmetry axis in the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}. For high degrees of (3D) alignment the AF may approach the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} in the ideal case, although will usually be limited by the symmetry of the system.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{axes_QNs_inc_rotations_QM1}.png}
\caption{Reference frame and angular momentum definitions for the Laboratory frame ({\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}) and Molecular frame ({\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}), using a general notation from molecular spectroscopy. In this case the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} shows an angular momentum vectors \(J\) and \(l\); \(J\) is usually used to define rotational (or sometimes total) angular momentum of the system, and \(l\) the electronic component. Projection terms onto the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} \(z\)\sphinxhyphen{}axis, \(M_J\) and \(m_l\) are also indicated. In the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} equivalent angular momentum terms are shown, with projections \(K\) and \(\lambda\) onto the molecular symmetry axis. The insert shows a {\hyperref[\detokenize{backmatter/glossary:term-frame-rotation}]{\sphinxtermref{\DUrole{xref,std,std-term}{frame rotation}}}} \((x,y,z)\leftarrow(x',y',z')\), defined by a set of {\hyperref[\detokenize{backmatter/glossary:term-Euler-angles}]{\sphinxtermref{\DUrole{xref,std,std-term}{Euler angles}}}} \(R_{\hat{n}}=\{\chi,\Theta,\Phi\}\), and illustrating the rotation of the \(z\)\sphinxhyphen{}axis (defined by the electric field vector \(E\)), and a spherical harmonic function in the \((x',y',z')\) frame. See also \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}}. Figure reproduced from \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}, Fig. 2.3 \sphinxhyphen{} note that some alternative notations are used in this volume.}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-frame-defns}}\end{figure}


\subsection{Numerical aside: symmetry\sphinxhyphen{}defined channel functions}
\label{\detokenize{part1/theory_tensor_formalism_160723:numerical-aside-symmetry-defined-channel-functions}}
\sphinxAtStartPar
In the following sub\sphinxhyphen{}sections, each component is defined in detail, including numerical examples. For illustration purposes, the numerical example uses a minimal set of assumptions, and is defined initially purely by symmetry, although further terms may be required for computation of some of the geometric terms and are discussed where required. A fuller discussion of symmetry considerations in photoionization can be found in \hyperref[\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}]{Sect.\@ \ref{\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}}}, and discussion of {\hyperref[\detokenize{backmatter/glossary:term-symmetrized-harmonics}]{\sphinxtermref{\DUrole{xref,std,std-term}{symmetrized harmonics}}}} in \hyperref[\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}}}.

\sphinxAtStartPar
For this example, the \(D_{2h}\) point group is used, representing a fairly general case of a planar asymmetric top system, e.g. ethylene (\(C_2H_4\)). Note that, in this case, the symmetrization coefficients (\(b_{hl\lambda}^{\Gamma\mu}\), see Eqn. \eqref{equation:part1/theory_observables_intro_100723:eq:symHarm-defn}) have the property that \(\mu=0\) only, and the \(h\) index is redundant, since it maps uniquely to \(l\) \sphinxhyphen{} see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:tab-d2hxlm}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:tab-d2hxlm}}} \sphinxhyphen{} so these indexes can be dropped. Note, also, the unfortunate convention that the label \(\mu\) is used for multiple indexes; to avoid ambiguity this term is remapped to \(\mu_X\) in the numerics below. However, in this case, since \(\mu\) can be dropped from the symmetrization coefficients, there is actually no ambiguity in later usage.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Full tabulations of the parameters available in HTML or notebook formats only.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Setup symmetry\PYGZhy{}defined matrix elements using PEMtk}

\PYG{c+c1}{\PYGZsh{} Import class}
\PYG{k+kn}{from} \PYG{n+nn}{pemtk}\PYG{n+nn}{.}\PYG{n+nn}{sym}\PYG{n+nn}{.}\PYG{n+nn}{symHarm} \PYG{k+kn}{import} \PYG{n}{symHarm}

\PYG{c+c1}{\PYGZsh{}*** Compute hamronics for Td, lmax=4}
\PYG{n}{sym} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D2h}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{lmax}\PYG{o}{=}\PYG{l+m+mi}{4}

\PYG{n}{lmaxPlot} \PYG{o}{=} \PYG{l+m+mi}{2}  \PYG{c+c1}{\PYGZsh{} Set lmaxPlot for subselection on plots later.}

\PYG{c+c1}{\PYGZsh{} Create symHarm object with given settings, }
\PYG{c+c1}{\PYGZsh{} this will also compute the symmetrized harmonics}
\PYG{n}{symObj} \PYG{o}{=} \PYG{n}{symHarm}\PYG{p}{(}\PYG{n}{sym}\PYG{p}{,}\PYG{n}{lmax}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Display results (real harmonics)}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{n}{setCols}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{h}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{}, dropLevels=\PYGZsq{}mu\PYGZsq{})}

\PYG{c+c1}{\PYGZsh{} Glue version for JupyterBook output}
\PYG{c+c1}{\PYGZsh{} As above, but with PD object return and glue.}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{D2hXlm}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{n}{setCols}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{h}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{returnPD}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{llllllllll}
\toprule
    &   &   & {} & \multicolumn{6}{l}{b} \\
    &   &   & h &    0 &    1 &    2 &    3 &    4 &    5 \\
Character (\$\textbackslash Gamma\$) & PFIX (\$\textbackslash mu\$) & l & m &      &      &      &      &      &      \\
\midrule
A1g & 0 & 0 &  0 &  1.0 &      &      &      &      &      \\
    &   & 2 &  0 &      &  1.0 &      &      &      &      \\
    &   &   &  2 &      &      &  1.0 &      &      &      \\
    &   & 4 &  0 &      &      &      &  1.0 &      &      \\
    &   &   &  2 &      &      &      &      &  1.0 &      \\
    &   &   &  4 &      &      &      &      &      &  1.0 \\
A1u & 0 & 3 & -2 &  1.0 &      &      &      &      &      \\
B1g & 0 & 2 & -2 &  1.0 &      &      &      &      &      \\
    &   & 4 & -4 &      &  1.0 &      &      &      &      \\
    &   &   & -2 &      &      &  1.0 &      &      &      \\
B1u & 0 & 1 &  0 &  1.0 &      &      &      &      &      \\
    &   & 3 &  0 &      &  1.0 &      &      &      &      \\
    &   &   &  2 &      &      &  1.0 &      &      &      \\
B2g & 0 & 2 &  1 &  1.0 &      &      &      &      &      \\
    &   & 4 &  1 &      &  1.0 &      &      &      &      \\
    &   &   &  3 &      &      &  1.0 &      &      &      \\
B2u & 0 & 1 & -1 &  1.0 &      &      &      &      &      \\
    &   & 3 & -3 &      &  1.0 &      &      &      &      \\
    &   &   & -1 &      &      &  1.0 &      &      &      \\
B3g & 0 & 2 & -1 &  1.0 &      &      &      &      &      \\
    &   & 4 & -3 &      &  1.0 &      &      &      &      \\
    &   &   & -1 &      &      &  1.0 &      &      &      \\
B3u & 0 & 1 &  1 &  1.0 &      &      &      &      &      \\
    &   & 3 &  1 &      &  1.0 &      &      &      &      \\
    &   &   &  3 &      &      &  1.0 &      &      &      \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Symmetrized harmonics coefficients (\(b_{hl\lambda}^{\Gamma\mu}\), see Eqn. \eqref{equation:part1/theory_observables_intro_100723:eq:symHarm-defn}) for \DUrole{pasted-text}{D2h} symmetry (\(l_{max}=\)\DUrole{pasted-text}{4}) generated with the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} wrapper for \sphinxhref{https://github.com/mcodev31/libmsym}{\sphinxcode{\sphinxupquote{libmsym}}} {[}\hyperlink{cite.backmatter/bibliography:id708}{64}, \hyperlink{cite.backmatter/bibliography:id709}{65}{]}. Note that, in this case, the coeffcients have the property that \(\mu=0\) only, and the \(h\) index is redundant (maps uniquely to \(l\)).}\label{\detokenize{part1/theory_tensor_formalism_160723:tab-d2hxlm}}\end{figure}

\sphinxAtStartPar
To compute basis tensors from these symmetry coefficients, they can be converted to the standard {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} format used in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} (see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-mapping-params}]{Sect.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-mapping-params}}} for further discussion of the numerical implementation), and used with the standard routines. These are demonstrated below, for two flavours \sphinxhyphen{} the base \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]} routine for computation of {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}, and the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} fitting routine which wraps this functionality. Note that all tensors are stored as \sphinxhref{https://docs.xarray.dev}{\sphinxcode{\sphinxupquote{Xarray}}} {[}\hyperlink{cite.backmatter/bibliography:id698}{53}, \hyperlink{cite.backmatter/bibliography:id975}{54}{]} objects, which allow for easy numerical manipulation, subselection etc.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Compute basis functions for given matrix elements using PEMtk fit class}
\PYG{c+c1}{\PYGZsh{} This illustration uses the symmetrized matrix elements set above}

\PYG{c+c1}{\PYGZsh{}*** To use ePSproc/PEMtk classes, }
\PYG{c+c1}{\PYGZsh{} these values can be converted to ePSproc BLM data type...}
\PYG{c+c1}{\PYGZsh{} Run conversion \PYGZhy{} the default is to set the coeffs to the \PYGZsq{}BLM\PYGZsq{} data type, }
\PYG{c+c1}{\PYGZsh{} additional dim mappings can also be set.}
\PYG{c+c1}{\PYGZsh{} Outputs are set to symObj.coeffs[dataType]}
\PYG{n}{dimMap} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cont}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{muX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{toePSproc}\PYG{p}{(}\PYG{n}{dimMap}\PYG{o}{=}\PYG{n}{dimMap}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run conversion with a different dimMap \PYGZam{} dataType}
\PYG{c+c1}{\PYGZsh{} Outputs are set to symObj.coeffs[dataType]}
\PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{toePSproc}\PYG{p}{(}\PYG{n}{dimMap} \PYG{o}{=} \PYG{n}{dimMap}\PYG{p}{,} \PYG{n}{dataType}\PYG{o}{=}\PYG{n}{dataType}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{}*** Setup class object}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pemtkFit}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set to new key in data class}
\PYG{n}{dataKey} \PYG{o}{=} \PYG{n}{sym}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}

\PYG{c+c1}{\PYGZsh{} Set data.data[dataKey][dataType] from cases set above}
\PYG{c+c1}{\PYGZsh{} This pushes the symmetrized coeffs computed above to the PEMtk fit class }
\PYG{c+c1}{\PYGZsh{} object for general use with PEMtk methods.}
\PYG{c+c1}{\PYGZsh{} Here set \PYGZsq{}matE\PYGZsq{} for use as matrix elements, and \PYGZsq{}BLM\PYGZsq{} for pad plotting routines.}
\PYG{k}{for} \PYG{n}{dataType} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} Select expansion in complex harmonics, and sum redundant dims}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]} \PYG{o}{=} \PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b (comp)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{h}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{muX}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)} 
    \PYG{c+c1}{\PYGZsh{} Propagate attrs}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{o}{.}\PYG{n}{attrs} \PYG{o}{=} \PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{o}{.}\PYG{n}{attrs}

\PYG{c+c1}{\PYGZsh{} Set data by key}
\PYG{c+c1}{\PYGZsh{} data.subKey is the default location used by the PEMtk routines}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{subKey} \PYG{o}{=} \PYG{n}{dataKey}


\PYG{c+c1}{\PYGZsh{}*** Compute basis function \PYGZhy{} two flavours}
\PYG{c+c1}{\PYGZsh{} Using PEMtk `afblmMatEfit` method }
\PYG{c+c1}{\PYGZsh{} \PYGZhy{} this only returns the product basis set as used for fitting}
\PYG{c+c1}{\PYGZsh{} See the docs for more details, https://pemtk.readthedocs.io}
\PYG{n}{phaseConvention}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S}\PYG{l+s+s1}{\PYGZsq{}}  \PYG{c+c1}{\PYGZsh{} For consistency in the method, explicitly set the}
                     \PYG{c+c1}{\PYGZsh{} phase convention used here (\PYGZsq{}S\PYGZsq{} = standard, \PYGZsq{}E\PYGZsq{} = ePS).}
\PYG{n}{BetaNormX}\PYG{p}{,} \PYG{n}{basisProduct} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{afblmMatEfit}\PYG{p}{(}\PYG{n}{selDims}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
                                            \PYG{n}{sqThres}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} 
                                            \PYG{n}{phaseConvention}\PYG{o}{=}\PYG{n}{phaseConvention}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Using ePSproc directly \PYGZhy{} this includes full basis return if specified}
\PYG{c+c1}{\PYGZsh{} See the docs for more details, https://epsproc.readthedocs.io}
\PYG{n}{BetaNormX2}\PYG{p}{,} \PYG{n}{basisFull} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{geomFunc}\PYG{o}{.}\PYG{n}{afblmXprod}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{data}\PYG{o}{.}\PYG{n}{subKey}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} 
                                               \PYG{n}{basisReturn} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Full}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                                               \PYG{n}{thres}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{selDims}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
                                               \PYG{n}{sqThres}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
                                               \PYG{n}{phaseConvention}\PYG{o}{=}\PYG{n}{phaseConvention}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The basis dictionary contains various numerical parameters, these are investigated below.}
\PYG{c+c1}{\PYGZsh{} See also the ePSproc docs at }
\PYG{c+c1}{\PYGZsh{} https://epsproc.readthedocs.io/en/latest/methods/geometric\PYGZus{}method\PYGZus{}dev\PYGZus{}260220\PYGZus{}090420\PYGZus{}tidy.html}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Product basis elements: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{basisProduct}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Full basis elements: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{basisFull}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Use full basis for following sections}
\PYG{n}{basis} \PYG{o}{=} \PYG{n}{basisFull}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Mapping coeffs to ePSproc dataType = BLM
Remapped dims: \PYGZob{}\PYGZsq{}C\PYGZsq{}: \PYGZsq{}Cont\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}: \PYGZsq{}muX\PYGZsq{}\PYGZcb{}
Added dim Eke
Added dim P
Added dim T
Added dim C
*** Mapping coeffs to ePSproc dataType = matE
Remapped dims: \PYGZob{}\PYGZsq{}C\PYGZsq{}: \PYGZsq{}Cont\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}: \PYGZsq{}muX\PYGZsq{}\PYGZcb{}
Added dim Eke
Added dim Targ
Added dim Total
Added dim mu
Added dim it
Added dim Type
Product basis elements: dict\PYGZus{}keys([\PYGZsq{}BLMtableResort\PYGZsq{}, \PYGZsq{}polProd\PYGZsq{}, \PYGZsq{}phaseConvention\PYGZsq{}, \PYGZsq{}BLMRenorm\PYGZsq{}])
Full basis elements: dict\PYGZus{}keys([\PYGZsq{}QNs\PYGZsq{}, \PYGZsq{}EPRX\PYGZsq{}, \PYGZsq{}lambdaTerm\PYGZsq{}, \PYGZsq{}BLMtable\PYGZsq{}, \PYGZsq{}BLMtableResort\PYGZsq{}, \PYGZsq{}AFterm\PYGZsq{}, \PYGZsq{}AKQS\PYGZsq{}, \PYGZsq{}polProd\PYGZsq{}, \PYGZsq{}phaseConvention\PYGZsq{}, \PYGZsq{}BLMRenorm\PYGZsq{}, \PYGZsq{}matEmult\PYGZsq{}])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Matrix element geometric coupling term \protect\(B_{L,M}\protect\)}
\label{\detokenize{part1/theory_tensor_formalism_160723:matrix-element-geometric-coupling-term-b-l-m}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-blm-term}}
\sphinxAtStartPar
The coupling of the {\hyperref[\detokenize{backmatter/glossary:term-partial-waves}]{\sphinxtermref{\DUrole{xref,std,std-term}{partial\sphinxhyphen{}waves}}}} as coherent pairs, \(|l,m\rangle\) and \(|l',m'\rangle\), into the observable set of \(\{L,M\}\) is defined by a tensor contraction with two 3j terms:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:basis-BLM-defn}
\begin{split}
B_{L,M}=(-1)^{m}\left(\frac{(2l+1)(2l'+1)(2L+1)}{4\pi}\right)^{1/2}\left(\begin{array}{ccc}
l & l' & L\\
0 & 0 & 0
\end{array}\right)\left(\begin{array}{ccc}
l & l' & L\\
-m & m' & M
\end{array}\right)
\end{split}
\end{equation}
\sphinxAtStartPar
Note that this term is equivalent, effectively, to a triple integral over spherical harmonics (e.g. Eq. 3.119 in Zare {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]}):
\begin{equation*}
\begin{split}
\begin{aligned}
\intop_{0}^{2\pi}\intop_{0}^{\pi}Y_{J_{3}M_{3}}(\theta,\phi)Y_{J_{2}M_{2}}(\theta,\phi)Y_{J_{1}M_{1}}(\theta,\phi)\sin\theta d\theta d\phi & = & \left(\frac{(2J_{1}+1)(2J_{2}+1)(2J_{3}+1)}{4\pi}\right)^{1/2}\\
 & \times & \left(\begin{array}{ccc}
J_{1} & J_{2} & J_{3}\\
0 & 0 & 0
\end{array}\right)\left(\begin{array}{ccc}
J_{1} & J_{2} & J_{3}\\
M_{1} & M_{2} & M_{3}
\end{array}\right)
\end{aligned}
\end{split}
\end{equation*}
\sphinxAtStartPar
And a similar term appears in the contraction over a pair of harmonics into a resultant harmonic (e.g. Eqs. C.21, C.22 in Blum {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}) \sphinxhyphen{} this is how the term arises in the derivation of the observables.
\begin{equation*}
\begin{split}
\begin{aligned}
Y_{J_{1}M_{1}}(\theta,\phi)Y_{J_{2}M_{2}}(\theta,\phi) & = & \sum_{J_{3}M_{3}}\left(\frac{(2J_{1}+1)(2J_{2}+1)(2J_{3}+1)}{4\pi}\right)^{1/2}\\
 & \times & \left(\begin{array}{ccc}
J_{1} & J_{2} & J_{3}\\
0 & 0 & 0
\end{array}\right)\left(\begin{array}{ccc}
J_{1} & J_{2} & J_{3}\\
M_{1} & M_{2} & M_{3}
\end{array}\right)Y_{J_{3}M_{3}}^{*}(\theta,\phi)
\end{aligned}
\end{split}
\end{equation*}
\sphinxAtStartPar
Note also some definitions use conjugate spherical harmonics, which can be converted as, e.g., Eq. C.21 in Blum {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}:
\label{equation:part1/theory_tensor_formalism_160723:6e8ffd84-d4f2-4a72-ba65-cb7b213e7464}\begin{equation}
\beta_{L,M}^{\mu_{i},\mu_{f}}Y_{LM}^{*}(\theta_{\hat{k}},\phi_{\hat{k}})=\beta_{L,-M}^{\mu_{i},\mu_{f}}(-1)^{M}Y_{L,-M}(\theta_{\hat{k}},\phi_{\hat{k}})\label{eq:sph-conj-conv}
\end{equation}
\sphinxAtStartPar
In the current \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} codebase, the relevant basis item can be inspected as below, in order to illustrate the sensitivity of different \((L,M)\) terms to the matrix element products. In many typical cases, however, this term is restricted to only \(M=0\) components overall by other geometric factors (see below).

\sphinxAtStartPar
The code cells below illustrate this for the current example case, and \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-blm-basis-d2h}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-blm-basis-d2h}}} offers a general summary. In general, this is a convenient way to visualize the selection rules into the observable: for instance, only terms \(l=l'\) and \(m=-m'\) contribute to the overall photoionization cross\sphinxhyphen{}section term (\(L=0, M=0\)), and the maximum observable \(L_{max}=2l_{max}\). However, since these terms are fairly simply followed algebraically in this case, via the rules inherent in the \(3j\) product (Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:basis-BLM-defn}), this is not particularly insightful (although useful pedagogically). These visualizations will become more useful when dealing with real sets of matrix elements, and specific polarization geometries, which will further modulate or restrict the \(B_{L,M}\) terms.

\sphinxAtStartPar
Numerically, various standard functions may be used to quickly gain deeper insight, for example min/max, averages etc. Such considerations may provide a quick sanity\sphinxhyphen{}check for a given case, and may prove useful when planning experiments to investigate particular aspects or channels of a given system. Other properties of the basis functions may also be interrogated numerically; for instance, correlation maps provide an alternative way to check which terms are strongly correlated or coupled, or will dominate a given aspect of the observable.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Tabulate basis}

\PYG{n}{basisKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMtableResort}\PYG{l+s+s1}{\PYGZsq{}}  \PYG{c+c1}{\PYGZsh{} Key for BLM basis set}

\PYG{c+c1}{\PYGZsh{} Reformat basis for display (optional)}
\PYG{n}{stackDims} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{M}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\PYG{n}{basisPlot} \PYG{o}{=} \PYG{n}{basis}\PYG{p}{[}\PYG{n}{basisKey}\PYG{p}{]}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZhy{}Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{M}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{(}\PYG{n}{stackDims}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Convert to Pandas, use ep.multiDimXrToPD as a general multi\PYGZhy{}dimensional restacker}
\PYG{n}{pd}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{multiDimXrToPD}\PYG{p}{(}\PYG{n}{basisPlot}\PYG{p}{,} \PYG{n}{colDims}\PYG{o}{=}\PYG{n}{stackDims}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Summarise properties and tabulate via Pandas Describe}
\PYG{n}{pd}\PYG{o}{.}\PYG{n}{describe}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Plot BLM terms for basis set \PYGZhy{} basic case}
\PYG{n}{basisKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMtableResort}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Basic plot}
\PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{basisPlot}\PYG{p}{,} \PYG{n}{xDim}\PYG{o}{=}\PYG{n}{stackDims}\PYG{p}{)}\PYG{p}{;}  \PYG{c+c1}{\PYGZsh{} Basic plot with all terms}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Plot BLM terms for basis set \PYGZhy{} plot with some additional figure formatting options}

\PYG{c+c1}{\PYGZsh{} Formatting options}
\PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{}B\PYGZus{}}\PYG{l+s+se}{\PYGZob{}\PYGZob{}}\PYG{l+s+s1}{L,M}\PYG{l+s+se}{\PYGZcb{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZdl{} terms for }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{sym}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{, lmax=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{lmaxPlot}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{titleDetails}\PYG{o}{=}\PYG{k+kc}{True}
\PYG{n}{labelRound} \PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{n}{catLegend}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{n}{labelCols} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} cmap = None for default.}
\PYG{c+c1}{\PYGZsh{} cmap = \PYGZsq{}vlag\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} lmPlot with various options}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{basisPlot}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{p}{(}\PYG{n}{basisPlot}\PYG{o}{.}\PYG{n}{l}\PYG{o}{\PYGZlt{}}\PYG{o}{=}\PYG{n}{lmaxPlot}\PYG{p}{)} 
                        \PYG{o}{\PYGZam{}} \PYG{p}{(}\PYG{n}{basisPlot}\PYG{o}{.}\PYG{n}{lp}\PYG{o}{\PYGZlt{}}\PYG{o}{=}\PYG{n}{lmaxPlot}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} 
                       \PYG{n}{xDim}\PYG{o}{=}\PYG{n}{stackDims}\PYG{p}{,} \PYG{n}{pType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                       \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{,} \PYG{n}{labelRound} \PYG{o}{=} \PYG{n}{labelRound}\PYG{p}{,} 
                       \PYG{n}{catLegend}\PYG{o}{=}\PYG{n}{catLegend}\PYG{p}{,} 
                       \PYG{n}{titleString}\PYG{o}{=}\PYG{n}{titleString}\PYG{p}{,} \PYG{n}{titleDetails}\PYG{o}{=}\PYG{n}{titleDetails}\PYG{p}{,} 
                       \PYG{n}{labelCols} \PYG{o}{=} \PYG{n}{labelCols}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{\PYGZsh{} Glue figure}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lmPlot\PYGZus{}BLM\PYGZus{}basis\PYGZus{}D2h}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{1a70c9da2b5175d1dafa3f01e0fcd8393d208c491421f863c9432dea5252a0da}.png}
\caption{Example \(B_{L,M}\) basis functions for \DUrole{pasted-text}{D2h} symmetry. Note figure is truncated to \(l_{max}=l'_{max}=\)\DUrole{pasted-text}{2} for clarity. The colour\sphinxhyphen{}map (top left) shows the (real) values of the allowed terms shown in the main panel of the figure. The key (middle left) indicates categorical colour\sphinxhyphen{}mapping for the \((l,l',m,m')\) terms corresponding to the left\sphinxhyphen{}hand side\sphinxhyphen{}panel of the main plot, which illustrates the quantum numbers for each row.}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-blm-basis-d2h}}\end{figure}


\subsection{Electric field geometric coupling term \protect\({E_{P,R}(\hat{e};\mu_{0})}\protect\)}
\label{\detokenize{part1/theory_tensor_formalism_160723:electric-field-geometric-coupling-term-e-p-r-hat-e-mu-0}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-epr-term}}
\sphinxAtStartPar
The coupling of two 1\sphinxhyphen{}photon terms (which arises in the square of the ionization matrix element as per Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1}) can be written as a tensor contraction:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:EPR-defn-1}
\begin{split}
E_{P,R}(\hat{e})=[e\otimes e^{*}]_{R}^{P}=[P]^{\frac{1}{2}}\sum_{p}(-1)^{R}\left(\begin{array}{ccc}
1 & 1 & P\\
p & R-p & -R
\end{array}\right)e_{p}e_{R-p}^{*}
\end{split}
\end{equation}
\sphinxAtStartPar
Where:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(e_{p}\) and \(e_{R-p}\) define the field strengths for the polarizations \(p\) and \(R-p\), which are coupled into the spherical tensor \(E_{PR}\);

\item {} 
\sphinxAtStartPar
square\sphinxhyphen{}brackets indicate degeneracy terms, e.g. \([P]^{\frac{1}{2}} = (2P+1)^{\frac{1}{2}}\);

\item {} 
\sphinxAtStartPar
in the literature {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} field projection terms are usually denoted \(p\) (as above) or \(\mu_0\) (used as a more general angular\sphinxhyphen{}momentum projection notation). For the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} case photon projection terms are usually denoted by \(q\) or \(\mu\).

\item {} 
\sphinxAtStartPar
The polarization vector or propagation direction is usually chosen to define the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} z\sphinxhyphen{}axis for linear or non\sphinxhyphen{}linearly polarized light respectively (see \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}} for the linear example), or defined relative to the molecular symmetry axis in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}. (See \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}} for further details.)

\item {} 
\sphinxAtStartPar
For a given case the polarization geometry may define a single projection term, or there may be multiple terms allowed. For instance, linearly polarized light is defined by \(\mu_0=0\) only, resulting in non\sphinxhyphen{}zero values for just the \(P=0,2\) terms in Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:EPR-defn-1}, i.e. product terms \(E_{0,0}, E_{2,0}\) are allowed. Non\sphinxhyphen{}linearly polarized light may contain all allowed components (\(\mu_0=-1,0,1\)). For the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} case, allowed components may be defined directly in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} or determined via a frame transformation from the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} \sphinxhyphen{} see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-lambda-term}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-lambda-term}}}.

\item {} 
\sphinxAtStartPar
Note this notation implicitly describes only the time\sphinxhyphen{}independent photon angular momentum coupling, but time\sphinxhyphen{}dependent/shaped laser fields can be readily incorporated by allowing for time\sphinxhyphen{}dependent fields \(e_{p}(t)\) (see, for instance, Ref. {[}\hyperlink{cite.backmatter/bibliography:id663}{99}{]}). (Support for this is planned in \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]}, as of v1.3.2 this is in the development and testing phase.)

\end{itemize}

\sphinxAtStartPar
To derive this result, one can start from a general spherical tensor direct product, e.g., Eq. 5.36 in Zare {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]}; for two first\sphinxhyphen{}rank tensors (e.g. electric field vectors) this contraction is given explicitly by Eq. 5.40 in Zare {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]}:
\label{equation:part1/theory_tensor_formalism_160723:6dc60947-4009-4d4d-aed1-50a242de2308}\begin{equation}
[A^{(1)}\otimes B^{(1)}]_{q}^{k}=\sum_{m}\langle1m,1q-m|kq\rangle A(1,m)B(1,q-m)
\end{equation}
\sphinxAtStartPar
This can be converted to \(3j\) form:
\label{equation:part1/theory_tensor_formalism_160723:f35649e5-0f1d-47c2-b12a-3ccf27ae0de4}\begin{equation}
[A^{(1)}\otimes B^{(1)}]_{q}^{k}=\sum_{m}(-1)^{q}[k]^{1/2}\left(\begin{array}{ccc}
1 & 1 & k\\
m & q-m & -q
\end{array}\right)A(1,m)B(1,q-m)
\end{equation}
\sphinxAtStartPar
And the appropriate E\sphinxhyphen{}field terms substituted in to arrive at equation Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:EPR-defn-1}.

\sphinxAtStartPar
As before, we can visualise these values with the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, as illustrated in the following code block, and corresponding output \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-epr-basis}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-epr-basis}}}.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** For illustration, recompute EPR term for default case.}
\PYG{n}{EPRX} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{geomCalc}\PYG{o}{.}\PYG{n}{EPR}\PYG{p}{(}\PYG{n}{form} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{xarray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set parameters to restack the Xarray into (L,M) pairs}
\PYG{n}{plotDimsRed} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{R\PYGZhy{}p}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\PYG{n}{xDim} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{PR}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{R}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}

\PYG{c+c1}{\PYGZsh{} Plot with ep.lmPlot(), real values}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{EPRX}\PYG{p}{,} \PYG{n}{plotDims}\PYG{o}{=}\PYG{n}{plotDimsRed}\PYG{p}{,} \PYG{n}{xDim}\PYG{o}{=}\PYG{n}{xDim}\PYG{p}{,} 
                     \PYG{n}{pType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                     \PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{}E\PYGZus{}}\PYG{l+s+se}{\PYGZob{}\PYGZob{}}\PYG{l+s+s1}{P,R}\PYG{l+s+se}{\PYGZcb{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZdl{} terms (all cases).}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                     \PYG{n}{labelCols} \PYG{o}{=} \PYG{n}{labelCols}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Alternative version summed over l,l\PYGZsq{},m}
\PYG{c+c1}{\PYGZsh{} *\PYGZus{}, gFig = ep.lmPlot(EPRX.unstack().sum([\PYGZsq{}l\PYGZsq{},\PYGZsq{}lp\PYGZsq{},\PYGZsq{}R\PYGZhy{}p\PYGZsq{}]), xDim=xDim, pType = \PYGZsq{}r\PYGZsq{})}

\PYG{c+c1}{\PYGZsh{} Glue figure}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{lmPlot\PYGZus{}EPR\PYGZus{}basis}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{80f09ffaf7bd2b91ed3143103d8f1aedc9b508eb9bad2ea77f7d2e5c6499e037}.png}
\caption{Example \(E_{P,R}\) basis functions. Note that for linearly polarised light \(p=R-p=0\) only, hence only the terms \(E_{0,0}\) and \(E_{2,0}\) are non\sphinxhyphen{}zero in this case. For non\sphinxhyphen{}linearly polarised cases many other terms are allowed. The colour\sphinxhyphen{}map (top left) shows the (real) values of the allowed terms shown in the main panel of the figure. The first key (middle left) indicates categorical colour\sphinxhyphen{}mapping for the \((l,l')\) terms (and \(l=l'=1\) only in this case), and the second (“Categories”) key indicates the colour\sphinxhyphen{}mapping for the remaining terms. The keys correspond to the left\sphinxhyphen{}hand side\sphinxhyphen{}panel of the main plot, which indicates the quantum numbers for each row.}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-epr-basis}}\end{figure}


\subsection{Molecular frame projection term \protect\(\Lambda\protect\)}
\label{\detokenize{part1/theory_tensor_formalism_160723:molecular-frame-projection-term-lambda}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-lambda-term}}
\sphinxAtStartPar
For the molecular frame case, the coupling between the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} can be defined by a projection term, \(\Lambda_{R',R}(R_{\hat{n}})\):
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:basis-lambda-MF-defn}
\begin{split}
\Lambda_{R',R}(R_{\hat{n}})=(-1)^{(R')}\left(\begin{array}{ccc}
1 & 1 & P\\
\mu & -\mu' & R'
\end{array}\right)D_{-R',-R}^{P}(R_{\hat{n}})
\end{split}
\end{equation}
\sphinxAtStartPar
This is similar to the \(E_{P,R}\) term, and essentially rotates it into the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}, defining the projections of the polarization vector (photon angular momentum) \(\mu\) into the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} for a given molecular orientation ({\hyperref[\detokenize{backmatter/glossary:term-frame-rotation}]{\sphinxtermref{\DUrole{xref,std,std-term}{frame rotation}}}}) defined by a set of rotations. The {\hyperref[\detokenize{backmatter/glossary:term-frame-rotation}]{\sphinxtermref{\DUrole{xref,std,std-term}{frame rotation}}}} is parameterized by a set of {\hyperref[\detokenize{backmatter/glossary:term-Euler-angles}]{\sphinxtermref{\DUrole{xref,std,std-term}{Euler angles}}}}, \(R_{\hat{n}}=\{\chi,\Theta,\Phi\}\), with projections given by {\hyperref[\detokenize{backmatter/glossary:term-Wigner-rotation-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{Wigner rotation matrix elements}}}} \(D_{-R',-R}^{P}(R_{\hat{n}})\).

\sphinxAtStartPar
For the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} case, the same term appears but in a simplified form:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:basis-lambda-LF-defn}
\begin{split}
\bar{\Lambda}_{R'}=(-1)^{(R')}\left(\begin{array}{ccc}
1 & 1 & P\\
\mu & -\mu' & R'
\end{array}\right)\equiv\Lambda_{R',R'}(R_{\hat{n}}=0)
\end{split}
\end{equation}
\sphinxAtStartPar
This form pertains since \sphinxhyphen{} in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} case \sphinxhyphen{} there is no specific frame transformation defined (i.e. there is no single molecular orientation defined in relation to the light polarization, rather a distribution as defined by the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}), but the total angular momentum coupling of the photon terms is still required in the equations.

\sphinxAtStartPar
Numerically, the function is calculated for a specified set of orientations, which default to the standard set of \((x,y,z)\) {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} polarization cases in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} routines. For the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} case, this term is still used, but restricted to \(R_{\hat{n}} = (0,0,0) = z\), i.e. no frame rotation relative to the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} \(E_{P,R}\) definition. In some cases additional frame transformations may be required here to define, e.g., the use of the propagation axis as the reference \(z\)\sphinxhyphen{}axis for circularly or elliptically polarized light. (See \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}} for further discussion.)


\subsection{Alignment tensor \protect\(\Delta_{L,M}(K,Q,S)\protect\)}
\label{\detokenize{part1/theory_tensor_formalism_160723:alignment-tensor-delta-l-m-k-q-s}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term}}
\sphinxAtStartPar
Finally, for the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} case, the alignment tensor couples the molecular axis ensemble (defined as a set of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}, see \hyperref[\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}]{Sect.\@ \ref{\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}}} for details) and the photoionization multipole terms into the final observable.
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:basis-alignmentTensor-defn}
\begin{split}
\Delta_{L,M}(K,Q,S)=(2K+1)^{1/2}(-1)^{K+Q}\left(\begin{array}{ccc}
P & K & L\\
R & -Q & -M
\end{array}\right)\left(\begin{array}{ccc}
P & K & L\\
R' & -S & S-R'
\end{array}\right)
\end{split}
\end{equation}
\sphinxAtStartPar
In the full equations for the observable, this term appears in a summation with the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}, as:
\begin{equation}\label{equation:part1/theory_tensor_formalism_160723:eq:basis-aligmentTerm-defn}
\begin{split}
\tilde{\Delta}_{L,M}(t) = \sum_{K,Q,S}\Delta_{L,M}(K,Q,S)A_{Q,S}^{K}(t)
\end{split}
\end{equation}
\sphinxAtStartPar
This summed alignment term can be considered, essentially, as a (coherent) geometric averaging of the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} observable weighted by the axis distribution in the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} (for more on the axis averaging as a convolution, see Refs. {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id937}{96}{]}); equivalently, the averaging can be considered as a purely angular\sphinxhyphen{}momentum coupling effect, which accounts for all contributing moments of the various aspects of the system, and defines the allowed projections onto the final observables in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}.

\sphinxAtStartPar
Mappings of these terms are investigated numerically below, for some examplar cases.


\subsubsection{Basic cases}
\label{\detokenize{part1/theory_tensor_formalism_160723:basic-cases}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term-basic}}
\sphinxAtStartPar
\hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-deltaterm000}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-deltaterm000}}} illustrates the alignment tensor \(\Delta_{L,M}(K,Q,S)\) for some basic cases, and values are also tabulated in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:tab-deltaterm000}]{Table \ref{\detokenize{part1/theory_tensor_formalism_160723:tab-deltaterm000}}}. Note that for illustration purposes the term is subselected with \(K=0\), \(Q=0\), \(S=0\) and \(R'=0\); \(R\neq0\) terms are included to illustrate the elliptically\sphinxhyphen{}polarized case, which can give rise to non\sphinxhyphen{}zero \(M\) terms.

\sphinxAtStartPar
For the simplest case of an unaligned ensemble, this term is restricted to \(K=Q=S=0\), i.e. \(\Delta_{L,M}(0,0,0)\); for single\sphinxhyphen{}photon ionization with linearly\sphinxhyphen{}polarized light (\(p=0\), hence \(P=0,2\) and \(R=R'=0\)), this has non\sphinxhyphen{}zero values for \(L=0,2\) and \(M=0\) only. Typically, this simplest case is synonymous with standard {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} results, and maintains cylindrical and up\sphinxhyphen{}down symmetry in the observable.

\sphinxAtStartPar
For circularly polarized light (\(p=\pm1\), hence \(P=0,1,2\) and \(R=R'=0\)), odd\sphinxhyphen{}\(L\) is allowed, signifying up/down symmetry breaking in the observable (where up/down pertains to the propagation direction of the light, conventionally the \(z\)\sphinxhyphen{}axis for non\sphinxhyphen{}linear polarizations, see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}}). For elliptically polarized light, mixing of terms with different \(p\) allows for non\sphinxhyphen{}zero \(R\) terms (see Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:EPR-defn-1}), hence non\sphinxhyphen{}zero \(M\) is allowed (see Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:basis-alignmentTensor-defn}), signifying breaking of cylindrical symmetry in the observable is allowed. Note, however, that non\sphinxhyphen{}zero values here do not indicate that such effects \sphinxstyleemphasis{will} be observed in any given case, only that they may be (or, at least, are not restricted by the alignment tensor).

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Set range of ADMs for test as time\PYGZhy{}dependent values (linear ramps)}

\PYG{c+c1}{\PYGZsh{} Set ADMs for increasing alignment...}
\PYG{c+c1}{\PYGZsh{} Note that delta term is independent of the absolute values of the ADMs(t), }
\PYG{c+c1}{\PYGZsh{} but does use this term to define limits on some quantum numbers.}

\PYG{n}{tPoints} \PYG{o}{=} \PYG{l+m+mi}{10}  \PYG{c+c1}{\PYGZsh{} 10 t\PYGZhy{}points}
\PYG{n}{inputADMs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
             \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} 
             \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
             \PYG{p}{[}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.3}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
             \PYG{p}{[}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.2}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Set to AKQS parameters in Xarray}
\PYG{n}{AKQS} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{setADMs}\PYG{p}{(}\PYG{n}{ADMs} \PYG{o}{=} \PYG{n}{inputADMs}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Use default EPR term \PYGZhy{} note this computes for all pol states, p=[\PYGZhy{}1,0,1]}
\PYG{n}{EPR} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{geomCalc}\PYG{o}{.}\PYG{n}{EPR}\PYG{p}{(}\PYG{n}{form}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{xarray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}*** Compute alignment terms}
\PYG{n}{AFterm}\PYG{p}{,} \PYG{n}{DeltaTerm} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{geomCalc}\PYG{o}{.}\PYG{n}{deltaLMKQS}\PYG{p}{(}\PYG{n}{EPR}\PYG{p}{,} \PYG{n}{AKQS}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}*** Plot Delta term with subselections and formatting}
\PYG{n}{xDim} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{M}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}
\PYG{n}{daPlot}\PYG{p}{,} \PYG{n}{daPlotpd}\PYG{p}{,} \PYG{n}{legendList}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}
                     \PYG{n}{DeltaTerm}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{K}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{Q}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{S}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{Rp}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZhy{}Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{,} 
                     \PYG{n}{xDim} \PYG{o}{=} \PYG{n}{xDim}\PYG{p}{,} 
                     \PYG{n}{pType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{squeeze} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{thres}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,}
                     \PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdl{}}\PYG{l+s+s2}{\PYGZbs{}}\PYG{l+s+s2}{Delta(0,0,0)\PYGZdl{} term (\PYGZdl{}R}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{=0\PYGZdl{} only)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
                     \PYG{c+c1}{\PYGZsh{} Set dim mapping to use P,R with \PYGZdq{}l,m\PYGZdq{} colourmap}
                     \PYG{n}{dimMaps}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lDims}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mDims}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{R}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,}  
                     \PYG{n}{labelCols}\PYG{o}{=}\PYG{n}{labelCols}\PYG{p}{,}
                     \PYG{n}{catLegend}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} Glue versions for JupyterBook output}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{deltaTerm000\PYGZhy{}lmPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} As above, but with PD object return and glue.}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{deltaTerm000\PYGZhy{}tab}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{daPlotpd}\PYG{o}{.}\PYG{n}{fillna}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{0b181a471caeb0bd22ab9abccc869734f8179274383cfca076619ea60d1d939b}.png}
\caption{Example \(\Delta_{L,M}(0,0,0)\) basis functions (see also \hyperref[\detokenize{part1/theory_tensor_formalism_160723:tab-deltaterm000}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:tab-deltaterm000}}}). For illustration purposes, the plot only shows terms for \(R'=0\). See main text for discussion.}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-deltaterm000}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{lllllllllll}
\toprule
  & L &    0 & \multicolumn{3}{l}{1} & \multicolumn{5}{l}{2} \\
  & M &    0 &     -1 &      0 &      1 &   -2 &   -1 &    0 &    1 &    2 \\
P & R &      &        &        &        &      &      &      &      &      \\
\midrule
0 &  0 &  1.0 &        &        &        &      &      &      &      &      \\
1 & -1 &      &        &        & -0.333 &      &      &      &      &      \\
  &  0 &      &        &  0.333 &        &      &      &      &      &      \\
  &  1 &      & -0.333 &        &        &      &      &      &      &      \\
2 & -2 &      &        &        &        &      &      &      &      &  0.2 \\
  & -1 &      &        &        &        &      &      &      & -0.2 &      \\
  &  0 &      &        &        &        &      &      &  0.2 &      &      \\
  &  1 &      &        &        &        &      & -0.2 &      &      &      \\
  &  2 &      &        &        &        &  0.2 &      &      &      &      \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Example \(\Delta_{L,M}(0,0,0)\) basis functions (see also \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-deltaterm000}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-deltaterm000}}}). For illustration purposes, the table only shows terms for \(R'=0\). See main text for discussion.}\label{\detokenize{part1/theory_tensor_formalism_160723:tab-deltaterm000}}\end{figure}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Plot ADMs}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{ADMFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{AKQS}\PYG{p}{,} \PYG{n}{xDim} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{pType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                       \PYG{n}{labelCols}\PYG{o}{=}\PYG{n}{labelCols}\PYG{p}{,} \PYG{n}{catLegend}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
                       \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{vlag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                       \PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADMs (linear ramp example)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 

\PYG{c+c1}{\PYGZsh{}*** Plot AF term with subselection}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{AFFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{AFterm}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{R}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{Rp}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZhy{}Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{,} 
                      \PYG{n}{xDim} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{pType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                      \PYG{n}{labelCols}\PYG{o}{=}\PYG{n}{labelCols}\PYG{p}{,}
                      \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{vlag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s+s1}{tilde}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{Delta\PYGZcb{}\PYGZus{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{L,M\PYGZcb{}(t)\PYGZdl{} (linear ramp example)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 

\PYG{c+c1}{\PYGZsh{} Glue versions for JupyterBook output}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ADMs\PYGZhy{}linearRamp\PYGZhy{}lmPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{ADMFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{AFterm\PYGZhy{}linearRamp\PYGZhy{}lmPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{AFFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{e733c81a0a4c2ffdd50b03a0d1150c8eb698f4519e234bb150e4b7851e03665a}.png}
\caption{Example ADMs used for {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} basis function example (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-afterm-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-afterm-linearramp}}}). These ADMs essentially show an increasing degree of alignment with the \(t\) parameter, with high\sphinxhyphen{}order terms increasing at later \(t\).}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{8843790fad916e8611979f751cab5841297c84af311c71dc77879741ba266b3a}.png}
\caption{Example of \(\tilde{\Delta}_{L,M}(t)\) basis values for various choices of alignment (as per \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}}}). The ADMs essentially show an increasing degree of alignment with the \(t\) parameter, with high\sphinxhyphen{}order terms increasing at later \(t\), and this is reflected in the \(\tilde{\Delta}_{L,M}(t)\) terms with higher\sphinxhyphen{}order \(L\) appearing at later \(t\).}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-afterm-linearramp}}\end{figure}

\sphinxAtStartPar
For cases with aligned molecular ensembles, additional terms can similarly appear depending on the alignment as well as the properties of the ionizing radiation. Again, the types of terms follow some typical patterns dependent on the symmetry of the ensemble, as well as the order of the terms allowed. For instance, \(L_{max}=P_{max}+K_{max}=2+K_{max}\), and \(K_{max}\) represents the overall degree of alignment of the ensemble; hence an aligned ensemble may be signified by higher\sphinxhyphen{}order terms in the observable (if allowed by other terms in the overall expansion) or, equivalently, aligning an ensemble prior to ionization can be used as a way to control which terms contribute to the alignment tensor.

\sphinxAtStartPar
Since this is a coherent averaging, additional interferences can also appear in the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} \sphinxhyphen{} or be restricted in the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} \sphinxhyphen{} depending on these geometric parameters and the contributing matrix elements. Additionally, any effects modulating these terms, for instance a time\sphinxhyphen{}dependent alignment (rotational wavepacket), vibronic dynamics (vibrational and/or electronic wavepacket), time\sphinxhyphen{}dependent laser field (control field) may be anticipated to lead to both changes in these terms and, potentially, interesting effects in the observable. Such effects have been discussed in more detail in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}, and in the current case the focus is purely on rotational wavepackets.

\sphinxAtStartPar
\hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-afterm-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-afterm-linearramp}}} shows \(\tilde{\Delta}_{L,M}(t)\) for various choices of alignment (as per the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} shown in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}}}), and illustrates some of the general features discussed. Note, for example:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(L_{max}\) varies with alignment; in the demonstration case \(K_{max}=8\) at later times, resulting in \(L_{max}=10\), whilst at \(t=0\) \(K_{max}=0\), thus restricting terms to \(L_{max}=2\).

\item {} 
\sphinxAtStartPar
Odd\sphinxhyphen{}\(L\) values are correlated with \(P=1\) terms.

\item {} 
\sphinxAtStartPar
Only \(M=0\) terms are allowed in this case (\(Q=S=0\)).

\end{itemize}


\subsubsection{3D alignments and symmetry breaking}
\label{\detokenize{part1/theory_tensor_formalism_160723:d-alignments-and-symmetry-breaking}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term-3d}}
\sphinxAtStartPar
As discussed above, for the case where \(Q\neq0\) and/or \(S\neq0\) additional symmetry breaking can occur. It is simple to examine these effects numerically via changing the trial {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} used to determine \(\tilde{\Delta}_{L,M}(t)\) (Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:basis-aligmentTerm-defn}), as illustrated in the following code block. (Realistic cases can be found in the case\sphinxhyphen{}studies presented in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}.)

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Set range of ADMs for test as time\PYGZhy{}dependent values (linear ramps), }
\PYG{c+c1}{\PYGZsh{}    including some trial \PYGZdq{}3D\PYGZdq{} alignment terms}

\PYG{c+c1}{\PYGZsh{} Set ADMs for increasing alignment...}
\PYG{c+c1}{\PYGZsh{} Here add some (arb) terms for Q,S non\PYGZhy{}zero (indexed as [K,Q,S, ADMs(t)])}
\PYG{n}{tPoints} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{n}{inputADMs3D} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} 
             \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} 
             \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
             \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
             \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.8}\PYG{p}{,}\PYG{n}{tPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Set to AKQS parameters in an Xarray}
\PYG{n}{AKQS} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{setADMs}\PYG{p}{(}\PYG{n}{ADMs} \PYG{o}{=} \PYG{n}{inputADMs3D}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute alignment terms}
\PYG{n}{AFterm}\PYG{p}{,} \PYG{n}{DeltaTerm} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{geomCalc}\PYG{o}{.}\PYG{n}{deltaLMKQS}\PYG{p}{(}\PYG{n}{EPR}\PYG{p}{,} \PYG{n}{AKQS}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}*** Plot subsection, L\PYGZlt{}=2, and sum over Rp and S\PYGZhy{}Rp terms}
\PYG{n}{titleString} \PYG{o}{=} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s+s1}{tilde}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{Delta\PYGZcb{}\PYGZus{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{L,M\PYGZcb{}(t)\PYGZdl{} (3D alignment ramp example).}\PYG{l+s+s1}{\PYGZsq{}}
               \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{ Summed over \PYGZdl{}R}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{} and \PYGZdl{}S\PYGZhy{}R}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{} terms.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{AFterm}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{AFterm}\PYG{o}{.}\PYG{n}{L}\PYG{o}{\PYGZlt{}}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZhy{}Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
                    \PYG{n}{xDim} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{pType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                    \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{vlag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                    \PYG{n}{titleString}\PYG{o}{=}\PYG{n}{titleString}\PYG{p}{)} 

\PYG{c+c1}{\PYGZsh{} Glue versions for JupyterBook output}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ADMs\PYGZhy{}3DlinearRamp\PYGZhy{}lmPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{88998ddaef4dbcb99470af20aea1b302feee88a3dcd9461cd502662b3abec19d}.png}
\caption{Example \(\tilde{\Delta}_{L,M}(t)\) basis values for various choices of “3D” alignment, i.e. including some \(K\neq0\) and \(S\neq0\) terms. Note, in particular, the presence of \(M\neq0\) terms in general, and a complicated dependence of the allowed terms on the alignment ({\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}), which may increase, decrease, or even change sign for a given \(L,M\).}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-adms-3dlinearramp}}\end{figure}

\sphinxAtStartPar
For illustration purposes, \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-adms-3dlinearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-adms-3dlinearramp}}} shows a subselection of the \(\tilde{\Delta}_{L,M}(t)\) basis values, indicating some of the key features in the full 3D case, subselected for \(L\leq2\) and summed over \(R'\) and \(S-R'\) terms. Note, in particular, the presence of \(M\neq0\) terms in general, and a complicated dependence of the allowed terms on the alignment, which may increase, decrease, or even change sign. As previously, these behaviours are generally useful for understanding specific cases or planning experiments for specific systems; this is explored further in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} which focuses on the results for particular molecules (hence symmetries and sets of matrix elements).


\subsection{Tensor product terms}
\label{\detokenize{part1/theory_tensor_formalism_160723:tensor-product-terms}}\label{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}}
\sphinxAtStartPar
Following the above, further resultant terms can also be examined, up to and including the full channel functions \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\) (see Eqn. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}) for a given case. Numerically these are all implemented in the main \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]}, and can be returned by these functions for inspection \sphinxhyphen{} the full basis set already defined includes some of these products. Custom tensor product terms are also readily computed with the codebase, with tensor multiplications handled natively by the \sphinxhref{https://docs.xarray.dev}{\sphinxcode{\sphinxupquote{Xarray}}} {[}\hyperlink{cite.backmatter/bibliography:id698}{53}, \hyperlink{cite.backmatter/bibliography:id975}{54}{]} data objects (for more details of the data structures used, see the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, specifically the \sphinxhref{https://epsproc.readthedocs.io/en/latest/dataStructures/ePSproc\_dataStructures\_demo\_070622.html}{data structures page}).

\sphinxAtStartPar
The main product basis returned, labelled \sphinxcode{\sphinxupquote{polProd}} in the output dictionary, contains the tensor product of the polarisation and alignment terms, \(\Lambda_{R}\otimes E_{PR}(\hat{e})\otimes \Delta_{L,M}(K,Q,S)\otimes A^{K}_{Q,S}(t)\), expanded over all quantum numbers (see \sphinxhref{https://epsproc.readthedocs.io/en/dev/methods/geometric\_method\_dev\_pt3\_AFBLM\_090620\_010920\_dev\_bk100920.html\#\%5Cbeta\_\%7BL,M\%7D\%5E\%7BAF\%7D-rewrite}{full definition here}). This term, therefore, incorporates all of the dependence (or response) of the AF\sphinxhyphen{}\(\beta_{LM}\)s on the polarisation state, and the axis distribution. Example results, making use of the linear\sphinxhyphen{}ramp {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} of \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term-basic}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term-basic}}} are illustrated in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-polprod-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-polprod-linearramp}}}.

\sphinxAtStartPar
The full channel (response) functions \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\) as defined in \eqref{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-MF-defn} and \eqref{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-AF-defn} can be determined by the product of this term with the \(B_{L,M}\) tensor. This is essentially the complete geometric basis set, hence equivalent to the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}\sphinxhyphen{}\(\beta_{LM}\) if the ionization matrix elements were set to unity. This illustrates not only the coupling of the geometric terms into the observable \(L,M\), but also how the partial wave \(|l,m\rangle\) terms map to the observables, and hence the sensitivity of the observables to given partial wave properties. Example results, making use of the linear\sphinxhyphen{}ramp {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} of \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term-basic}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term-basic}}} are illustrated in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-channelfunc-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-channelfunc-linearramp}}}.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set data \PYGZhy{} set example ADMs to data structure \PYGZam{} subset for calculation}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setADMs}\PYG{p}{(}\PYG{n}{ADMs} \PYG{o}{=} \PYG{n}{inputADMs}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Using PEMtk \PYGZhy{} this only returns the product basis set as used for fitting}
\PYG{n}{BetaNormX}\PYG{p}{,} \PYG{n}{basisProduct} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{afblmMatEfit}\PYG{p}{(}\PYG{n}{selDims}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{sqThres}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Subselected from dataset \PYGZsq{}ADM\PYGZsq{}, dataType \PYGZsq{}ADM\PYGZsq{}: 50 from 50 points (100.00\PYGZpc{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{basisKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{polProd}\PYG{l+s+s1}{\PYGZsq{}}  \PYG{c+c1}{\PYGZsh{} Key for BLM basis set}

\PYG{c+c1}{\PYGZsh{} Plot with subselection on pol state (by label, \PYGZsq{}A\PYGZsq{}=z\PYGZhy{}pol case)}
\PYG{n}{titleString}\PYG{o}{=}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{Polprod}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{ basis term, \PYGZdl{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{Lambda\PYGZus{}}\PYG{l+s+si}{\PYGZob{}R\PYGZcb{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{otimes E\PYGZus{}}\PYG{l+s+si}{\PYGZob{}PR\PYGZcb{}}\PYG{l+s+s1}{(}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{hat}\PYG{l+s+si}{\PYGZob{}e\PYGZcb{}}\PYG{l+s+s1}{)}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{otimes}\PYG{l+s+s1}{\PYGZsq{}} 
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{Delta\PYGZus{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{L,M\PYGZcb{}(K,Q,S)}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{otimes A\PYGZca{}}\PYG{l+s+si}{\PYGZob{}K\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{Q,S\PYGZcb{}(t)\PYGZdl{}.}\PYG{l+s+s1}{\PYGZsq{}}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Subselected for \PYGZdl{}z\PYGZdl{}\PYGZhy{}pol.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{basisProduct}\PYG{p}{[}\PYG{n}{basisKey}\PYG{p}{]}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{Labels}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} 
                   \PYG{n}{xDim}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cmap} \PYG{o}{=} \PYG{n}{cmap}\PYG{p}{,} \PYG{n}{mDimLabel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                   \PYG{n}{labelCols}\PYG{o}{=}\PYG{n}{labelCols}\PYG{p}{,}
                   \PYG{n}{titleString}\PYG{o}{=}\PYG{n}{titleString}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{\PYGZsh{} Glue versions for JupyterBook output}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{polProd\PYGZhy{}linearRamp\PYGZhy{}lmPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Full channel functions}
\PYG{c+c1}{\PYGZsh{} Plot with subselection on pol state (by label, \PYGZsq{}A\PYGZsq{}=z\PYGZhy{}pol case)}
\PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Channel functions example.}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Subselected for \PYGZdl{}z\PYGZdl{}\PYGZhy{}pol, \PYGZdl{}S\PYGZhy{}R}\PYG{l+s+se}{\PYGZbs{}\PYGZsq{}}\PYG{l+s+s1}{=0\PYGZdl{}.}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=}  \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{p}{(}\PYG{n}{basisProduct}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMtableResort}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{*} 
                       \PYG{n}{basisProduct}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{polProd}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{Labels}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZhy{}Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{L}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{,} 
                      \PYG{n}{xDim}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{,} \PYG{n}{mDimLabel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{titleString}\PYG{o}{=}\PYG{n}{titleString}\PYG{p}{)}\PYG{p}{;} 

\PYG{c+c1}{\PYGZsh{} Glue versions for JupyterBook output}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{channelFunc\PYGZhy{}linearRamp\PYGZhy{}lmPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{a7cda0de841125c68778b46cbe39ecd614b61fa34b5e91e48d12033bea490374}.png}
\caption{Example product basis function for the polarisation and ADM terms, as given by \(\Lambda_{R}\otimes E_{PR}(\hat{e})\otimes \Delta_{L,M}(K,Q,S)\otimes A^{K}_{Q,S}(t)\). Shown for \(z\)\sphinxhyphen{}pol case only (\(p=0\)).}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-polprod-linearramp}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{a3b45fc94a3fa791c444959d9f39312a374c8d1122c8cc37a48d8c40d681fa91}.png}
\caption{Example of \(\bar{\varUpsilon_{}}_{L,M}^{u,\zeta\zeta'}\) basis values for various choices of alignment (as per \hyperref[\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}]{Fig.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:fig-adms-linearramp}}}), shown for \(L=2\) and \(z\)\sphinxhyphen{}pol case only (\(p=0\)). The basis essentially shows the obsevable terms if the ionization matrix elements are neglected, hence the sensitivity of the configuration to each pair of partial wave terms. Note, in general, that the sensitivity to any given pair \(\langle l',m'|l,m\rangle\), increases with alignment (hence with \(t\) in this example) for the linear polarisation case (\(\mu=\mu'=0\)), but typically decreases with alignment for cross\sphinxhyphen{}polarised terms.}\label{\detokenize{part1/theory_tensor_formalism_160723:fig-channelfunc-linearramp}}\end{figure}


\bigskip\hrule\bigskip


\sphinxstepscope


\section{Density matrix representation}
\label{\detokenize{part1/theory_density_matrices_190723:density-matrix-representation}}\label{\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}}\label{\detokenize{part1/theory_density_matrices_190723::doc}}

\subsection{General introduction}
\label{\detokenize{part1/theory_density_matrices_190723:general-introduction}}\label{\detokenize{part1/theory_density_matrices_190723:sec-density-mat-intro}}
\sphinxAtStartPar
For a general introduction, and discussion of density matrix techniques and applications in AMO physics, see Blum’s textbook \sphinxstyleemphasis{Density Matrix Theory and Applications} {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}, which is referred to extensively herein. The general density operator, for a mixture of independent states \(|\psi_{n}\rangle\), can be defined as per Eqn. 2.8 in Blum {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}:
\begin{equation*}
\begin{split}
\hat{\rho}=\sum_{n}W_{n}|\psi_{n}\rangle\langle\psi_{n}|
\end{split}
\end{equation*}
\sphinxAtStartPar
Where \(W_{n}\) defines the (statistical) weighting of each state \(\psi_{n}\) in the mixture.

\sphinxAtStartPar
For a given basis set, \(|\phi_{m}\rangle\), the states can be expanded and the matrix elements of \(\rho\) defined as per Eqns. 2.9 \sphinxhyphen{} 2.11 in Blum {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}:
\begin{equation*}
\begin{split}
| \psi_{n} \rangle = \sum_{m'} a_{m'}^{(n)}| \phi_{m'}\rangle
\end{split}
\end{equation*}\begin{equation}\label{equation:part1/theory_density_matrices_190723:eqn:density-mat-outer-prod}
\begin{split}
\hat{\rho}=\sum_{n}\sum_{mm'}W_{n}a_{m'}^{(n)}a_{m}^{(n)*}|\phi_{m'}\rangle\langle\phi_{m}|
\end{split}
\end{equation}
\sphinxAtStartPar
And the matrix elements \sphinxhyphen{} \sphinxstyleemphasis{the density matrix} \sphinxhyphen{} given explicitly as:
\begin{equation}\label{equation:part1/theory_density_matrices_190723:eqn:density-mat-generic}
\begin{split}
\rho_{i,j}=\langle\phi_{i}|\hat{\rho}|\phi_{j}\rangle=\sum_{n}W_{n}a_{i}^{(n)}a_{j}^{(n)*}
\end{split}
\end{equation}
\sphinxAtStartPar
For all pairs of basis states \((i,j)\). This defines the density matrix in the \(\{|\phi_n\rangle\}\) \sphinxstyleemphasis{representation} (basis space). Of particular note here is that the mixed states are assumed to be incoherent (independent), whilst the basis expansion is coherent.


\subsection{Continuum density matrices}
\label{\detokenize{part1/theory_density_matrices_190723:continuum-density-matrices}}\label{\detokenize{part1/theory_density_matrices_190723:sec-density-mat-intro-continuum}}
\sphinxAtStartPar
In general, the discussion herein will focus on the photoelectron properties and generally assume a single final ion, and associated free\sphinxhyphen{}electron state of interest, hence the final state (Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:continuum-state-vec}) can be simplified to \(|\Psi_f\rangle\equiv|\mathbf{k}\rangle\). This is equivalent to a “pure state” in density matrix terminology, which can then expanded (coherently) in an appropriate representation (basis). Following this, the density operator associated with the continuum state can be written as \(\hat{\rho}=|\Psi_f\rangle\langle\Psi_f|\equiv|\mathbf{k}\rangle\langle\mathbf{k}|\). Making use of the tensor notation introduced in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}, the final continuum state can then be expanded as a density matrix in the \(\zeta\zeta'\) representation (with the observable dimensions \(\{L,M\}\) explicitly included in the density matrix), which will also be dependent on the choice of {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} (hence “experiment” \(u\)); the density matrix can then be given as:
\begin{equation}\label{equation:part1/theory_density_matrices_190723:eqn:full-density-mat}
\begin{split}
{\rho}_{L,M}^{u,\zeta\zeta'}=\varUpsilon_{L,M}^{u,\zeta\zeta'}\mathbb{I}^{\zeta,\zeta'}
\end{split}
\end{equation}
\sphinxAtStartPar
Here the density matrix can be interpreted as the final, {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} or {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} density matrix (depending on the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} used), incorporating both the intrinsic and extrinsic effects (i.e. all channel couplings and radial matrix elements for the given measurement), with dimensions dependent on the unique sets of quantum numbers required \sphinxhyphen{} in the simplest case, this will just be a set of partial waves \(\zeta = \{l,m\}\).

\sphinxAtStartPar
In the channel function basis, a radial, or reduced, form of the density matrix can also be constructed, and is given by the coherent product of the radial matrix elements (as defined in Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta}):
\begin{equation}\label{equation:part1/theory_density_matrices_190723:eqn:radial-density-mat}
\begin{split}
\rho^{\zeta\zeta'} = \mathbb{I}^{\zeta,\zeta'}
\end{split}
\end{equation}
\sphinxAtStartPar
This form encodes purely intrinsic (molecular scattering) photoionization dynamics (thus characterises the scattering event), whilst the full form \({\rho}_{L,M}^{u,\zeta\zeta'}\) of Eq. \eqref{equation:part1/theory_density_matrices_190723:eqn:full-density-mat} includes any additional effects incorporated via the channel functions. For reconstruction problems, it is usually the reduced form of Eq. \eqref{equation:part1/theory_density_matrices_190723:eqn:radial-density-mat} that is of interest, since the remainder of the problem is already described analytically by the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\). In other words, the retrieval of the radial matrix elements \(\mathbb{I}^{\zeta,\zeta'}\) and the radial density matrix \(\rho^{\zeta\zeta'}\) are equivalent, and both can be viewed as completely describing the photoionization dynamics.

\sphinxAtStartPar
The \(L,M\) notation for the full density matrix \({\rho}_{L,M}^{u,\zeta\zeta'}\) (Eq. \eqref{equation:part1/theory_density_matrices_190723:eqn:full-density-mat}) indicates here that these dimensions should not be summed over, hence the tensor coupling into the \(\beta_{L,M}^{u}\) parameters can also be written directly in terms of the density matrix (cf. Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}):
\begin{equation}\label{equation:part1/theory_density_matrices_190723:eqn:beta-density-mat}
\begin{split}
\beta_{L,M}^{u}=\sum_{\zeta,\zeta'}{\rho}_{L,M}^{u,\zeta\zeta'}
\end{split}
\end{equation}
\sphinxAtStartPar
In fact, this form arises naturally since the \(\beta_{L,M}^{u}\) terms are the state multipoles (geometric tensors) defining the system, which can be thought of as a coupled basis equivalent of the density matrix representations (see, e.g., Ref. {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}, Chpt. 4.).

\sphinxAtStartPar
In a more traditional notation (following Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:continuum-state-vec}, see also Ref. {[}\hyperlink{cite.backmatter/bibliography:id637}{100}{]}), the density operator can be expressed as:
\begin{equation}\label{equation:part1/theory_density_matrices_190723:eqn:full-density-mat-traditional}
\begin{split}
\rho(t) =\sum_{LM}\sum_{KQS}A^{K}_{QS}(t)\sum_{\zeta\zeta^{\prime}}\varUpsilon_{L,M}^{u,\zeta\zeta'}|\zeta,\Psi_+\rangle\langle\zeta,\Psi_+|\mu_q\rho_i\mu_{q\prime}^{*}|\zeta^{\prime},\Psi_+\rangle\langle\zeta^{\prime},\Psi_+|
\end{split}
\end{equation}
\sphinxAtStartPar
This is, effectively, equivalent to an expansion in the various tensor operators defined in the channel function notation above (Eq. \eqref{equation:part1/theory_density_matrices_190723:eqn:full-density-mat}), but in a standard state\sphinxhyphen{}vector notation. Note, also, that this form explicitly defines the initial state of the system as a density matrix \(\rho_i = |\Psi_i\rangle\langle\Psi_i|\), and explicitly allows for time\sphinxhyphen{}dependence via the \(A_{Q,S}^{K}(t)\) term. Finally, it is of note that these density matrices are implicitly energy dependent through the dependence on the final state energy \(|\mathbf{k}|\) but, in many cases (including the examples herein) are considered only at a single energy. This is usually due to experimental considerations, which typically provide photoelectron observables at a single energy (or small range \(\delta k\) over which the change in the continuum is considered negligible), hence there are no cross\sphinxhyphen{}terms in energy; however, in some cases (e.g. certain types of multi\sphinxhyphen{}pulse experiment), interferences \sphinxstyleemphasis{between} different continuum energies may be access, and density matrices including energy\sphinxhyphen{}dependence (e.g. in the \(\zeta = \{l,m,k\}\) representation) may be of interest.
(For further discussion of the use of density matrices in other specific cases, see \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}, particularly Chpts. 2 \& 3, and refs. therein.)

\sphinxAtStartPar
The main benefit of a (continuum) density matrix representation in the current work is as a rapid way to visualize the phase relations between the photoionization matrix elements (the off\sphinxhyphen{}diagonal density matrix elements), and the ability to quickly check the overall pattern of the elements, hence confirm that no phase\sphinxhyphen{}relations are missing and orthogonality relations are fulfilled \sphinxhyphen{} some numerical examples are given below. Since the method for computing the density matrices is also numerically equivalent to a tensor outer\sphinxhyphen{}product, density matrices and visualizations can also be rapidly composed for other properties of interest, e.g. the various {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} defined herein, providing another complementary methodology and tool for investigation. (Further examples can be found in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, as well as in the literature, see, e.g., Ref. {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]} for general discussion, Ref. {[}\hyperlink{cite.backmatter/bibliography:id837}{84}{]} for application in pump\sphinxhyphen{}probe schemes.)

\sphinxAtStartPar
Furthermore, as noted above, the density matrix elements provide a complete description of the photoionization event, and hence make clear the equivalence of the “complete” photoionization experiments (and associated continuum reconstruction methods) discussed herein, with general quantum tomography schemes {[}\hyperlink{cite.backmatter/bibliography:id782}{101}{]}. The density matrix can also be used as the starting point for further analysis based on standard density matrix techniques \sphinxhyphen{} this is discussed, for instance, in Ref. {[}\hyperlink{cite.backmatter/bibliography:id535}{97}{]}, and can also be viewed as a bridge between traditional methods in spectroscopy and AMO physics, and more recent concepts in the quantum information sciences (see, e.g., Refs. {[}\hyperlink{cite.backmatter/bibliography:id922}{102}, \hyperlink{cite.backmatter/bibliography:id986}{103}{]} for recent discussions in this context). A brief numerical diversion in this direction is given in \hyperref[\detokenize{part1/theory_density_matrices_190723:sect-theory-denmat-qutip}]{Sect.\@ \ref{\detokenize{part1/theory_density_matrices_190723:sect-theory-denmat-qutip}}}, which illustrates the use of the \sphinxhref{https://qutip.org/}{the \sphinxcode{\sphinxupquote{QuTiP}} (\sphinxstyleemphasis{Quantum Toolkbox in Python}) library} {[}\hyperlink{cite.backmatter/bibliography:id706}{104}, \hyperlink{cite.backmatter/bibliography:id707}{105}, \hyperlink{cite.backmatter/bibliography:id833}{106}{]} with the density matrix results derived herein.


\subsection{Numerical setup}
\label{\detokenize{part1/theory_density_matrices_190723:numerical-setup}}
\sphinxAtStartPar
This follows the setup in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}} {\hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{\sphinxcrossref{\DUrole{std,std-ref}{Tensor formulation of photoionization}}}}, using a symmetry\sphinxhyphen{}based set of basis functions for demonstration purposes. (Repeated code is hidden in PDF version.)


\subsection{Compute a density matrix}
\label{\detokenize{part1/theory_density_matrices_190723:compute-a-density-matrix}}
\sphinxAtStartPar
A basic density matrix computation routine is implemented in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]}. This makes use of input tensor arrays, and computes the density matrix as an outer\sphinxhyphen{}product of the defined dimension(s). The numerics essentially compute the outer product from the specified dimensions, which can be written generally as per Eqs. \eqref{equation:part1/theory_density_matrices_190723:eqn:density-mat-outer-prod}, \eqref{equation:part1/theory_density_matrices_190723:eqn:density-mat-generic}, where \(a_{i}^{(n)}a_{j}^{(n)*}\) are the values along the specified dimensions/state vector/representation. These dimensions must be in input arrays, but will be restacked as necessary to define the effective basis space, and all coherent pairs will be computed.

\sphinxAtStartPar
For instance, considering the ionization matrix elements demonstrated herein, setting indexes (quantum numbers) as \sphinxcode{\sphinxupquote{{[}l,m{]}}} will select the \(|\zeta\rangle = |l,m\rangle\) basis, hence define the density operator as \(\hat{\rho} = |\zeta\rangle \langle\zeta'| = |l,m\rangle\langle l',m'|\) and the corresponding density matrix elements \(\rho^{\zeta,\zeta'}=\langle\zeta|\hat{\rho}|\zeta'\rangle=a_{l,m}a_{l',m'}^{*}\). Similarly, setting \sphinxcode{\sphinxupquote{{[}'l','m','mu'{]}}} will set the \(|\zeta\rangle = |l,m,\mu\rangle\) as the basis vector and so forth, where \(|\zeta\rangle\) is used as a generic state vector denoting all required quantum numbers. Additionally, other quantum numbers/dimensions can be kept, summed or selected from the input tensors prior to computation, thus density matrices can be readily computed as a function of other parameters, or averaged, according to the properties of interest, experimental parameters and observables.

\sphinxAtStartPar
Note, however, that this selection is purely based on the numerics, which compute the outer product along the defined dimensions \(|\zeta\rangle\langle\zeta'|\) to form the density matrix, hence does not guarantee a well\sphinxhyphen{}formed density matrix in the strictest sense (depending on the basis set), although will always present a basis state correlation matrix of sorts. A brief example, for the \DUrole{pasted-text}{D2h} defined matrix element is given below; for more examples see the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} See the docs for more, }
\PYG{c+c1}{\PYGZsh{} https://epsproc.readthedocs.io/en/dev/methods/density\PYGZus{}mat\PYGZus{}notes\PYGZus{}demo\PYGZus{}300821.html}

\PYG{c+c1}{\PYGZsh{} Import routines for density calculation and plotting}
\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{calc} \PYG{k+kn}{import} \PYG{n}{density}

\PYG{c+c1}{\PYGZsh{}*** Compose density matrix}

\PYG{c+c1}{\PYGZsh{} Set dimensions/state vector/representation}
\PYG{c+c1}{\PYGZsh{} These must be in original data, but will be restacked as }
\PYG{c+c1}{\PYGZsh{} necessary to define the effective basis space.}

\PYG{c+c1}{\PYGZsh{} Set dimensions for density matrix. Note stacked dims are OK, in this case LM = \PYGZob{}l,m\PYGZcb{}}
\PYG{n}{denDims} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LM}\PYG{l+s+s1}{\PYGZsq{}}  
\PYG{n}{selDims} \PYG{o}{=} \PYG{k+kc}{None}  \PYG{c+c1}{\PYGZsh{} Select on any other dimensions?}
\PYG{n}{sumDims} \PYG{o}{=} \PYG{k+kc}{None}  \PYG{c+c1}{\PYGZsh{} Sum over any other dimensions? }
                \PYG{c+c1}{\PYGZsh{} (Set sumDims=True to sum over all dims except denDims.)}
\PYG{n}{pTypes}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{r}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{i}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} Plotting types \PYGZsq{}r\PYGZsq{}=real, \PYGZsq{}i\PYGZsq{}=imaginary}
\PYG{n}{thres} \PYG{o}{=} \PYG{l+m+mf}{1e\PYGZhy{}4}    \PYG{c+c1}{\PYGZsh{} Threshold for outputs (otherwise set to zero and/or dropped from result)}
\PYG{n}{normME} \PYG{o}{=} \PYG{k+kc}{False}  \PYG{c+c1}{\PYGZsh{} Normalise matrix elements before computing?}
\PYG{n}{normDen} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Method to normalise density matrix}

\PYG{c+c1}{\PYGZsh{} Calculate \PYGZhy{} Ref case}
\PYG{n}{k} \PYG{o}{=} \PYG{n}{sym}
\PYG{n}{matE} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{k}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{copy}\PYG{p}{(}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Set data from main class instance by key}

\PYG{c+c1}{\PYGZsh{} Normalise input matrix elements?}
\PYG{k}{if} \PYG{n}{normME}\PYG{p}{:}
    \PYG{n}{matE} \PYG{o}{=} \PYG{n}{matE}\PYG{o}{/}\PYG{n}{matE}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}*** Compute density matrix for given parameters}
\PYG{c+c1}{\PYGZsh{} See demo at:}
\PYG{c+c1}{\PYGZsh{}   https://epsproc.readthedocs.io/en/latest/methods/density\PYGZus{}mat\PYGZus{}notes\PYGZus{}demo\PYGZus{}300821.html}
\PYG{c+c1}{\PYGZsh{} API docs:}
\PYG{c+c1}{\PYGZsh{}   https://epsproc.readthedocs.io/en/latest/modules/epsproc.calc.density.html\PYGZsh{}epsproc.calc.density.densityCalc}
\PYG{n}{daOut}\PYG{p}{,} \PYG{o}{*}\PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{density}\PYG{o}{.}\PYG{n}{densityCalc}\PYG{p}{(}\PYG{n}{matE}\PYG{p}{,} \PYG{n}{denDims} \PYG{o}{=} \PYG{n}{denDims}\PYG{p}{,} 
                                \PYG{n}{selDims} \PYG{o}{=} \PYG{n}{selDims}\PYG{p}{,} \PYG{n}{thres} \PYG{o}{=} \PYG{n}{thres}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Renormlise output?}
\PYG{k}{if} \PYG{n}{normDen}\PYG{o}{==}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}
    \PYG{n}{daOut} \PYG{o}{=} \PYG{n}{daOut}\PYG{o}{/}\PYG{n}{daOut}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}
\PYG{k}{elif} \PYG{n}{normDen}\PYG{o}{==}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{trace}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} Need sym sum here to get 2D trace}
    \PYG{n}{daOut} \PYG{o}{=} \PYG{n}{daOut}\PYG{o}{/}\PYG{p}{(}\PYG{n}{daOut}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{pipe}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{trace}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}  

\PYG{c+c1}{\PYGZsh{} Plot density matrix with Holoviews}
\PYG{c+c1}{\PYGZsh{} Note sum over \PYGZsq{}Sym\PYGZsq{} dimension to flatten plot to (l,m) dims only.}
\PYG{n}{daPlot} \PYG{o}{=} \PYG{n}{density}\PYG{o}{.}\PYG{n}{matPlot}\PYG{p}{(}\PYG{n}{daOut}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{pTypes}\PYG{o}{=}\PYG{n}{pTypes}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{d9e887d4aaecc7ef08945679c1217e80c95a9cf833ce99acd1a048f9b46356b6}.png}
\caption{Example density matrix, computed from matrix elements defined purely by \DUrole{pasted-text}{D2h} symmetry. Note in this case only the real part is non\sphinxhyphen{}zero. Axes labels give terms \(\{L,M\}\) and \(\{L',M'\}\).}\label{\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hrealonly}}\end{figure}


\subsection{Visualising matrix element reconstruction fidelity with density matrices}
\label{\detokenize{part1/theory_density_matrices_190723:visualising-matrix-element-reconstruction-fidelity-with-density-matrices}}
\sphinxAtStartPar
To demonstrate the use of the density matrix representation as a means to test similarity or fidelity between two sets of matrix elements, a trial set of matrix elements can be derived from the original set used above, plus random noise, and the differences in the density matrices directly computed. An example is shown in \hyperref[\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}]{Fig.\@ \ref{\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}}}; in this example up to 10\% random noise has been added to the original (input) matrix elements, and the resultant density matrix computed. The difference matrix (\hyperref[\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}]{Fig.\@ \ref{\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}}}(c)) then provides the fidelity between the original and noisy case. In testing retrieval methodologies, this type of analysis thus provides a quick means to test reconstruction results vs. known inputs. Although this case is only illustrated for real density matrices, a similar analysis can be used for the imaginary (or phase) components, thus coherences can also be quickly visualised in this manner.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}*** Set trial matrix element for comparison with the original case computed above}
\PYG{n}{matE} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{k}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{copy}\PYG{p}{(}\PYG{p}{)}

\PYG{k}{if} \PYG{n}{normME}\PYG{p}{:}
    \PYG{n}{matE} \PYG{o}{=} \PYG{n}{matE}\PYG{o}{/}\PYG{n}{matE}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}
    
\PYG{c+c1}{\PYGZsh{} Add random noise, +/\PYGZhy{} 10\PYGZpc{}}
\PYG{c+c1}{\PYGZsh{} Note this is applied to normalised matE}
\PYG{c+c1}{\PYGZsh{} For the normalised case this results in a standard deviation in the difference }
\PYG{c+c1}{\PYGZsh{} density matrix elements of \PYGZti{}sqrt(2*(0.1\PYGZca{}2) + 2*0.1) = 0.2}
\PYG{c+c1}{\PYGZsh{} (Derived from basic error propagation, ignoring the actual values \PYGZhy{} }
\PYG{c+c1}{\PYGZsh{}  see https://en.wikipedia.org/wiki/Propagation\PYGZus{}of\PYGZus{}uncertainty\PYGZsh{}Example\PYGZus{}formulae.)}
\PYG{n}{noise} \PYG{o}{=} \PYG{l+m+mf}{0.1}
\PYG{n}{SD} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sqrt}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{o}{*}\PYG{p}{(}\PYG{n}{noise}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Set range to random values +/\PYGZhy{}1 * noise}
\PYG{n}{matE\PYGZus{}noise} \PYG{o}{=} \PYG{n}{matE} \PYG{o}{+} \PYG{n}{matE}\PYG{o}{*}\PYG{p}{(}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{rand}\PYG{p}{(}\PYG{o}{*}\PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{matE}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{l+m+mf}{0.5}\PYG{p}{)} \PYG{o}{*} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{noise}\PYG{p}{)}  

\PYG{c+c1}{\PYGZsh{} Compute density matrix}
\PYG{n}{daOut\PYGZus{}noise}\PYG{p}{,} \PYG{o}{*}\PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{density}\PYG{o}{.}\PYG{n}{densityCalc}\PYG{p}{(}\PYG{n}{matE\PYGZus{}noise}\PYG{p}{,} \PYG{n}{denDims} \PYG{o}{=} \PYG{n}{denDims}\PYG{p}{,} \PYG{n}{selDims} \PYG{o}{=} \PYG{n}{selDims}\PYG{p}{,} \PYG{n}{thres} \PYG{o}{=} \PYG{n}{thres}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Renormlise output?}
\PYG{k}{if} \PYG{n}{normDen}\PYG{o}{==}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}
    \PYG{n}{daOut\PYGZus{}noise} \PYG{o}{=} \PYG{n}{daOut\PYGZus{}noise}\PYG{o}{/}\PYG{n}{daOut\PYGZus{}noise}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}
\PYG{k}{elif} \PYG{n}{normDen}\PYG{o}{==}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{trace}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}
    \PYG{n}{daOut\PYGZus{}noise} \PYG{o}{=} \PYG{n}{daOut\PYGZus{}noise}\PYG{o}{/}\PYG{p}{(}\PYG{n}{daOut\PYGZus{}noise}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{pipe}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{trace}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}
    
\PYG{n}{daPlot\PYGZus{}noise} \PYG{o}{=} \PYG{n}{density}\PYG{o}{.}\PYG{n}{matPlot}\PYG{p}{(}\PYG{n}{daOut\PYGZus{}noise}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{pTypes}\PYG{o}{=}\PYG{n}{pTypes}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute differences}
\PYG{n}{daDiff} \PYG{o}{=} \PYG{n}{daOut}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{daOut\PYGZus{}noise}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{daDiff}\PYG{o}{.}\PYG{n}{name} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Difference}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{daPlotDiff} \PYG{o}{=} \PYG{n}{density}\PYG{o}{.}\PYG{n}{matPlot}\PYG{p}{(}\PYG{n}{daDiff}\PYG{p}{,} \PYG{n}{pTypes}\PYG{o}{=}\PYG{n}{pTypes}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Noise = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{noise}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{, SD (approx) = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{SD}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{maxDiff} \PYG{o}{=} \PYG{n}{daDiff}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{values}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Max difference = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{maxDiff}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}*** Layout plot from Holoviews objects for real parts, with custom titles.}
\PYG{n}{daLayout} \PYG{o}{=} \PYG{p}{(}\PYG{n}{daPlot}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{n}{pType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Real}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{opts}\PYG{p}{(}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(a) Original}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{xlabel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L,M}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                                             \PYG{n}{ylabel}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{L}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{,M}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} 
            \PYG{o}{+} \PYG{n}{daPlot\PYGZus{}noise}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{n}{pType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Real}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{opts}\PYG{p}{(}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(b) With noise}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} 
                \PYG{n}{xlabel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L,M}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{ylabel}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{L}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{,M}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} 
            \PYG{o}{+} \PYG{n}{daPlotDiff}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{n}{pType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Real}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{opts}\PYG{p}{(}\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{(c) Difference (fidelity)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} 
                \PYG{n}{xlabel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L,M}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{ylabel}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{L}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{,M}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{d503c9723f6f5a87927f612fe69775f6e893f15eaabb2f5c6af329f25ae5c9be}.png}
\caption{Example density matrices, computed from matrix elements defined purely by \DUrole{pasted-text}{D2h} symmetry. Here the panels show (a) the original density matrix, (b) density matrix computed with +/\sphinxhyphen{} 10\% random noise added to the original matrix elements, (c) the difference matrix, which indicates the fidelity of the noisy case relative to the original case. For normalised density matrices the 10\% noise case translates to a standard deviation \(\sigma\approx\)\DUrole{pasted-text}{0.2} on the differences; the maximum error in the test case as illustrated =\DUrole{pasted-text}{0.285}.}\label{\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}}\end{figure}


\subsection{Working with density matrices with QuTiP library functions}
\label{\detokenize{part1/theory_density_matrices_190723:working-with-density-matrices-with-qutip-library-functions}}\label{\detokenize{part1/theory_density_matrices_190723:sect-theory-denmat-qutip}}
\sphinxAtStartPar
From the numerical density matrix, a range of other standard properties can be computed \sphinxhyphen{} of particular interest are likely to be various standard quantities such as the trace, Von Neuman entropy and so forth. Naturally these can be computed numerically directly from the relevant formal definitions; however, many of the fundamentals are already implemented in other libraries, and numerical representations can be passed directly to such libraries. In particular, \sphinxhref{https://qutip.org/}{the \sphinxcode{\sphinxupquote{QuTiP}} (\sphinxstyleemphasis{Quantum Toolkbox in Python}) library} {[}\hyperlink{cite.backmatter/bibliography:id706}{104}, \hyperlink{cite.backmatter/bibliography:id707}{105}, \hyperlink{cite.backmatter/bibliography:id833}{106}{]} implements a range of standard functions, metrics, transforms and utility functions for working with state vectors and density matrices. A brief numerical example is given below, see \sphinxhref{https://qutip.org/}{the QuTiP documentation} {[}\hyperlink{cite.backmatter/bibliography:id833}{106}{]} for more possibilities.


\subsubsection{Convert numerical arrays to QuTiP objects}
\label{\detokenize{part1/theory_density_matrices_190723:convert-numerical-arrays-to-qutip-objects}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Import QuTip}
\PYG{k+kn}{from} \PYG{n+nn}{qutip} \PYG{k+kn}{import} \PYG{o}{*}

\PYG{c+c1}{\PYGZsh{} Wrap density matrices to QuTip objects}
\PYG{c+c1}{\PYGZsh{} Note sum(\PYGZsq{}Sym\PYGZsq{}) to ensure 2D matrix, and .data to pass Numpy data array only}
\PYG{n}{pa} \PYG{o}{=} \PYG{n}{Qobj}\PYG{p}{(}\PYG{n}{daOut}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}    \PYG{c+c1}{\PYGZsh{} Reference continuum density matrix}
\PYG{n}{pb} \PYG{o}{=} \PYG{n}{Qobj}\PYG{p}{(}\PYG{n}{daOut\PYGZus{}noise}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sym}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Noisy case}

\PYG{c+c1}{\PYGZsh{} QuTip objects have data as Numpy arrays, and render as typeset matrices in a notebook}
\PYG{c+c1}{\PYGZsh{} DEBUG NOTE 22/04/23 \PYGZhy{} QuTip matrix latex output currently causing PDF build errors, so set hide output for testing.}
\PYG{c+c1}{\PYGZsh{} See https://github.com/phockett/Quantum\PYGZhy{}Metrology\PYGZhy{}with\PYGZhy{}Photoelectrons\PYGZhy{}Vol3/issues/8}
\PYG{k}{if} \PYG{n}{buildEnv} \PYG{o}{!=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pdf}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}
    \PYG{n}{display}\PYG{p}{(}\PYG{n}{pa}\PYG{p}{)}
    \PYG{c+c1}{\PYGZsh{} print(pa)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}

\subsubsection{Fidelity metric}
\label{\detokenize{part1/theory_density_matrices_190723:fidelity-metric}}
\sphinxAtStartPar
Fidelity between two density matrices \(\rho_{a},\rho_{b}\) can be defined as per Refs. {[}\hyperlink{cite.backmatter/bibliography:id527}{107}, \hyperlink{cite.backmatter/bibliography:id807}{108}{]}:

\sphinxAtStartPar
\(F(\rho_{a},\rho_{b})=\operatorname{Tr} {\sqrt {{\sqrt {\rho_{a}}}\rho_{b} {\sqrt {\rho_{a}}}}}\)

\sphinxAtStartPar
This is implemented by the \sphinxcode{\sphinxupquote{fidelity}} function in \sphinxhref{https://qutip.org/}{the \sphinxcode{\sphinxupquote{QuTiP}} (\sphinxstyleemphasis{Quantum Toolkbox in Python}) library} {[}\hyperlink{cite.backmatter/bibliography:id706}{104}, \hyperlink{cite.backmatter/bibliography:id707}{105}, \hyperlink{cite.backmatter/bibliography:id833}{106}{]}. Of note in this test case is that the resultant is close to limiting\sphinxhyphen{}case value of \(F(\rho_{a},\rho_{b})=1\) for the test case herein, despite the added noise and some per\sphinxhyphen{}element disparities as shown in   \hyperref[\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}]{Fig.\@ \ref{\detokenize{part1/theory_density_matrices_190723:fig-denmatd2hcompexample}}}(c). This reflects the conceptual difference between an element\sphinxhyphen{}wise evaluation of the differences, vs. a formal scalar metric.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Test fidelity, =1 if trace\PYGZhy{}normalised}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Fidelity (a,a) = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fidelity}\PYG{p}{(}\PYG{n}{pa}\PYG{p}{,}\PYG{n}{pa}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Trace = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{pa}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Trace\PYGZhy{}normed fidelity = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fidelity}\PYG{p}{(}\PYG{n}{pa}\PYG{p}{,}\PYG{n}{pa}\PYG{p}{)}\PYG{o}{/}\PYG{n}{pa}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Fidelity (a,a) = 25.00000031332397
Trace = 25.0
Trace\PYGZhy{}normed fidelity = 1.0000000125329587
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Test fidelity vs noisy case}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Fidelity (a,b) = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fidelity}\PYG{p}{(}\PYG{n}{pa}\PYG{p}{,}\PYG{n}{pb}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Trace a = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{pa}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{, Trace b = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{pb}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Trace\PYGZhy{}normed fidelity = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fidelity}\PYG{p}{(}\PYG{n}{pa}\PYG{o}{/}\PYG{n}{pa}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{pb}\PYG{o}{/}\PYG{n}{pb}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Fidelity (a,b) = 23.291626669620815
Trace a = 25.0, Trace b = 21.7704918784886
Trace\PYGZhy{}normed fidelity = 0.9983847074132652
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} This can also be computed rapidly with lower\PYGZhy{}level QuTip functionality...}

\PYG{c+c1}{\PYGZsh{} Compute inner term, note .sqrtm() for square root.}
\PYG{n}{inner} \PYG{o}{=} \PYG{n}{pa}\PYG{o}{.}\PYG{n}{sqrtm}\PYG{p}{(}\PYG{p}{)} \PYG{o}{*} \PYG{n}{pa} \PYG{o}{*} \PYG{n}{pa}\PYG{o}{.}\PYG{n}{sqrtm}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute fidelity}
\PYG{n}{inner}\PYG{o}{.}\PYG{n}{sqrtm}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{tr}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(25.00000059788841+8.879641550582872e\PYGZhy{}08j)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxstepscope


\section{Molecular alignment}
\label{\detokenize{part1/theory_molecular_alignment_170723:molecular-alignment}}\label{\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}}\label{\detokenize{part1/theory_molecular_alignment_170723::doc}}

\subsection{A very brief introduction to molecular alignment}
\label{\detokenize{part1/theory_molecular_alignment_170723:a-very-brief-introduction-to-molecular-alignment}}
\sphinxAtStartPar
The term {\hyperref[\detokenize{backmatter/glossary:term-molecular-alignment}]{\sphinxtermref{\DUrole{xref,std,std-term}{molecular alignment}}}} can be used, in general, to define any case where the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} is specified relative to the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} in some way \sphinxhyphen{} for instance if the molecular symmetry axis is constrained to the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} \(z\)\sphinxhyphen{}axis. Herein, it is generally used more specifically, to refer to the case of a (time\sphinxhyphen{}dependent) aligned molecular ensemble in gas\sphinxhyphen{}phase experiments (e.g. as illustrated in \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}}). Any such axis distribution, in which there is a defined arrangement of axes created in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}, can be discussed, and characterised, in terms of the axis distribution moments ({\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}), which have already been introduced passing in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}. More specifically, {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} are coefficients in a multipole expansion, usually in terms of {\hyperref[\detokenize{backmatter/glossary:term-Wigner-rotation-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{Wigner rotation matrix elements}}}}, of the molecular axis probability distribution. In this section some additional definitions are given, along with numerical examples.

\sphinxAtStartPar
The creation of an aligned ensemble in the gas phase can be achieved via a single, or sequence of, N\sphinxhyphen{}photon transitions, or strong\sphinxhyphen{}field mediated techniques. Of the latter, adiabatic and non\sphinxhyphen{}adiabatic alignment methods are particularly powerful, and make use of a strong, slowly\sphinxhyphen{}varying or impulsive laser field respectively. (Here the “slow” and “impulsive” time\sphinxhyphen{}scales are defined in relation to molecular rotations, roughly on the ps time\sphinxhyphen{}scale, with ns and fs laser fields corresponding to the typical slow and fast control fields.) In the former case, the molecular axis, or axes, will gradually align along the electric\sphinxhyphen{}field vector(s) while the field is present. In the latter, impulsive case, a broad rotational wavepacket ({\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}}) can be created, initiating complex rotational dynamics including field\sphinxhyphen{}free revivals of ensemble alignment. For further general discussion, there is a rich literature on molecular alignment available, see, for instance, Refs. {[}\hyperlink{cite.backmatter/bibliography:id903}{109}, \hyperlink{cite.backmatter/bibliography:id645}{110}, \hyperlink{cite.backmatter/bibliography:id728}{111}, \hyperlink{cite.backmatter/bibliography:id1002}{112}{]} for reviews and further introductory materials, and further discussion in the current context can be found in \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} and Refs. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}, \hyperlink{cite.backmatter/bibliography:id841}{95}, \hyperlink{cite.backmatter/bibliography:id937}{96}, \hyperlink{cite.backmatter/bibliography:id835}{113}, \hyperlink{cite.backmatter/bibliography:id836}{114}, \hyperlink{cite.backmatter/bibliography:id664}{115}{]} and references therein.

\sphinxAtStartPar
For {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval problems based on {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} methods, the absolute degree of alignment may \sphinxhyphen{} or may not \sphinxhyphen{} be critical in a given case. The sampling of a range of \sphinxstyleemphasis{different} alignments, however, is vital, since this directly feeds into the information content of the measurements (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term}}} and \hyperref[\detokenize{part1/theory_info_content_200723:sec-info-content}]{Sect.\@ \ref{\detokenize{part1/theory_info_content_200723:sec-info-content}}}). In the case\sphinxhyphen{}studies of {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}, the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} are assumed to be known, but in general these must be determined from experimental data, this is discussed in \hyperref[\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}}}.


\subsection{Alignment distribution moments (ADMs)}
\label{\detokenize{part1/theory_molecular_alignment_170723:alignment-distribution-moments-adms}}
\sphinxAtStartPar
The parametrization of an aligned distribution can be given generally by an expansion in {\hyperref[\detokenize{backmatter/glossary:term-Wigner-rotation-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{Wigner rotation matrix elements}}}}:
\begin{equation}\label{equation:part1/theory_molecular_alignment_170723:eqn:P-omega-t}
\begin{split} 
P(\Omega,t) = \sum_{K,Q,S} A^K_{Q,S}(t)D^K_{Q,S}(\Omega)
\end{split}
\end{equation}
\sphinxAtStartPar
Where \(P(\Omega,t)\) is the full axis distribution probability, expanded for a set of {\hyperref[\detokenize{backmatter/glossary:term-Euler-angles}]{\sphinxtermref{\DUrole{xref,std,std-term}{Euler angles}}}} \(\Omega\), and the expansion parameters \(A^K_{Q,S}(t)\) are the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}.

\sphinxAtStartPar
This reduces to the 2D case if \(S=0\), which can equivalently be described as an expansion in spherical harmonics (note that the normalisation of the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} may be different in this case):
\begin{equation}\label{equation:part1/theory_molecular_alignment_170723:eqn:P-omega-t-2D}
\begin{split} 
P(\theta,\phi,t) = \sum_{K,Q} A^K_{Q,0}(t)D^K_{Q,0}(\Omega) = \sum_{K,Q} A^K_{Q}(t)Y_{K,Q}(\Omega)
\end{split}
\end{equation}
\sphinxAtStartPar
In the examples given in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}, some arbitrary choices of \(A^K_{Q,S}(t)\) were demonstrated to investigate their effects on the tensor basis sets; in the case\sphinxhyphen{}studies presented in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} realistic {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} are used for specific fitting problems. In practice this equates to (accurately) simulating rotational wavepackets, hence obtaining the corresponding \(A_{Q,S}^{K}(t)\) parameters (expectation values), as a function of laser fluence and rotational temperature. (Given experimental data, a 2D uncertainty (or error) surface in these two fundamental quantities can then be obtained from a linear regression for each set of \(A_{Q,S}^{K}(t)\), see Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]} for further introductory discussion on this point.) Note that, as discussed in \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-general}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-general}}}, computation of molecular alignment is not yet implemented in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, so values must be obtained from other codes. {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} used herein were all computed with codes developed by V. Makhija {[}\hyperlink{cite.backmatter/bibliography:id772}{116}{]}, and are available from the \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]} repo on Github.


\subsection{Numerical setup}
\label{\detokenize{part1/theory_molecular_alignment_170723:numerical-setup}}
\sphinxAtStartPar
For illustrative purposes, the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} used for the \(N_2\) fitting example are here loaded and used to compute \(P(\Omega,t)\). (Note these {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} are for a 2\sphinxhyphen{}pulse alignment scheme, as outlined in Ref. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]}.)

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Quick plot for subselected ADMs (setup in the script), }
\PYG{c+c1}{\PYGZsh{} using basic plotter}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{ADMplot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{subKey}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Quick plot for subselected ADMs (setup in the script), using hvplot}
\PYG{c+c1}{\PYGZsh{} data.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}ADM\PYGZsq{}].unstack().squeeze().real.hvplot.line(x=\PYGZsq{}t\PYGZsq{}).overlay(\PYGZsq{}K\PYGZsq{})}

\PYG{c+c1}{\PYGZsh{} As above, but plot K\PYGZgt{}0 terms only, and keep \PYGZsq{}Q\PYGZsq{},\PYGZsq{}S\PYGZsq{} indexes (here all =0)}
\PYG{n}{figObj} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{unstack}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{unstack}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{K}\PYG{o}{\PYGZgt{}}\PYG{l+m+mi}{0}\PYG{p}{)} \PYGZbs{}
        \PYG{o}{.}\PYG{n}{real}\PYG{o}{.}\PYG{n}{hvplot}\PYG{o}{.}\PYG{n}{line}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{overlay}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{K}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Q}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{opts}\PYG{p}{(}\PYG{n}{width}\PYG{o}{=}\PYG{l+m+mi}{700}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{fitSystem}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{fitSystem}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ADMdemoPlot}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{figObj}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{438832e2818d3412fd75e9b9cb1f4758a28e24b6d690f8ffd5a1575006fc901c}.png}
\caption{Example {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} for \DUrole{pasted-text}{N2}.}\label{\detokenize{part1/theory_molecular_alignment_170723:fig-admdemoplot}}\end{figure}


\subsection{Compute \protect\(P(\theta,\Phi,t)\protect\) distributions}
\label{\detokenize{part1/theory_molecular_alignment_170723:compute-p-theta-phi-t-distributions}}
\sphinxAtStartPar
For 1D and 2D cases, the full axis distributions can be expanded in spherical harmonics and plotted using \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} class methods. This is briefly illustrated below. Note that expansions in {\hyperref[\detokenize{backmatter/glossary:term-Wigner-rotation-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{Wigner rotation matrix elements}}}} are not currently supported by these routines.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} NOTE \PYGZhy{} need this in some builds if Matplotlib has call\PYGZhy{}back errors.}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline  
\PYG{c+c1}{\PYGZsh{} Plot P(theta,t) with summation over phi dimension}
\PYG{c+c1}{\PYGZsh{} Note the plotting function automatically expands the ADMs in spherical harmonics}
\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{padPlot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{n}{dataKey}\PYG{p}{,} \PYG{n}{dataType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Etype} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{pStyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{grid}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{reducePhi}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sum}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Using default sph betas.
Summing over dims: set()
Plotting from self.data[subset][ADM], facetDims=[\PYGZsq{}t\PYGZsq{}, None], pType=a with backend=mpl.
Grid plot: (\PYGZsq{}subset\PYGZsq{}, \PYGZsq{}ADM\PYGZsq{}), dataType: ADM, plotType: a
Set plot to self.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}plots\PYGZsq{}][\PYGZsq{}ADM\PYGZsq{}][\PYGZsq{}grid\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{552a5788e8ea3eb18ca2105b2d8355a293903da7102e66dcfcd0caf027301e47}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot full axis distributions at selected time\PYGZhy{}steps}
\PYG{c+c1}{\PYGZsh{} tPlot = [39.402, 40.791, 42.18]  \PYGZsh{} Manual setting for baseline case, and at max and min K=2 times. OCS}
\PYG{n}{tPlot} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{4.018}\PYG{p}{,} \PYG{l+m+mf}{4.254}\PYG{p}{,} \PYG{l+m+mf}{4.49}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} N2}

\PYG{c+c1}{\PYGZsh{} Alternatively, plot at selected times by index slice}
\PYG{c+c1}{\PYGZsh{} Note that selDims below requires labels (not index inds)}
\PYG{c+c1}{\PYGZsh{} tPlot = data.data[dataKey][\PYGZsq{}ADM\PYGZsq{}].t[::5]  \PYGZsh{} OCS}
\PYG{c+c1}{\PYGZsh{} tPlot = data.data[dataKey][\PYGZsq{}ADM\PYGZsq{}].t[0:7:3] \PYGZsh{} N2}

\PYG{c+c1}{\PYGZsh{} Plot}
\PYG{n}{ep}\PYG{o}{.}\PYG{n}{plot}\PYG{o}{.}\PYG{n}{hvPlotters}\PYG{o}{.}\PYG{n}{setPlotters}\PYG{p}{(}\PYG{n}{width}\PYG{o}{=}\PYG{l+m+mi}{1200}\PYG{p}{,} \PYG{n}{height}\PYG{o}{=}\PYG{l+m+mi}{600}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Force plot dims for HTML render (avoids subplot clipping issues)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{padPlot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{n}{dataKey}\PYG{p}{,} \PYG{n}{dataType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{Etype} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{pType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
             \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{selDims}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{tPlot}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pl}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} And GLUE for display later with caption}
\PYG{n}{figObj} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{polar}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{axisDistDemo}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{figObj}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{6d196d3ecae44217683537edfcc8cc9b2eda36d212bf4917189a597e86ba2afa}.png}
\caption{Molecular axis distributions \(P(\theta,\phi)\) at selected times. In this demo case the alignment is “1D”, and cylindrically symmetric.}\label{\detokenize{part1/theory_molecular_alignment_170723:fig-axisdistdemo}}\end{figure}

\sphinxstepscope


\section{Observables: photoelectron flux in the LF and MF}
\label{\detokenize{part1/theory_observables_intro_100723:observables-photoelectron-flux-in-the-lf-and-mf}}\label{\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}}\label{\detokenize{part1/theory_observables_intro_100723::doc}}
\sphinxAtStartPar
The observables of interest herein \sphinxhyphen{} the photoelectron flux as a function of energy, ejection angle, and time (see \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}}) \sphinxhyphen{} can be written quite generally as expansions in radial and angular basis functions. Various types and definitions are given in this section, including worked numerical examples. The final section, \hyperref[\detokenize{part1/theory_observables_intro_100723:sect-theory-time-resolved-data}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sect-theory-time-resolved-data}}}, illustrates typical data from a time\sphinxhyphen{}resolved measurement, resulting in time and energy dependant observables \sphinxhyphen{} this is the type of data required for the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}.


\subsection{Spherical harmonics}
\label{\detokenize{part1/theory_observables_intro_100723:spherical-harmonics}}\label{\detokenize{part1/theory_observables_intro_100723:sec-theory-sph-harm-intro}}
\sphinxAtStartPar
The photoelectron flux as a function of energy, ejection angle, and time, can be written generally as an expansion in spherical harmonics:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}
\begin{split}
\begin{align}
\bar{I}(\epsilon,t,\theta,\phi)=\sum_{L=0}^{2n}\sum_{M=-L}^{L}\bar{\beta}_{L,M}(\epsilon,t)Y_{L,M}(\theta,\phi)
\end{align}
\end{split}
\end{equation}
\sphinxAtStartPar
Here the flux in the laboratory frame ({\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}) or aligned frame ({\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}) is denoted \(\bar{I}(\epsilon,t,\theta,\phi)\), with the bar signifying ensemble averaging, and the molecular frame flux by \(I(\epsilon,t,\theta,\phi)\). Similarly, the expansion parameters \(\bar{\beta}_{L,M}(\epsilon,t)\) include a bar for the LF/AF case. These observables are generally termed photoelectron angular distributions ({\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}), often with a prefix denoting the reference frame, e.g. LFPADs, MFPADs, and the associated expansion parameters \(\bar{\beta}_{L,M}(\epsilon,t)\) are generically termed {\hyperref[\detokenize{backmatter/glossary:term-anisotropy-paramters}]{\sphinxtermref{\DUrole{xref,std,std-term}{anisotropy paramters}}}}. The polar coordinate system \((\theta,\phi)\) is referenced to
an experimentally\sphinxhyphen{}defined axis in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}/{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} case (usually defined by the laser polarization), and the molecular symmetry axis in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}, as illustrated in \hyperref[\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}]{Fig.\@ \ref{\detokenize{part1/main_intro_060723:fig-bootstrap-concept-outline}}}. Some arbitrary examples are given in \hyperref[\detokenize{part1/theory_observables_intro_100723:fig-pads-example}]{Fig.\@ \ref{\detokenize{part1/theory_observables_intro_100723:fig-pads-example}}}, which illustrates a range of distributions of increasing complexity; corresponding basic code to set \(\beta_{L,M}\) parameters and visualise them is given below; the values used are as tabulated in \hyperref[\detokenize{part1/theory_observables_intro_100723:blm-tab}]{Fig.\@ \ref{\detokenize{part1/theory_observables_intro_100723:blm-tab}}}.

\sphinxAtStartPar
Numerically, there are some choices and conventions which apply to the spherical harmonics. As noted in \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}}: “spherical harmonics are defined with the usual physics conventions: orthonormalised, and including the Condon\sphinxhyphen{}Shortley phase. Numerically they are implemented directly or via SciPy’s \sphinxcode{\sphinxupquote{sph\_harm}} function (see \sphinxhref{https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.sph\_harm.html}{the SciPy docs for details} {[}\hyperlink{cite.backmatter/bibliography:id877}{59}{]}.” For further details, including conversion routines, see the \sphinxhref{https://shtools.oca.eu}{\sphinxcode{\sphinxupquote{pySHtools}}} {[}\hyperlink{cite.backmatter/bibliography:id888}{60}, \hyperlink{cite.backmatter/bibliography:id957}{61}, \hyperlink{cite.backmatter/bibliography:id958}{62}, \hyperlink{cite.backmatter/bibliography:id959}{63}{]} documentation, and numerical examples below.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot some distributions from specified BLMs}

\PYG{c+c1}{\PYGZsh{} Set specific LM coeffs by list with setBLMs, items are [l,m,value(s)]}
\PYG{c+c1}{\PYGZsh{} Multiple values are automatically assigned to an index \PYGZsq{}t\PYGZsq{}}
\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{sphCalc} \PYG{k+kn}{import} \PYG{n}{setBLMs}

\PYG{n}{BLM} \PYG{o}{=} \PYG{n}{setBLMs}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
               \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.8}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.8}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
               \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
               \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.8}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.8}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Output a quick tabulation of the values with Pandas}
\PYG{n}{BLM}\PYG{o}{.}\PYG{n}{to\PYGZus{}pandas}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Glue for later use}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{blm\PYGZhy{}tab}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{BLM}\PYG{o}{.}\PYG{n}{to\PYGZus{}pandas}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Note also that the Xarray contains metadata (attributes) on type and normalisation}
\PYG{c+c1}{\PYGZsh{} This uses the SHtools format specification.}

\PYG{c+c1}{\PYGZsh{} Display full Xarray, including metadata }
\PYG{n}{BLM}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Show harmonics info only}
\PYG{n}{BLM}\PYG{o}{.}\PYG{n}{attrs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{harmonics}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZob{}\PYGZsq{}dtype\PYGZsq{}: \PYGZsq{}Complex harmonics\PYGZsq{},
 \PYGZsq{}kind\PYGZsq{}: \PYGZsq{}complex\PYGZsq{},
 \PYGZsq{}normType\PYGZsq{}: \PYGZsq{}ortho\PYGZsq{},
 \PYGZsq{}csPhase\PYGZsq{}: True\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot some PADs from BLMs}
\PYG{c+c1}{\PYGZsh{} Set the backend to \PYGZsq{}pl\PYGZsq{} for an interactive surface plot with Plotly}

\PYG{c+c1}{\PYGZsh{} Explict row,column layout setting for figure}
\PYG{n}{rc} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{]}  

\PYG{c+c1}{\PYGZsh{} Compute expansions from BLM parameters and return figure objext}
\PYG{n}{dataPlot}\PYG{p}{,} \PYG{n}{figObj} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{sphFromBLMPlot}\PYG{p}{(}\PYG{n}{BLM}\PYG{p}{,} \PYG{n}{facetDim}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{backend} \PYG{o}{=} \PYG{n}{plotBackend}\PYG{p}{,} \PYG{n}{rc}\PYG{o}{=}\PYG{n}{rc}\PYG{p}{,} \PYG{n}{plotFlag}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{535e89ab48f6d074d745a025de12dfbd1aa042b542393a240115022aa923122a}.png}
\caption{Examples of angular distributions (expansions in spherical harmonics \(Y_{L,M}\)), for a range of cases indexed by \(t\). Note that up\sphinxhyphen{}down asymmetry is associated with odd\sphinxhyphen{}\(l\) contributions (e.g. \(t=1,2\)), breaking of cylindrical symmetry with \(m\neq0\) terms (all \(t>0\)), and asymmetries in the (x,y) plane (skew/directionality) with different \(\pm m\) terms (magnitude or phase, e.g. \(t=2,3,4\)). Higher\sphinxhyphen{}order \(L,M\) terms have more nodes, and lead to more complex angular structures, as shown in the lower row (\(t=3,4,5\)).}\label{\detokenize{part1/theory_observables_intro_100723:fig-pads-example}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{llrrrrrr}
\toprule
  & t &    0 &    1 &    2 &    3 &    4 &    5 \\
l & m &      &      &      &      &      &      \\
\midrule
0 &  0 &  1.0 &  1.0 &  1.0 &  1.0 &  1.0 &  1.0 \\
1 &  0 &  0.0 &  0.5 &  0.8 &  1.0 &  0.5 &  0.0 \\
  & -1 &  0.0 &  0.5 &  0.8 &  1.0 &  0.5 &  0.0 \\
  &  1 &  0.0 &  0.5 & -0.5 &  1.0 &  0.5 &  0.0 \\
2 &  0 &  1.0 &  0.5 &  0.0 &  0.0 &  0.5 &  1.0 \\
4 &  2 &  0.0 &  0.0 &  0.0 &  0.5 &  0.8 &  1.0 \\
  & -2 &  0.0 &  0.0 &  0.0 &  0.0 & -0.8 &  1.0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Values used for the plots in \hyperref[\detokenize{part1/theory_observables_intro_100723:fig-pads-example}]{Fig.\@ \ref{\detokenize{part1/theory_observables_intro_100723:fig-pads-example}}}.}\label{\detokenize{part1/theory_observables_intro_100723:blm-tab}}\end{figure}

\sphinxAtStartPar
In general, the spherical harmonic rank and order \((L,M)\) of Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general} are constrained by experimental factors in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} or {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}, and \(n\) is effectively limited by the molecular alignment (which is correlated with the photon\sphinxhyphen{}order for gas phase experiments, or conservation of angular momentum in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} more generally {[}\hyperlink{cite.backmatter/bibliography:id980}{117}{]}), but in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} is defined by the maximum continuum angular momentum \(n=l_{max}\) imparted by the scattering event {[}\hyperlink{cite.backmatter/bibliography:id582}{118}{]} (note lower\sphinxhyphen{}case \(l\) here refers specifically to the continuum photoelectron wavefunction, see Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:elwf}).

\sphinxAtStartPar
For basic cases these limits may be low: for instance, a simple 1\sphinxhyphen{}photon photoionization event (\(n=1\)) from an isotropic ensemble (zero net ensemble angular momentum) defines \(L_{max}=2\); for cylindrically symmetric cases (i.e. \(D_{\infty h}\) symmetry) \(M=0\) only. For {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} cases, \(l_{max}=4\) is often given as a reasonable rule\sphinxhyphen{}of\sphinxhyphen{}thumb for the continuum \sphinxhyphen{} hence \(L_{max}=8\) \sphinxhyphen{} although in practice higher\sphinxhyphen{}\(l\) may be populated. Some realistic example cases are discussed later ({\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}), see also ref. {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]} for more discussion and complex examples.

\sphinxAtStartPar
In general, these observables may also be dependent on various other parameters; in Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general} two such parameters, \((\epsilon,t)\), are included, as the usual variables of interest. Usually \(\epsilon\) denotes the photoelectron energy, and \(t\) is used in the case of time\sphinxhyphen{}dependent (usually pump\sphinxhyphen{}probe) measurements. As discussed in \hyperref[\detokenize{part1/theory_photoionization_dynamics_140723:sec-dynamics-intro}]{Sect.\@ \ref{\detokenize{part1/theory_photoionization_dynamics_140723:sec-dynamics-intro}}}, the origin of such dependencies may be complicated but, in general, the associated photoionization matrix elements are energy\sphinxhyphen{}dependent, and time\sphinxhyphen{}dependence may also appear for a number of intrinsic or extrinsic (experimental) reasons, e.g. electronic or nuclear dynamics, rotational (alignment) dynamics, electric field dynamics etc. In many cases only one particular aspect may be of interest, so \(t\) can be used as a generic label to index changes as per \hyperref[\detokenize{part1/theory_observables_intro_100723:fig-pads-example}]{Fig.\@ \ref{\detokenize{part1/theory_observables_intro_100723:fig-pads-example}}}.


\subsection{Symmetrized harmonics}
\label{\detokenize{part1/theory_observables_intro_100723:symmetrized-harmonics}}\label{\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}}
\sphinxAtStartPar
Symmetrized (or generalised) harmonics, which essentially provide correctly symmetrized expansions of spherical harmonics (\(Y_{LM}\)) functions for a given irreducible representation, \(\Gamma\), of the molecular point\sphinxhyphen{}group can be defined by linear combinations of spherical harmonics {[}\hyperlink{cite.backmatter/bibliography:id508}{119}, \hyperlink{cite.backmatter/bibliography:id509}{120}, \hyperlink{cite.backmatter/bibliography:id555}{121}{]}:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:symHarm-defn}
\begin{split}
X_{hl}^{\Gamma\mu*}(\theta,\phi)=\sum_{\lambda}b_{hl\lambda}^{\Gamma\mu}Y_{l,\lambda}(\theta,\phi)
\end{split}
\end{equation}
\sphinxAtStartPar
where:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\Gamma\) is an irreducible representation;

\item {} 
\sphinxAtStartPar
\((l, \lambda)\) define the usual spherical harmonic indices (rank, order), but note the use of \((l, \lambda)\) by convention, since these harmonics are usually referenced to the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}};

\item {} 
\sphinxAtStartPar
\(b_{hl\lambda}^{\Gamma\mu}\) are symmetrization coefficients;

\item {} 
\sphinxAtStartPar
index \(\mu\) allows for indexing of degenerate components (note here the unfortunate convention that the label \(\mu\) is also used for photon projection terms in general, as per \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-full-tensor-expansion}}} \sphinxhyphen{} in ambiguous cases the symmetrization term will instead be labelled herein as \(\mu_X\), although in many cases may actually be redundant and safely dropped from the symmetrization coefficients);

\item {} 
\sphinxAtStartPar
\(h\) indexes cases where multiple components are required with all other quantum numbers identical.

\end{itemize}

\sphinxAtStartPar
Analogously to Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}, a general expansion of an observable in the symmetrized harmonic basis set can then be defined as:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general-symHarm}
\begin{split}
\bar{I}(\epsilon,t,\theta,\phi) = \sum_{\Gamma\mu hl}\bar{\beta}_{hl}^{\Gamma\mu}(\epsilon,t)X_{hl}^{\Gamma\mu*}(\theta,\phi)
\end{split}
\end{equation}
\sphinxAtStartPar
Alternatively, by substitution into Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}, and assigning \(l=L\) and \(\lambda=M\), a general symmetrized expansion may also be defined as:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general-symHarm-subs}
\begin{split}
\begin{align}
\bar{I}(\epsilon,t,\theta,\phi)=\sum_{\Gamma\mu h}\sum_{L=0}^{2n}\sum_{M=-L}^{L}b_{hLM}^{\Gamma\mu}\bar{\beta}_{L,M}(\epsilon,t)Y_{L,M}(\theta,\phi)
\end{align}
\end{split}
\end{equation}
\sphinxAtStartPar
However, in many cases the symmetrization coefficients are subsumed into the \(\beta_{L,M}\) terms (or underlying matrix elements); in this case a simplified symmetrized expansion can be defined as:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general-sym-betas}
\begin{split}
\begin{align}
\bar{I}^{\Gamma}(\epsilon,t,\theta,\phi)=\sum_{L=0}^{2n}\sum_{M=-L}^{L}\bar{\beta}^{\Gamma}_{L,M}(\epsilon,t)Y_{L,M}(\theta,\phi)
\end{align}
\end{split}
\end{equation}
\sphinxAtStartPar
Where the expansion is defined for a given symmetry and irreducible representation with the shorthand \(\Gamma\); in many systems a single label may be sufficient here, since allowed \((L,M)\) terms will be defined uniquely by irreducible representation, although multiple quantum numbers may be required for unique definition in the most general cases as per Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:symHarm-defn} (e.g. for cases with degenerate components). Further details and usage in relation to channel functions are also discussed in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}} (see, in particular, Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns} for a similar general case), and in relation to fitting for specific cases in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}.

\sphinxAtStartPar
The exact form of these coefficients will depend on the point\sphinxhyphen{}group of the system, see, e.g. Refs. {[}\hyperlink{cite.backmatter/bibliography:id555}{121}, \hyperlink{cite.backmatter/bibliography:id839}{122}{]}. Numerical routines for the generation of symmetrized harmonics are implemented in \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}: point\sphinxhyphen{}groups, character table generation and symmetrization (computing \(b_{hl\lambda}^{\Gamma\mu}\) parameters) is handled by \sphinxhref{https://github.com/mcodev31/libmsym}{\sphinxcode{\sphinxupquote{libmsym}}} {[}\hyperlink{cite.backmatter/bibliography:id708}{64}, \hyperlink{cite.backmatter/bibliography:id709}{65}{]}; additional handling also makes use of \sphinxhref{https://shtools.oca.eu}{\sphinxcode{\sphinxupquote{pySHtools}}} {[}\hyperlink{cite.backmatter/bibliography:id888}{60}, \hyperlink{cite.backmatter/bibliography:id957}{61}, \hyperlink{cite.backmatter/bibliography:id958}{62}, \hyperlink{cite.backmatter/bibliography:id959}{63}{]}.

\sphinxAtStartPar
A brief numerical example is given below, and more details can be found in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}. In this case, full tabulations of the parameters list all \(b_{hLM}^{\Gamma\mu}\) for each irreducible representation, and the corresponding PADs are illustrated in \hyperref[\detokenize{part1/theory_observables_intro_100723:fig-symharmpads-example}]{Fig.\@ \ref{\detokenize{part1/theory_observables_intro_100723:fig-symharmpads-example}}}.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Full tabulations of the parameters available in HTML or notebook formats only.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Import class}
\PYG{k+kn}{from} \PYG{n+nn}{pemtk}\PYG{n+nn}{.}\PYG{n+nn}{sym}\PYG{n+nn}{.}\PYG{n+nn}{symHarm} \PYG{k+kn}{import} \PYG{n}{symHarm}

\PYG{c+c1}{\PYGZsh{} Compute hamronics for Td, lmax=4}
\PYG{n}{sym} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Td}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{lmax}\PYG{o}{=}\PYG{l+m+mi}{6}

\PYG{n}{symObj} \PYG{o}{=} \PYG{n}{symHarm}\PYG{p}{(}\PYG{n}{sym}\PYG{p}{,}\PYG{n}{lmax}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Character tables can be displayed \PYGZhy{} this will render directly in a notebook.}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{printCharacterTable}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{lllllll}
\toprule
   &   &    E &  C2\textasciicircum 1 &  S4\textasciicircum 1 &    σd &  C3\textasciicircum 1 \\
Character & dim &      &       &       &       &       \\
\midrule
A1 & 1 &  1.0 &   1.0 &   1.0 &   1.0 &   1.0 \\
A2 & 1 &  1.0 &   1.0 &  -1.0 &  -1.0 &   1.0 \\
E & 2 &  2.0 &   2.0 &   0.0 &   0.0 &  -1.0 \\
T1 & 3 &  3.0 &  -1.0 &   1.0 &  -1.0 &   0.0 \\
T2 & 3 &  3.0 &  -1.0 &  -1.0 &   1.0 &   0.0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Example character table for \DUrole{pasted-text}{Td} symmetry generated with the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} wrapper for \sphinxhref{https://github.com/mcodev31/libmsym}{\sphinxcode{\sphinxupquote{libmsym}}} {[}\hyperlink{cite.backmatter/bibliography:id708}{64}, \hyperlink{cite.backmatter/bibliography:id709}{65}{]}.}\label{\detokenize{part1/theory_observables_intro_100723:tab-chartable-example}}\end{figure}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The full set of expansion parameters can be tabulated}

\PYG{c+c1}{\PYGZsh{} pd.set\PYGZus{}option(\PYGZsq{}display.max\PYGZus{}rows\PYGZsq{}, 100)}

\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Display values (note this defaults to REAL harmonics)}
\PYG{c+c1}{\PYGZsh{} symObj.displayXlm(YlmType=\PYGZsq{}comp\PYGZsq{})   \PYGZsh{} Display values for COMPLEX harmonic expansion.}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To plot using ePSproc/PEMtk class, these values can be converted to ePSproc BLM data type...}

\PYG{c+c1}{\PYGZsh{} Run conversion \PYGZhy{} the default is to set the coeffs to the \PYGZsq{}BLM\PYGZsq{} data type}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{toePSproc}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set to new key in data class}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symHarm}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}

\PYG{k}{for} \PYG{n}{dataType} \PYG{o+ow}{in} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{:}  \PYG{c+c1}{\PYGZsh{}[\PYGZsq{}matE\PYGZsq{},\PYGZsq{}BLM\PYGZsq{}]:}
    \PYG{c+c1}{\PYGZsh{} Select expansion in complex harmonics}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symHarm}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]} \PYG{o}{=} \PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b (comp)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}  
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symHarm}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{o}{.}\PYG{n}{attrs} \PYG{o}{=} \PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{o}{.}\PYG{n}{attrs}
    
\PYG{c+c1}{\PYGZsh{} Plot full harmonics expansions, plots by symmetry}
\PYG{c+c1}{\PYGZsh{} Note \PYGZsq{}squeeze=True\PYGZsq{} to force drop of singleton dims may be required.}
\PYG{c+c1}{\PYGZsh{} data.padPlot(keys=\PYGZsq{}symHarm\PYGZsq{},dataType=\PYGZsq{}BLM\PYGZsq{}, facetDims = [\PYGZsq{}Cont\PYGZsq{}], squeeze = True, backend=plotBackend)}

\PYG{c+c1}{\PYGZsh{} As above, with some additional layout options}
\PYG{n}{rc} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{]}  \PYG{c+c1}{\PYGZsh{} Explict layout setting}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{padPlot}\PYG{p}{(}\PYG{n}{keys}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symHarm}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{dataType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{facetDims} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cont}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{squeeze} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{n}{plotBackend}\PYG{p}{,} 
             \PYG{n}{rc} \PYG{o}{=} \PYG{n}{rc}\PYG{p}{,} \PYG{n}{plotFlag}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,} \PYG{n}{returnFlag}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{figObj} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symHarm}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{polar}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} And GLUE for display later with caption}
\PYG{n}{gluePlotly}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{symHarmPADs}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{figObj}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{2761c00d3b9766092516663fd674aed92f287503c4cbe62eda3ded917e537df3}.png}
\caption{Examples of angular distributions from expansions in symmetrized harmonics \(X_{hl}^{\Gamma\mu*}(\theta,\phi)\), for all irreducible representations in \DUrole{pasted-text}{Td} symmetry (\(l_{max}=\)\DUrole{pasted-text}{6}). (Note \(A_2\) only has components for \(l\geq 6\).)}\label{\detokenize{part1/theory_observables_intro_100723:fig-symharmpads-example}}\end{figure}


\subsubsection{Real \& complex forms}
\label{\detokenize{part1/theory_observables_intro_100723:real-complex-forms}}
\sphinxAtStartPar
By convention, the complex form of the spherical harmonics are usually used for photoionization problems. However, real harmonics are also in common use (and have already appeared in the numerical routines above). The relationships can be defined as any of the following sets of equations (per \sphinxhref{https://en.wikipedia.org/wiki/Spherical\_harmonics\#Real\_form}{the Wikipaedia definitions} {[}\hyperlink{cite.backmatter/bibliography:id963}{123}{]}):
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:re-complex-YLM}
\begin{split}
\begin{aligned}
Y_{\ell m}&={\begin{cases}{\dfrac {i}{\sqrt {2}}}\left(Y_{\ell }^{m}-(-1)^{m}\,Y_{\ell }^{-m}\right)&{\text{if}}\ m\lt0
\\Y_{\ell }^{0}&{\text{if}}\ m=0
\\{\dfrac {1}{\sqrt {2}}}\left(Y_{\ell }^{-m}+(-1)^{m}\,Y_{\ell }^{m}\right)&{\text{if}}\ m\gt0.\end{cases}}
\\&={\begin{cases}{\dfrac {i}{\sqrt {2}}}\left(Y_{\ell }^{-|m|}-(-1)^{m}\,Y_{\ell }^{|m|}\right)&{\text{if}}\ m\lt0
\\Y_{\ell }^{0}&{\text{if}}\ m=0
\\{\dfrac {1}{\sqrt {2}}}\left(Y_{\ell }^{-|m|}+(-1)^{m}\,Y_{\ell }^{|m|}\right)&{\text{if}}\ m\gt0.\end{cases}}
\\&={\begin{cases}{\sqrt {2}}\,(-1)^{m}\,\Im [{Y_{\ell }^{|m|}}]&{\text{if}}\ m\lt0
\\Y_{\ell }^{0}&{\text{if}}\ m=0
\\{\sqrt {2}}\,(-1)^{m}\,\Re [{Y_{\ell }^{m}}]&{\text{if}}\ m\gt0.\end{cases}}
\end{aligned}
\end{split}
\end{equation}
\sphinxAtStartPar
Where the notation here uses \(Y_{\ell m}\) for real harmonics, and \(Y_{\ell }^{m}\) for complex.

\sphinxAtStartPar
Conversion between types is handled in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} either directly or via the \sphinxhref{https://shtools.oca.eu}{\sphinxcode{\sphinxupquote{pySHtools}}} {[}\hyperlink{cite.backmatter/bibliography:id888}{60}, \hyperlink{cite.backmatter/bibliography:id957}{61}, \hyperlink{cite.backmatter/bibliography:id958}{62}, \hyperlink{cite.backmatter/bibliography:id959}{63}{]} library, and objects usually have the type specified in their metadata (if missing, they are assumed to be complex). The symmetry routines outlined above automatically compute both types, and these are available in the output data structure (see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for further details and examples, and the \sphinxhref{https://epsproc.readthedocs.io/en/dev/special\_topics/ePSproc\_docs\_working\_with\_real\_harmonics\_220922.html}{“Working with real spherical harmonics”} note from the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, and the \sphinxhref{https://shtools.github.io/SHTOOLS/real-spherical-harmonics.html}{relevant pySHtools documentation pages}).

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Display complex values}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{n}{YlmType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{comp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Display values for COMPLEX harmonic expansion.}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Access complex values from SH tools objects}
\PYG{c+c1}{\PYGZsh{} SHtools object are stored in nested dicts by character and type}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SH}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SH}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{comp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}real\PYGZsq{}, \PYGZsq{}comp\PYGZsq{}])
kind = \PYGZsq{}complex\PYGZsq{}
normalization = \PYGZsq{}4pi\PYGZsq{}
csphase = \PYGZhy{}1
lmax = 6
error\PYGZus{}kind = None
header = None
header2 = None
name = None
units = None
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Similarly Xarray forms include both types}
\PYG{n}{symObj}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{XR}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\subsection{Legendre polynomials}
\label{\detokenize{part1/theory_observables_intro_100723:legendre-polynomials}}
\sphinxAtStartPar
Finally, it is of note that Legendre polynomial expansions are also in common use in the description of photoionization obsevables. These are suitable for cylindrically symmetric cases only, and form a subset of the general spherical harmonic case. Using the same notation as Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}, the 1D expansion can be given as:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:AF-PAD-Lg}
\begin{split}
\bar{I}(\epsilon,t,\theta)=\sum_{L=0}^{2n}\bar{\beta}_{L}(\epsilon,t)P_{L}(\cos(\theta))
\end{split}
\end{equation}
\sphinxAtStartPar
Where \(P_{L}(\cos(\theta))\) are Legendre polynomials in \(\cos(\theta)\) (equivalently, associated Legendre polynomials \(P_{L}^{M=0}(\cos(\theta))\)). Note that, since the normalisation is different, care must be taken when comparing associated anisotropy parameters between Legendre polynomial and spherical harmonic expansions. Specifically:
\begin{equation}\label{equation:part1/theory_observables_intro_100723:eq:Lg-Sph-conv}
\begin{split}
\beta^{Sph}_{L,0} = \sqrt{(2L+1)/4\pi}\beta^{Lg}_{L}
\end{split}
\end{equation}
\sphinxAtStartPar
Where \(Sph\) and \(Lg\) labels have been added to make explicit that the expansion parameters in the spherical harmonic and Legndre polynomial basis sets respectively.

\sphinxAtStartPar
Herein only spherical harmonic expansions are used, but the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} does include a conversion routine to convert expansion parameters as required. Again more information can be found in the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, particularly the \sphinxhref{https://epsproc.readthedocs.io/en/dev/special\_topics/ePSproc\_docs\_working\_with\_spherical\_harmonics\_200922.html}{“Working with spherical harmonics”} notebook.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set example BLMs and convert to Lg basis}
\PYG{c+c1}{\PYGZsh{} Note \PYGZsq{}renorm=True\PYGZsq{} setting to renorm by B0 (will affect abs value of B0, but not form of distribution)}
\PYG{c+c1}{\PYGZsh{} Note also \PYGZsq{}harmonics\PYGZsq{} and \PYGZsq{}normType\PYGZsq{} specifications in output data.}

\PYG{n}{BLMsph} \PYG{o}{=} \PYG{n}{setBLMs}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.8}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{n}{drop}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{BLMlg} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{util}\PYG{o}{.}\PYG{n}{conversion}\PYG{o}{.}\PYG{n}{conv\PYGZus{}BL\PYGZus{}BLM}\PYG{p}{(}\PYG{n}{BLMsph}\PYG{p}{,} \PYG{n}{to} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{renorm} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{BLMlg}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\subsection{Time\sphinxhyphen{}resolved data}
\label{\detokenize{part1/theory_observables_intro_100723:time-resolved-data}}\label{\detokenize{part1/theory_observables_intro_100723:sect-theory-time-resolved-data}}
\sphinxAtStartPar
In general, the datasets from a time\sphinxhyphen{}resolved measurement can be expressed as some form of {\hyperref[\detokenize{backmatter/glossary:term-anisotropy-paramters}]{\sphinxtermref{\DUrole{xref,std,std-term}{anisotropy paramters}}}}, as outlined above. In a similar manner to the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} detailed in \hyperref[\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}]{Sect.\@ \ref{\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}}}, the \(\beta_{L,M}(t)\) can be plotted directly, or expanded as distributions \(I(\epsilon,t,\theta,\phi...)\). A brief demonstration is given below, making use of the \(N_2\) dataset explored in the case study in \hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{Chpt.\@ \ref{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}}, for further details of the computational and plotting tools see {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}, and the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]} and \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Configure settings for case study}
\PYG{c+c1}{\PYGZsh{} \PYGZpc{}run \PYGZsq{}../scripts/setup\PYGZus{}notebook.py\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Fitting setup including data generation and parameter creation}
\PYG{c+c1}{\PYGZsh{} NOTE this assumes relevant data is available in ../part2/n2fitting.}
\PYG{c+c1}{\PYGZsh{} See Part 2 for more details and data sources}
\PYG{n}{fitSystem} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{N2}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{dataName} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2fitting}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Set datapath, }
\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{Path}\PYG{o}{.}\PYG{n}{cwd}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{parent}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{part2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{dataName}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run general config script with dataPath set above}
\PYG{o}{\PYGZpc{}}\PYG{k}{run} \PYGZdq{}../scripts/setup\PYGZus{}fit\PYGZus{}case\PYGZhy{}studies\PYGZus{}270723.py\PYGZdq{} \PYGZhy{}d \PYGZob{}dataPath\PYGZcb{} \PYGZhy{}c \PYGZob{}fitSystem\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute AFBLMs for all matrix elements (energies) for selected orbital}
\PYG{c+c1}{\PYGZsh{} (Note the main fitting script only computes for a single E\PYGZhy{}point.)}
\PYG{c+c1}{\PYGZsh{} Use ADMs from fitting subset}
\PYG{n}{orbKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{orb5}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{AFBLM}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{n}{orbKey}\PYG{p}{,} \PYG{n}{AKQS} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}
           \PYG{n}{selDims} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}2}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Calculating AF\PYGZhy{}BLMs for job key: orb5
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
In this case, making use of \sphinxstyleemphasis{ab initio} {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, a full set of \(\beta_{L,M}(\epsilon,t)\) are computed, for the ionizing channel(s) defined (in this case as labelled by the \sphinxcode{\sphinxupquote{orbKey}} parameter). These can be plotted vs. energy or time as line\sphinxhyphen{}plots or colourmaps. The \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} currently has some basic routines for some specific cases, or low\sphinxhyphen{}level functionality from the base libraries can be used for more control.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Default plot with Holoviews/Bokeh}
\PYG{c+c1}{\PYGZsh{} Will plot BLM(E,t) data with selectors \PYGZam{} sliders for other dimensions}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMplot}\PYG{p}{(}\PYG{n}{keys}\PYG{o}{=}\PYG{n}{orbKey}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
BLMplot set data and plots to self.plots[\PYGZsq{}BLMplot\PYGZsq{}]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
:HoloMap   [Orb,t]
   :NdOverlay   [l,m]
      :Curve   [Eke]   (BLM)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
True
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} For a full BLM(E,t) surface, the output Holoviews dataset can be used.}
\PYG{c+c1}{\PYGZsh{} See the Holoviews (https://holoviews.org) and HVplot (https://hvplot.holoviz.org) docs for more details}

\PYG{c+c1}{\PYGZsh{} Set opts to match sizes \PYGZhy{} should be able to link plots or set gridspace to handle this?}
\PYG{n}{ep}\PYG{o}{.}\PYG{n}{plot}\PYG{o}{.}\PYG{n}{hvPlotters}\PYG{o}{.}\PYG{n}{setPlotDefaults}\PYG{p}{(}\PYG{n}{fSize} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{750}\PYG{p}{,}\PYG{l+m+mi}{300}\PYG{p}{]}\PYG{p}{,} \PYG{n}{imgSize} \PYG{o}{=} \PYG{l+m+mi}{600}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot heatmap for l=2 vs. Eke and add ADM plot to layout with hvplot}
\PYG{n}{daLayout} \PYG{o}{=} \PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{plots}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMplot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{hvDS}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{select}\PYG{p}{(}\PYG{n}{l}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{to}\PYG{p}{(}\PYG{n}{hv}\PYG{o}{.}\PYG{n}{HeatMap}\PYG{p}{,} \PYG{n}{kdims}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Eke}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{opts}\PYG{p}{(}\PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{coolwarm}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}  \PYG{o}{+} 
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{unstack}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{K}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{real}\PYG{o}{.}\PYG{n}{hvplot}\PYG{o}{.}\PYG{n}{line}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{overlay}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{K}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{cols}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{68c953227ba43f23fd86e606d48b00628590e34e55a3c3ba4cf09d6a91f4364c}.png}
\caption{Example \(I(\epsilon,t)\) data, computed for \(N_2\) (upper panel), and the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} used in the calculation (lower panel).}\label{\detokenize{part1/theory_observables_intro_100723:fig-n2blmtdemo}}\end{figure}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Similarly, AFPADs can be plotted.}
\PYG{c+c1}{\PYGZsh{} Plot I(theta,t) for a single E}
\PYG{c+c1}{\PYGZsh{} \PYGZpc{}matplotlib inline}
\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}  \PYG{c+c1}{\PYGZsh{} Use subset data set for fitting}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{padPlot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{n}{dataKey}\PYG{p}{,} \PYG{n}{dataType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{selDims}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Labels}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
             \PYG{n}{Etype} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{pStyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{grid}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{reducePhi}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sum}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
             \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Using default sph betas.
Summing over dims: set()
Plotting from self.data[subset][AFBLM], facetDims=[\PYGZsq{}t\PYGZsq{}, None], pType=a with backend=mpl.
Grid plot: 3sg\PYGZhy{}1, dataType: AFBLM, plotType: a
Set plot to self.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}plots\PYGZsq{}][\PYGZsq{}AFBLM\PYGZsq{}][\PYGZsq{}grid\PYGZsq{}]
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{f675e6197a39e464377251278227d84c5880bedcd00046d65eba340f4d842504}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot I(theta,phi) at selected (E,t)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{padPlot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{n}{dataKey}\PYG{p}{,} \PYG{n}{dataType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{selDims}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Labels}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
             \PYG{n}{Erange}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{,} \PYG{n}{Etype} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pl}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} And GLUE for display later with caption}
\PYG{n}{figObj} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{polar}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{N2AFPADsdemo}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{figObj}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{37ba3d1be5c7a7f940e60e1878f4e179fbbcbba2e80be06c883ce47e51679e0f}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} (\(I(\theta,\phi;\epsilon,t)\)) example for \(N_2\) at selected \((\epsilon,t)\). In this demo case the alignment and {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} are “1D”, and cylindrically symmetric.}\label{\detokenize{part1/theory_observables_intro_100723:fig-n2afpadsdemo}}\end{figure}

\sphinxstepscope


\section{Information content \& sensitivity}
\label{\detokenize{part1/theory_info_content_200723:information-content-sensitivity}}\label{\detokenize{part1/theory_info_content_200723:sec-info-content}}\label{\detokenize{part1/theory_info_content_200723::doc}}
\sphinxAtStartPar
A useful tool in considering the possibility of matrix element retrieval is the response, or sensitivity, of the experimental observables to the matrix elements of interest. Aspects of this have already been explored in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}, where consideration of the various geometric tensors (or geometric basis set) provided a route to investigating the coupling \sphinxhyphen{} hence sensitivity \sphinxhyphen{} of various parameters into product terms. In particular the tensor products discussed in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}}}, including the full channel (response) functions \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\) (\eqref{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-MF-defn} and \eqref{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-AF-defn}), can be used to examine the overall sensitivity of a given measurement to the underlying observables. By careful consideration of the problem at hand, experiments may then be tailored for particular cases based on these sensitivities. A related question, is how a given experimental sensitivity might be more readily quantified, and interpreted, for reconstruction problems, in a simpler manner. In general, this can be termed as the \sphinxstyleemphasis{information content} of the measurement(s); an important aspect of such a metric is that it should be readily interpretable and, ideally, related to whether a reconstruction will be possible in a given case (this has, for example, been considered by other authors for specific cases, e.g. Refs. {[}\hyperlink{cite.backmatter/bibliography:id835}{113}, \hyperlink{cite.backmatter/bibliography:id870}{124}{]}).

\sphinxAtStartPar
Work in this direction is ongoing, and some thoughts are given below. In particular, the use of the observable \(\beta_{L,M}\) presents an experimental route to (roughly) define a form of information content, whilst metrics derived from channel functions or density matrices may present a more rigorous theoretical route to a useful parameterization of information content.


\subsection{Numerical setup}
\label{\detokenize{part1/theory_info_content_200723:numerical-setup}}
\sphinxAtStartPar
This follows the setup in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}} {\hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{\sphinxcrossref{\DUrole{std,std-ref}{Tensor formulation of photoionization}}}}, using a symmetry\sphinxhyphen{}based set of basis functions for demonstration purposes. (Repeated code is hidden in PDF version.)


\subsection{Experimental information content}
\label{\detokenize{part1/theory_info_content_200723:experimental-information-content}}\label{\detokenize{part1/theory_info_content_200723:sec-expt-info-content}}
\sphinxAtStartPar
As discussed in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}, the information content of a single observable might be regarded as simply the number of contributing \(\beta_{L,M}\) parameters. In set notation:
\begin{equation}\label{equation:part1/theory_info_content_200723:eq:BLM-set}
\begin{split}M=\mathrm{n}\{\beta_{L,M}\}\end{split}
\end{equation}
\sphinxAtStartPar
where \(M\) is the information content of the measurement, defined as
\(\mathrm{n}\{...\}\) the cardinality (number of elements) of the set of
contributing parameters. A set of measurements, made for some
experimental variable \(u\), will then have a total information content:
\begin{equation*}
\begin{split}M_{u}=\sum_{u}\mathrm{n}\{\beta_{L,M}^{u}\}\end{split}
\end{equation*}
\sphinxAtStartPar
In the case where a single measurement contains multiple \(\beta_{L,M}\),
e.g. as a function of energy \(\epsilon\) or time \(t\), the information
content will naturally be larger:
\begin{equation*}
\begin{split}\begin{aligned}
M_{u,\epsilon,t} & = & \sum_{u,\epsilon,t}\mathrm{n}\{\beta_{L,M}^{u}(\epsilon,t)\}\\
 & = & M_{u}\times M_{\epsilon,t}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where the second line pertains if each measurement has the same native
information content, independent of \(u\). It may be that the variable \(\epsilon\)
is continuous (e.g. photoelectron energy), but in practice it will
usually be discretized in some fashion by the measurement.

\sphinxAtStartPar
In terms of purely experimental methodologies, a larger \(M_{u}\) clearly
defines a richer experimental measurement which explores more of the
total measurement space spanned by the full set of
\(\{\beta_{L,M}^{u}(\epsilon,t)\}\). However, in this basic definition a larger
\(M_{u}\) does not necessarily indicate a higher information content for
quantum retrieval applications. The reason for this is simply down to
the complexity of the problem (cf. Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}), in which many couplings define the sensitivity of the observable to the underlying system properties of
interest. In this sense, more measurements, and larger \(M\), may only add
redundancy, rather than new information.

\sphinxAtStartPar
From a set of numerical results, it is relatively trivial to investigate some of these properties as a function of various constraints, using standard Python functionality, as shown in the code blocks below. For example, \(M\) can be determined numerically as the number of elements in the dataset, the number of \sphinxstyleemphasis{unique} elements, the number of elements within a certain range or above a threshold, and so on.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} For the basic case, the data (Xarray object) can be queried, }
\PYG{c+c1}{\PYGZsh{} and relevant dimensions investigated}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Available dimensions: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{BetaNorm}\PYG{o}{.}\PYG{n}{dims}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Show BLM dimension details from Xarray dataset}
\PYG{n}{display}\PYG{p}{(}\PYG{n}{BetaNorm}\PYG{o}{.}\PYG{n}{BLM}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Available dimensions: (\PYGZsq{}Labels\PYGZsq{}, \PYGZsq{}t\PYGZsq{}, \PYGZsq{}Type\PYGZsq{}, \PYGZsq{}it\PYGZsq{}, \PYGZsq{}Eke\PYGZsq{}, \PYGZsq{}h\PYGZsq{}, \PYGZsq{}muX\PYGZsq{}, \PYGZsq{}BLM\PYGZsq{})
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}xarray.DataArray \PYGZsq{}BLM\PYGZsq{} (BLM: 9)\PYGZgt{}
array([(0, \PYGZhy{}1), (0, 0), (0, 1), (1, \PYGZhy{}1), (1, 0), (1, 1), (2, \PYGZhy{}1), (2, 0),
       (2, 1)], dtype=object)
Coordinates:
  * BLM      (BLM) MultiIndex
  \PYGZhy{} l        (BLM) int64 0 0 0 1 1 1 2 2 2
  \PYGZhy{} m        (BLM) int64 \PYGZhy{}1 0 1 \PYGZhy{}1 0 1 \PYGZhy{}1 0 1
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Note, however, that the indexes may not always be physical, }
\PYG{c+c1}{\PYGZsh{} depending on how the data has been composed and cleaned up.}
\PYG{c+c1}{\PYGZsh{} For example, the above has l=0, m=+/\PYGZhy{}1 cases, which are non\PYGZhy{}physical.}

\PYG{c+c1}{\PYGZsh{} Clean array to remove terms |m|\PYGZgt{}l, and display}
\PYG{n}{cleanBLMs}\PYG{p}{(}\PYG{n}{BetaNorm}\PYG{p}{)}\PYG{o}{.}\PYG{n}{BLM}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}xarray.DataArray \PYGZsq{}BLM\PYGZsq{} (BLM: 7)\PYGZgt{}
array([(0, 0), (1, \PYGZhy{}1), (1, 0), (1, 1), (2, \PYGZhy{}1), (2, 0), (2, 1)], dtype=object)
Coordinates:
  * BLM      (BLM) MultiIndex
  \PYGZhy{} l        (BLM) int64 0 1 1 1 2 2 2
  \PYGZhy{} m        (BLM) int64 0 \PYGZhy{}1 0 1 \PYGZhy{}1 0 1
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Thresholding can also be used to reduce the results}
\PYG{n}{ep}\PYG{o}{.}\PYG{n}{matEleSelector}\PYG{p}{(}\PYG{n}{BetaNorm}\PYG{p}{,} \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}4}\PYG{p}{)}\PYG{o}{.}\PYG{n}{BLM}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}xarray.DataArray \PYGZsq{}BLM\PYGZsq{} (BLM: 2)\PYGZgt{}
array([(0, 0), (2, 0)], dtype=object)
Coordinates:
  * BLM      (BLM) MultiIndex
  \PYGZhy{} l        (BLM) int64 0 2
  \PYGZhy{} m        (BLM) int64 0 0
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The index can be returned as a Pandas object, and statistical routines applied...}
\PYG{c+c1}{\PYGZsh{} For example, nunique() will provide the number of unique values.}

\PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}4}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Original array M=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{BetaNorm}\PYG{o}{.}\PYG{n}{BLM}\PYG{o}{.}\PYG{n}{indexes}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{nunique}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cleaned array M=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{cleanBLMs}\PYG{p}{(}\PYG{n}{BetaNorm}\PYG{p}{)}\PYG{o}{.}\PYG{n}{BLM}\PYG{o}{.}\PYG{n}{size}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Thresholded array (thres=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{thres}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{), }\PYG{l+s+se}{\PYGZbs{}}
\PYG{l+s+s2}{      M=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{ep}\PYG{o}{.}\PYG{n}{matEleSelector}\PYG{p}{(}\PYG{n}{BetaNorm}\PYG{p}{,}\PYG{+w}{ }\PYG{n}{thres}\PYG{o}{=}\PYG{n}{thres}\PYG{p}{)}\PYG{o}{.}\PYG{n}{BLM}\PYG{o}{.}\PYG{n}{indexes}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{nunique}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Original array M=9
Cleaned array M=7
Thresholded array (thres=0.0001),       M=2
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
For more complicated cases, with \(u>1\), e.g. time\sphinxhyphen{}dependent measurements, interrogating the statistics of the observables may also be an interesting avenue to explore. The examples below investigate this for the example “linear ramp” {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} case. Here the statistical analysis is, potentially, a measure of the useful/non\sphinxhyphen{}redundant information content, for instance the range or variance in a particular observable can be analysed, as can the number of unique values and so forth.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Convert to PD and tabulate with epsproc functionality}
\PYG{c+c1}{\PYGZsh{} Note restack along \PYGZsq{}t\PYGZsq{} dimension}
\PYG{n}{BetaNormLinearADMsPD}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{util}\PYG{o}{.}\PYG{n}{multiDimXrToPD}\PYG{p}{(}\PYG{n}{BetaNormLinearADMs}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{real}\PYG{p}{,} 
                                                 \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}4}\PYG{p}{,} \PYG{n}{colDims}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Basic describe with Pandas, }
\PYG{c+c1}{\PYGZsh{} see https://pandas.pydata.org/docs/user\PYGZus{}guide/basics.html\PYGZsh{}summarizing\PYGZhy{}data\PYGZhy{}describe}
\PYG{c+c1}{\PYGZsh{} This will give properties per t}
\PYG{n}{BetaNormLinearADMsPD}\PYG{o}{.}\PYG{n}{describe}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrrrrrr}
\toprule
t &      0 &       1 &       2 &       3 &       4 &       5 &       6 &       7 &       8 &       9 \\
\midrule
count &  5.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 \\
mean  & -0.169 &  -0.074 &  -0.063 &  -0.052 &  -0.041 &  -0.031 &  -0.020 &  -0.009 &   0.002 &   0.012 \\
std   &  0.158 &   0.126 &   0.115 &   0.104 &   0.093 &   0.083 &   0.073 &   0.065 &   0.058 &   0.053 \\
min   & -0.282 &  -0.254 &  -0.226 &  -0.198 &  -0.170 &  -0.142 &  -0.114 &  -0.086 &  -0.058 &  -0.038 \\
25\%   & -0.282 &  -0.201 &  -0.179 &  -0.157 &  -0.135 &  -0.113 &  -0.092 &  -0.072 &  -0.052 &  -0.030 \\
50\%   & -0.282 &  -0.002 &  -0.004 &  -0.006 &  -0.008 &  -0.010 &  -0.011 &  -0.009 &  -0.007 &  -0.005 \\
75\%   & -0.045 &   0.004 &   0.008 &   0.011 &   0.015 &   0.019 &   0.023 &   0.027 &   0.031 &   0.034 \\
max   &  0.045 &   0.050 &   0.054 &   0.059 &   0.064 &   0.069 &   0.075 &   0.088 &   0.100 &   0.113 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Basic describe with Pandas, }
\PYG{c+c1}{\PYGZsh{} see https://pandas.pydata.org/docs/user\PYGZus{}guide/basics.html\PYGZsh{}summarizing\PYGZhy{}data\PYGZhy{}describe}
\PYG{c+c1}{\PYGZsh{} By transposing the input array, this will give properties per BLM}
\PYG{n}{BetaNormLinearADMsPD}\PYG{o}{.}\PYG{n}{T}\PYG{o}{.}\PYG{n}{describe}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrrrrrr}
\toprule
h & \multicolumn{2}{l}{0} & \multicolumn{4}{l}{1} & \multicolumn{4}{l}{2} \\
l &       0 &      2 &       0 &       2 &      4 &      6 &       0 &       2 &      4 &          6 \\
m &       0 &      0 &       0 &       0 &      0 &      0 &       0 &       0 &      0 &          0 \\
\midrule
count &  10.000 &  9.000 &  10.000 &  10.000 &  9.000 &  9.000 &  10.000 &  10.000 &  9.000 &  9.000e+00 \\
mean  &  -0.156 &  0.063 &  -0.156 &   0.066 &  0.021 &  0.012 &  -0.156 &  -0.029 & -0.021 &  1.669e-03 \\
std   &   0.085 &  0.034 &   0.085 &   0.014 &  0.012 &  0.007 &   0.085 &   0.011 &  0.011 &  9.140e-04 \\
min   &  -0.282 &  0.013 &  -0.282 &   0.045 &  0.004 &  0.002 &  -0.282 &  -0.045 & -0.038 &  3.337e-04 \\
25\%   &  -0.219 &  0.038 &  -0.219 &   0.056 &  0.013 &  0.007 &  -0.219 &  -0.037 & -0.029 &  1.001e-03 \\
50\%   &  -0.156 &  0.063 &  -0.156 &   0.066 &  0.021 &  0.012 &  -0.156 &  -0.029 & -0.021 &  1.669e-03 \\
75\%   &  -0.093 &  0.088 &  -0.093 &   0.077 &  0.030 &  0.017 &  -0.093 &  -0.021 & -0.013 &  2.336e-03 \\
max   &  -0.030 &  0.113 &  -0.030 &   0.088 &  0.038 &  0.022 &  -0.030 &  -0.013 & -0.004 &  3.004e-03 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
For further insight and control, specific aggregation functions and criteria can be specified. For instance, it may be interesting to look at the number of unique values to a certain precision (e.g. depending on experimental uncertainties), or consider deviation of values from the mean.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Round values to 2 d.p., then apply statistical methods}
\PYG{n}{ndp} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{n}{BetaNormLinearADMsPD}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{n}{ndp}\PYG{p}{)}\PYG{o}{.}\PYG{n}{agg}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{min}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{var}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{nunique}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrrrrrr}
\toprule
t &      0 &       1 &       2 &       3 &       4 &       5 &       6 &       7 &       8 &       9 \\
\midrule
min     & -0.280 &  -0.250 &  -0.230 &  -0.200 &  -0.170 &  -0.140 &  -0.110 &  -0.090 &  -0.060 &  -0.040 \\
max     &  0.040 &   0.050 &   0.050 &   0.060 &   0.060 &   0.070 &   0.080 &   0.090 &   0.100 &   0.110 \\
var     &  0.024 &   0.015 &   0.014 &   0.011 &   0.009 &   0.007 &   0.005 &   0.004 &   0.003 &   0.003 \\
count   &  5.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 &  10.000 \\
nunique &  3.000 &   5.000 &   7.000 &   7.000 &   8.000 &   8.000 &   8.000 &   8.000 &   8.000 &   8.000 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Define demean function and apply (from https://stackoverflow.com/a/26110278)}
\PYG{n}{demean} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{x} \PYG{o}{\PYGZhy{}} \PYG{n}{x}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute differences from mean}
\PYG{n}{BetaNormLinearADMsPD}\PYG{o}{.}\PYG{n}{transform}\PYG{p}{(}\PYG{n}{demean}\PYG{p}{,}\PYG{n}{axis}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{columns}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllrrrrrrrrrr}
\toprule
  &   & t &      0 &      1 &      2 &          3 &          4 &          5 &          6 &          7 &      8 &      9 \\
h & l & m &        &        &        &            &            &            &            &            &        &        \\
\midrule
0 & 0 & 0 & -0.126 & -0.098 & -0.070 & -4.205e-02 & -1.402e-02 &  1.402e-02 &  4.205e-02 &  7.009e-02 &  0.098 &  0.126 \\
  & 2 & 0 &    NaN & -0.050 & -0.038 & -2.508e-02 & -1.254e-02 &  0.000e+00 &  1.254e-02 &  2.508e-02 &  0.038 &  0.050 \\
1 & 0 & 0 & -0.126 & -0.098 & -0.070 & -4.205e-02 & -1.402e-02 &  1.402e-02 &  4.205e-02 &  7.009e-02 &  0.098 &  0.126 \\
  & 2 & 0 & -0.022 & -0.017 & -0.012 & -7.172e-03 & -2.391e-03 &  2.391e-03 &  7.172e-03 &  1.195e-02 &  0.017 &  0.022 \\
  & 4 & 0 &    NaN & -0.017 & -0.013 & -8.537e-03 & -4.269e-03 &  3.469e-18 &  4.269e-03 &  8.537e-03 &  0.013 &  0.017 \\
  & 6 & 0 &    NaN & -0.010 & -0.007 & -4.912e-03 & -2.456e-03 & -3.469e-18 &  2.456e-03 &  4.912e-03 &  0.007 &  0.010 \\
2 & 0 & 0 & -0.126 & -0.098 & -0.070 & -4.205e-02 & -1.402e-02 &  1.402e-02 &  4.205e-02 &  7.009e-02 &  0.098 &  0.126 \\
  & 2 & 0 & -0.016 & -0.013 & -0.009 & -5.366e-03 & -1.789e-03 &  1.789e-03 &  5.366e-03 &  8.943e-03 &  0.013 &  0.016 \\
  & 4 & 0 &    NaN &  0.017 &  0.013 &  8.364e-03 &  4.182e-03 &  0.000e+00 & -4.182e-03 & -8.364e-03 & -0.013 & -0.017 \\
  & 6 & 0 &    NaN & -0.001 & -0.001 & -6.675e-04 & -3.337e-04 & -1.735e-18 &  3.337e-04 &  6.675e-04 &  0.001 &  0.001 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Apply statistical functions to differences from mean.}
\PYG{n}{BetaNormLinearADMsPD}\PYG{o}{.}\PYG{n}{transform}\PYG{p}{(}\PYG{n}{demean}\PYG{p}{,}\PYG{n}{axis}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{columns}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.} \PYGZbs{}
        \PYG{n+nb}{round}\PYG{p}{(}\PYG{n}{ndp}\PYG{p}{)}\PYG{o}{.}\PYG{n}{agg}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{min}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{var}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{nunique}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrrrrrr}
\toprule
t &      0 &       1 &       2 &      3 &      4 &      5 &      6 &       7 &       8 &       9 \\
\midrule
min     & -0.130 &  -0.100 &  -0.070 &  -0.04 &  -0.01 &  -0.00 &   0.00 &  -0.010 &  -0.010 &  -0.020 \\
max     & -0.020 &   0.020 &   0.010 &   0.01 &  -0.00 &   0.01 &   0.04 &   0.070 &   0.100 &   0.130 \\
var     &  0.004 &   0.002 &   0.001 &   0.00 &   0.00 &   0.00 &   0.00 &   0.001 &   0.002 &   0.003 \\
count   &  5.000 &  10.000 &  10.000 &  10.00 &  10.00 &  10.00 &  10.00 &  10.000 &  10.000 &  10.000 \\
nunique &  2.000 &   6.000 &   5.000 &   5.00 &   2.00 &   2.00 &   3.00 &   5.000 &   6.000 &   6.000 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
In this case the analysis suggests that \(t=3 - 6\) contain minimal information (low variance), and \(t=4,5\) potentially redundant information (low nunique), whilst \(t=1,7 - 9\) show a greater total information content and number of unique values. However, this analysis is not necessarily absolutely definitive, since some nuances may be lost in this basic statistical analysis, particularly for weaker channels.

\sphinxAtStartPar
For a more detailed analysis, other standard analysis tools can be deployed. For instance, the covariance matrix can be investigated, given by \(K_{i,j}=\textrm{cov}[X_{i},X_{j}]=\langle(X_{i}-\langle X_{i}\rangle)(X_{j}-\langle X_{j}\rangle)\rangle\). For the linear ramp case this analysis is shown below and, although not particularly useful in this example, will become more informative for more complicated cases.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute covariance matrix with Pandas}
\PYG{c+c1}{\PYGZsh{} Note this is the pairwise covariance of the columns, }
\PYG{c+c1}{\PYGZsh{} see https://pandas.pydata.org/pandas\PYGZhy{}docs/stable/reference/api/pandas.DataFrame.cov.html}
\PYG{n}{covMat} \PYG{o}{=} \PYG{n}{BetaNormLinearADMsPD}\PYG{o}{.}\PYG{n}{cov}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot with holoviews}
\PYG{n}{figObj} \PYG{o}{=} \PYG{n}{covMat}\PYG{o}{.}\PYG{n}{hvplot}\PYG{o}{.}\PYG{n}{heatmap}\PYG{p}{(}\PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{viridis}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{9ce65efb90f1c5f6c6d0b8609c48b451408758a2e27c308cc9fc4d313f423313}.png}
\caption{Example \(\beta_{L,M}(t)\) covariance matrix, see text for details.}\label{\detokenize{part1/theory_info_content_200723:fig-covmatblmexample}}\end{figure}


\subsection{Information content from channel functions}
\label{\detokenize{part1/theory_info_content_200723:information-content-from-channel-functions}}
\sphinxAtStartPar
A more complete accounting of information content would, therefore, also
include the channel couplings, i.e. sensitivity/dependence of the
observable to a given system property, in some manner. For the case of a
time\sphinxhyphen{}dependent measurement, arising from a rotational wavepacket, this
can be written as:
\begin{equation*}
\begin{split}M_{u}=\mathrm{n}\{\varUpsilon_{L,M}^{u}(\epsilon,t)\}\end{split}
\end{equation*}
\sphinxAtStartPar
In this case, each \((\epsilon,t)\) is treated as an independent
measurement with unique information content, although there may be
redundancy as a function of \(t\) depending on the nature of the
rotational wavepacket and channel functions.

\sphinxAtStartPar
(Note this is in
distinction to previously demonstrated cases where the time\sphinxhyphen{}dependence
was created from a shaped laser\sphinxhyphen{}field, and was integrated over in the
measurements, which provided a coherently\sphinxhyphen{}multiplexed case, see refs.
{[}\hyperlink{cite.backmatter/bibliography:id663}{99}, \hyperlink{cite.backmatter/bibliography:id661}{125}, \hyperlink{cite.backmatter/bibliography:id662}{126}{]} for details.)

\sphinxAtStartPar
In the numerical examples below, this is considered in terms of the full channel (response) functions \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\) as defined in \eqref{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-MF-defn} and \eqref{equation:part1/theory_tensor_formalism_160723:eq:channelFunc-AF-defn} (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}}}). Numerically, the routines follow from those already introduced above for exploring the information content of \(\beta_{L,M}\) terms, with the caveat that there are more dimensions to handle in the channel functions, indexed by the relevant set of quantum numbers \(\{\zeta,\zeta'\}\) \sphinxhyphen{} these can be included in the criteria for determination of \(M\), or selected or summed over as desired.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Define a set of channel functions to test}
\PYG{n}{channelFuncs} \PYG{o}{=} \PYG{p}{(}\PYG{n}{basisProductLinearADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMtableResort}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{*} \PYG{n}{basisProductLinearADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{polProd}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} For illustrative purposes, define a subset to use for analysis}
\PYG{n}{channelFuncsSubset} \PYG{o}{=} \PYG{n}{channelFuncs}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{Labels}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S\PYGZhy{}Rp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{\PYGZcb{}}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{}.sel(L=2)}

\PYG{c+c1}{\PYGZsh{} Check dimensions}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Available dimensions: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{channelFuncs}\PYG{o}{.}\PYG{n}{dims}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Subset dimensions: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{channelFuncsSubset}\PYG{o}{.}\PYG{n}{dims}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Available dimensions: (\PYGZsq{}m\PYGZsq{}, \PYGZsq{}mp\PYGZsq{}, \PYGZsq{}S\PYGZhy{}Rp\PYGZsq{}, \PYGZsq{}l\PYGZsq{}, \PYGZsq{}lp\PYGZsq{}, \PYGZsq{}L\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}, \PYGZsq{}mup\PYGZsq{}, \PYGZsq{}Labels\PYGZsq{}, \PYGZsq{}M\PYGZsq{}, \PYGZsq{}t\PYGZsq{})
Subset dimensions: (\PYGZsq{}m\PYGZsq{}, \PYGZsq{}mp\PYGZsq{}, \PYGZsq{}l\PYGZsq{}, \PYGZsq{}lp\PYGZsq{}, \PYGZsq{}L\PYGZsq{}, \PYGZsq{}M\PYGZsq{}, \PYGZsq{}t\PYGZsq{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Full tabulations of the parameters available in HTML or notebook formats only.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Convert to PD and tabulate with epsproc functionality}
\PYG{c+c1}{\PYGZsh{} Note restack along \PYGZsq{}t\PYGZsq{} dimension}
\PYG{n}{channelFuncsSubsetPD}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{util}\PYG{o}{.}\PYG{n}{multiDimXrToPD}\PYG{p}{(}\PYG{n}{channelFuncsSubset}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{real}\PYG{p}{,} 
                                                 \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}4}\PYG{p}{,} \PYG{n}{colDims}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Round values to 1 d.p., then apply statistical methods}
\PYG{c+c1}{\PYGZsh{} Compute per basis index and display}
\PYG{n}{channelFuncsSubsetPD}\PYG{o}{.}\PYG{n}{T}\PYG{o}{.}\PYG{n}{round}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{o}{.}\PYG{n}{agg}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{min}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{var}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{count}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{nunique}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{o}{.}\PYG{n}{T}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
For the higher\sphinxhyphen{}dimensional case, it is useful to plot terms relative to all quantum numbers. For example, in a similar manner to the basis set explorations of \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-tensor-products}}}, related properties such as the distance from the mean can be examined with \sphinxcode{\sphinxupquote{lmPlot()}}. And, as previously demonstrated, other properties, such as the covariance, may be examined and plotted.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} channelFuncsSubsetPD.transform(demean,axis=\PYGZsq{}columns\PYGZsq{}) }
\PYG{c+c1}{\PYGZsh{} cmap=None   \PYGZsh{} cmap = None for default. \PYGZsq{}vlag\PYGZsq{} good?}
\PYG{c+c1}{\PYGZsh{} cmap = \PYGZsq{}vlag\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} De\PYGZhy{}meaned channel functions}
\PYG{n}{channelFuncsDemean} \PYG{o}{=} \PYG{n}{channelFuncsSubsetPD}\PYG{o}{.}\PYG{n}{transform}\PYG{p}{(}\PYG{n}{demean}\PYG{p}{,}\PYG{n}{axis}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{columns}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Plot using lmPlot routine \PYGZhy{} note this requires conversion to Xarray data type first.}
\PYG{n}{daPlot}\PYG{p}{,} \PYG{n}{daPlotpd}\PYG{p}{,} \PYG{n}{legendList}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=}  \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{channelFuncsDemean}\PYG{o}{.}\PYG{n}{to\PYGZus{}xarray}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{to\PYGZus{}array}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
                                                \PYG{p}{,} \PYG{n}{xDim}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{,} \PYG{n}{mDimLabel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set dataType (No dataType)
Plotting data (No filename), pType=a, thres=0.01, with Seaborn
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{661d9ffe62733296e63e6540d6d731a8c85195cf5b01cc51fd7587a3dbcbdfb4}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Full covariance mapping along all dims}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{n}{sns}\PYG{o}{.}\PYG{n}{clustermap}\PYG{p}{(}\PYG{n}{channelFuncsSubsetPD}\PYG{o}{.}\PYG{n}{T}\PYG{o}{.}\PYG{n}{cov}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fillna}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{}.round(3))}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.matrix.ClusterGrid at 0x7fddf224ac20\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{c93bee27e3000827498aa9bcc9863cbf991423e807b91f1f9e4647f1a607e4c0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxstepscope


\chapter{Numerical methodologies for extracting matrix elements}
\label{\detokenize{part1/numerics_070723:numerical-methodologies-for-extracting-matrix-elements}}\label{\detokenize{part1/numerics_070723:chpt-numerical-details}}\label{\detokenize{part1/numerics_070723::doc}}
\sphinxAtStartPar
Following the tensor notation outline in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}, the complete quantum metrology of a photoionization event (a.k.a. a “complete” photoionization experiment) can be characterized as recovery of the matrix elements \(I^{\zeta}(\epsilon)\) (per Eqs. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}, \eqref{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta}) from the experimental measurements or, equivalently, the density matrix \(\mathbf{\rho}^{\zeta\zeta'}\) (Eqs. \eqref{equation:part1/theory_density_matrices_190723:eqn:full-density-mat} \sphinxhyphen{} \eqref{equation:part1/theory_density_matrices_190723:eqn:beta-density-mat}). In general, such a recovery or reconstruction may be possible provided the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} are known, and the information content of the measurements is sufficient; it is, however, also possible that restrictions in any given case may preclude reconstruction, or restrict the level of recovery possible (e.g. to a lower symmetry group, or certain subsets of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}) or fidelity of such a reconstruction. (For further discussion and background, see Refs. {[}\hyperlink{cite.backmatter/bibliography:id842}{92}, \hyperlink{cite.backmatter/bibliography:id725}{94}{]} and \sphinxstyleemphasis{Quantum Metrology} Vol. 1 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}{]}.)

\sphinxAtStartPar
Of particular import for {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval is the phase\sphinxhyphen{}sensitive nature of the observables (\hyperref[\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sect-theory-observables}}}), which is required in order to obtain phase information on the {\hyperref[\detokenize{backmatter/glossary:term-partial-waves}]{\sphinxtermref{\DUrole{xref,std,std-term}{partial\sphinxhyphen{}waves}}}}. In this context, {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} can also be considered as \sphinxstyleemphasis{angular interferograms}, and reconstruction can be considered conceptually similar to other phase\sphinxhyphen{}retrieval problems, e.g. optical field recovery with techniques such as FROG {[}\hyperlink{cite.backmatter/bibliography:id929}{127}{]}, and general quantum tomography {[}\hyperlink{cite.backmatter/bibliography:id782}{101}{]}.

\sphinxAtStartPar
As introduced previously (\hyperref[\detokenize{part1/main_intro_060723:sec-main-intro-bootstrapping}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-main-intro-bootstrapping}}}), the focus herein is the development and testing of the \sphinxstyleemphasis{generalised {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}}, based on time\sphinxhyphen{}resolved {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} photoionization experiments. A general outline of the simplest 2\sphinxhyphen{}stage version of this protocol is shown in \hyperref[\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}]{Fig.\@ \ref{\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}}}. In this scheme, the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} are assumed to be known, and the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} assumed to be accurately computable: these are, in general, required to determine the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} in this protocol.

\sphinxAtStartPar
An extended outline comparing some similar approaches is shown in \hyperref[\detokenize{part1/numerics_070723:fig-general-fitting-diag}]{Fig.\@ \ref{\detokenize{part1/numerics_070723:fig-general-fitting-diag}}}; of particular note here is the possibility for retrieval directly from {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} measurements. Alternative, but conceptually similar, protocols involving different control parameters (as distinct from the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} cases), may also be also be used, see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} for examples. For protocols making use of control methods, the key requirement is for the contribution of the control parameters to the observable, and associated coupling to the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}, to be accurately accounted for. In general, these contributions may be computed and/or obtained from experiment depending on the scheme used. One advantage of the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} case is that the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} can be accurately computed, and the determination of the corresponding molecular alignment ({\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}) from an experiment can be treated as a reduced\sphinxhyphen{}dimensionality linear signal retrieval problem. As indicated in \hyperref[\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}]{Fig.\@ \ref{\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}}}, this stage is separable, and forms \sphinxstyleemphasis{level 1} of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}. In this procedure sets of computed {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} form the basis set for the fitting (as a function of laser fluence and rotational temperature), allowing the accurate determination of the experimentally\sphinxhyphen{}achieved alignment; this is discussed further in \hyperref[\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}}}. \sphinxstyleemphasis{Level 2} involves non\sphinxhyphen{}linear data fitting, making use of the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} and the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}, in order to compute observables, and obtaining the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} as the fitted parameters; this is discussed further in \hyperref[\detokenize{part1/numerics_070723:sect-numerics-mate-retrieval}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-mate-retrieval}}}. %
\begin{footnote}[1]\sphinxAtStartFootnote
As noted elsewhere: here the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} are assumed to be time\sphinxhyphen{}independent, although that may not be the case for the most complicated examples including vibronic dynamics, see \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} for further discussion on this point.
%
\end{footnote}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{bootstrap_flowchart_290822.gv}.png}
\caption{Outline of the 2\sphinxhyphen{}stage generalised bootstrap {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval protocol (outlined conceptually in \hyperref[\detokenize{part1/main_intro_060723:sec-main-intro-bootstrapping}]{Sect.\@ \ref{\detokenize{part1/main_intro_060723:sec-main-intro-bootstrapping}}}). In this case, level 1 outlines the determination of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}, and level 2 “bootstraps” from this to recover {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} observables. Grey inverted trapezoids indicate required inputs to the protocol, green trapezoids indicate the retrieved quantities.}\label{\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{all_protocol_flowchart_290822.gv}.png}
\caption{Comparison of similar {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval protocols, illustrating (left) pure {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} case; (middle) generalised bootstrap protocol; (lower right) matrix inversion protocol (see Ref. {[}\hyperlink{cite.backmatter/bibliography:id636}{98}{]}); (top right) alignment retrieval.  Grey inverted trapezoids indicate required inputs to the protocol, green trapezoids indicate the retrieved quantities. For the retrieval from the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} measurements case, no {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} and associated {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} are required. For the matrix inversion protocol, {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} observables are recovered, but not {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, although the latter may be possible by subsequent analysis of the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}.}\label{\detokenize{part1/numerics_070723:fig-general-fitting-diag}}\end{figure}


\section{Fitting methodologies}
\label{\detokenize{part1/numerics_070723:fitting-methodologies}}\label{\detokenize{part1/numerics_070723:sec-numerics-fitting-methodologies}}
\sphinxAtStartPar
In general, the extraction of parameters from a data set can be viewed as a general minimization (fitting) problem. This type of treatment is versatile, and can be multi\sphinxhyphen{}stage depending on the complexity of the problem. For the generalised bootstrapping method, the treatment of photoionization data is split into two types of fit, as shown in \hyperref[\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}]{Fig.\@ \ref{\detokenize{part1/numerics_070723:fig-bootstrap-fitting-diag}}}. Firstly, a linear fitting stage to retrieve the molecular axis distribution, characterised by a set of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} (see \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-theory-af-alignment-term}}} for details); secondly, a non\sphinxhyphen{}linear fitting stage to retrieve the complex\sphinxhyphen{}valued matrix elements.

\sphinxAtStartPar
In terms of the data, the 1st stage can be written as:
\begin{equation}\label{equation:part1/numerics_070723:eqn:beta-convolution-C}
\begin{split}
\bar{\beta}_{L,M}^{u}(\epsilon,t)=\sum_{K,Q,S}A_{Q,S}^{K}(t)\bar{C}_{KQS}^{LM}(\epsilon)
\end{split}
\end{equation}
\sphinxAtStartPar
And the 2nd stage as per Eqs. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns} and \eqref{equation:part1/theory_tensor_formalism_160723:eq:BLM-tensor-AF} for the AF case:
\begin{equation}\label{equation:part1/numerics_070723:eqn:beta-convolution-stage2}
\begin{split}
\bar{\beta}_{L,M}^{u}(\epsilon,t)=\sum_{\zeta,\zeta'}\bar{\varUpsilon_{}}_{L,M}^{u,\zeta\zeta'}(t)\mathbb{I}^{\zeta\zeta'}(\epsilon)
\end{split}
\end{equation}
\sphinxAtStartPar
In these forms, the terms are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(A_{Q,S}^{K}(t)\), the set of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} defining the molecular alignment, and associated parameters \(\bar{C}_{KQS}^{LM}(\epsilon)\).

\item {} 
\sphinxAtStartPar
\(\bar{\varUpsilon_{}}_{L,M}^{u,\zeta\zeta'}(t)\), the channel functions in the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} (Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eq:BLM-tensor-AF}, and matrix elements \(\mathbb{I}^{\zeta\zeta'}(\epsilon)\).

\end{enumerate}

\sphinxAtStartPar
Hence stage (2) relies on the inputs of stage (1), i.e. the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}; and the parameters in stage (1) can be determined via fitting the data (linear regression) making use of computed sets of \(A_{Q,S}^{K}(t)\) as a function of experimental parameters (laser fluence and rotational temperature). In this case, a range of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} (“basis sets”) are computed, and the best match to the experimental data chosen \sphinxhyphen{} more details are discussed in \hyperref[\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}}}. In a similar manner, the 2nd stage makes use of a known basis set \sphinxhyphen{} the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} \sphinxhyphen{} but a non\sphinxhyphen{}linear fit is required to determine the set of matrix elements, see \hyperref[\detokenize{part1/numerics_070723:sect-numerics-mate-retrieval}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-mate-retrieval}}}.

\sphinxAtStartPar
Finally, it is also of note that, although the case herein focusses on rotational wavepackets as a control parameter, the same general approach can be applied to other cases, e.g. fitting {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} directly (for which only the 2nd stage is required), fitting {\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} obtained via rotational state\sphinxhyphen{}resolved transitions, with shaped laser pulses and so on, as detailed in \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]}. Although only rotational wavepacket cases are illustrated in this work (see {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}), by suitable choice of dataset and channel functions many other experimental schemes may be modelled and analysed; the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} is designed with  this flexibility in mind.


\subsection{Computation and linear fitting for alignment characterisation}
\label{\detokenize{part1/numerics_070723:computation-and-linear-fitting-for-alignment-characterisation}}\label{\detokenize{part1/numerics_070723:sect-numerics-alignment-retrieval}}
\sphinxAtStartPar
Efforts to align and orient molecules in recent decades have led to detailed studies of the rotational dynamics of molecules after interaction with a non\sphinxhyphen{}resonant femtosecond laser pulse. A significant outcome of these studies has been the development of a reliable model capable of accurate simulations of rotational wavepacket dynamics that quantitatively agree with experimental results. By measurement of a signal from a time evolving rotational wavepacket, this ability to accurately simulate the wavepacket dynamics can be used to reconstruct the measured signal in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}. Since in this case the time resolved measurement constitutes a set of measurements of the same quantity from a variety of molecular axes distributions (sets of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}), it is reasonable to conclude that if the axes distributions are known, and provided a large enough space of orientations is explored by the molecule over the experimental time window, the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} signal should be extractable.

\sphinxAtStartPar
This is relatively straight forward for a signal that is a single number (scalar) in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} for a given polarization of the light, such as the photoionization yield. Such a signal may, in general, be expressed as an expansion,
\begin{equation}\label{equation:part1/numerics_070723:eq:mfrealsig}
\begin{split}
S(\theta,\chi)=\sum_{jk}C_{jk}D^{j}_{0k}(\theta,\chi),
\end{split}
\end{equation}
\sphinxAtStartPar
where \(\theta\) and \(\chi\) are the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} spherical polar and azimuthal angles of the linearly polarized electric field vector generating the signal (\hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}}); \(C_{jk}\) are unknown expansion coefficients; and \(D^{j}_{0k}\) are the {\hyperref[\detokenize{backmatter/glossary:term-Wigner-rotation-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{Wigner rotation matrix elements}}}}, a basis on the space of orientations. A time resolved measurement of \(S\) from a rotational wavepacket is the quantum expectation value of this expression,
\begin{equation}\label{equation:part1/numerics_070723:eq:St-Cjk}
\begin{split}
\langle S \rangle(t) = \sum_{jk}C_{jk}\langle D^{j}_{0k} \rangle (t).
\end{split}
\end{equation}
\sphinxAtStartPar
Since the rotational wavepacket can be accurately simulated, the \(\langle D^{j}_{0k} \rangle (t)\) are considered known. From the measurement of a time resolved signal \(\langle S \rangle(t)\), the unknown coefficients \(C_{jk}\) can be determined by linear regression, and the molecular frame signal in Eq. \eqref{equation:part1/numerics_070723:eq:mfrealsig} constructed. In this form the method was initially applied to strong field ionization and dubbed Orientation Reconstruction through Rotational Coherence Spectroscopy (ORRCS) {[}\hyperlink{cite.backmatter/bibliography:id996}{128}, \hyperlink{cite.backmatter/bibliography:id995}{129}{]}.
It has since been applied to strong field ionization of various molecules {[}\hyperlink{cite.backmatter/bibliography:id997}{130}, \hyperlink{cite.backmatter/bibliography:id998}{131}, \hyperlink{cite.backmatter/bibliography:id1001}{132}{]},
strong field dissociation {[}\hyperlink{cite.backmatter/bibliography:id1000}{133}{]} and few\sphinxhyphen{}photon ionization {[}\hyperlink{cite.backmatter/bibliography:id999}{134}{]}.%
\begin{footnote}[2]\sphinxAtStartFootnote
A large range of other experimental methods have also addressed alignment and orientation dependence and retrieval, other recent examples include Coulomb\sphinxhyphen{}explosion imaging {[}\hyperlink{cite.backmatter/bibliography:id939}{135}{]}, high\sphinxhyphen{}harmonic spectroscopy {[}\hyperlink{cite.backmatter/bibliography:id646}{136}, \hyperlink{cite.backmatter/bibliography:id647}{137}{]}, optical imaging {[}\hyperlink{cite.backmatter/bibliography:id760}{138}{]} and rotational echo spectroscopy {[}\hyperlink{cite.backmatter/bibliography:id953}{139}{]}, see Refs. {[}\hyperlink{cite.backmatter/bibliography:id728}{111}, \hyperlink{cite.backmatter/bibliography:id836}{114}{]} for further discussion.
%
\end{footnote}

\sphinxAtStartPar
The case of PADs is a more challenging one, since they are not generally described by Eq. \eqref{equation:part1/numerics_070723:eq:mfrealsig}. Instead, both {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} are determined by the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, as discussed in \hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chpt.\@ \ref{\detokenize{part1/theory_100723:chpt-theory}}}. However, the correspondence of the problem with an equation of the form of Eq. \eqref{equation:part1/numerics_070723:eq:St-Cjk} \sphinxhyphen{} essentially a convolution \sphinxhyphen{} can be made. This is discussed in detail in Ref. {[}\hyperlink{cite.backmatter/bibliography:id937}{96}{]}. In the current case Eqs. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns} and \eqref{equation:part1/theory_tensor_formalism_160723:eq:BLM-tensor-AF} can be rewritten in a similar form to Eq. \eqref{equation:part1/numerics_070723:eq:St-Cjk} by explicitly separating out the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} \(A_{Q,S}^{K}(t)\) and collapsing all other terms. The case of photoionization from a time\sphinxhyphen{}dependent ensemble can then be reparameterized as indicated in Eq. \eqref{equation:part1/numerics_070723:eqn:beta-convolution-C}. Here the set of axis distribution moments can thus be viewed as modulating all observables \(\beta_{L,M}^{u}(t)\). The unknowns, \(\bar{C}_{KQS}^{LM}\) and axis distribution moments \(A_{Q,S}^{K}(t)\), can be retrieved in a similar manner to that discussed for the simpler scalar observable case above (Eq. \eqref{equation:part1/numerics_070723:eq:St-Cjk}), i.e. via linear regression with an {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} basis set.

\sphinxAtStartPar
In practice this equates to (accurately) simulating {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}}s, hence obtaining the corresponding \(A_{Q,S}^{K}(t)\) parameters (expectation values), as a function of laser fluence and rotational temperature. Given experimental data, a 2D uncertainty (or error) surface in these two fundamental quantities can then be obtained from a linear regression for each set of \(A_{Q,S}^{K}(t)\). The closest set of parameters to the experimental case is then determined by selection of the best results (smallest uncertainty) from such a parameter\sphinxhyphen{}space mapping, which constitutes determination of both the rotational wavepacket (hence \(A_{Q,S}^{K}(t)\)) and \(\bar{C}_{KQS}^{LM}(\epsilon)\). Optimally, the corresponding physical properties can be cross\sphinxhyphen{}checked with other experimental estimates for additional confirmation of the fidelity of the protocol, although this may not always be possible. Note that, in this case, the photoionization dynamics are phenomenologically described by the real parameters \(\bar{C}_{KQS}^{LM}\), but details of the matrix elements are not obtained directly.

\sphinxAtStartPar
At the time of writing, computation of {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}}s and this stage of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} analysis is not implemented in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, although is planned for the near future, and has been demonstrated in practice {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]}. The examples in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} instead make use of computed {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} directly, essentially corresponding to the assumption that level 1 of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} was successful. Given accurate {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}}s, a successful fit to experimental data is generally assumed to be a given outcome, as this stage of the analysis requires only linear fitting in a two\sphinxhyphen{}parameter basis space.


\subsection{Non\sphinxhyphen{}linear fitting for matrix elements}
\label{\detokenize{part1/numerics_070723:non-linear-fitting-for-matrix-elements}}\label{\detokenize{part1/numerics_070723:sect-numerics-mate-retrieval}}
\sphinxAtStartPar
The nature of the photoionization problem suggests that a fitting approach can work, in general, which can be expressed (for example) in the standard way as a (non\sphinxhyphen{}linear) least\sphinxhyphen{}squares minimization problem:
\begin{equation}\label{equation:part1/numerics_070723:eq:chi2-I}
\begin{split}
\chi^{2}(\mathbb{I}^{\zeta\zeta'})=\sum_{u}\left[\beta^{u}_{L,M}(\epsilon,t;\mathbb{I}^{\zeta\zeta'})-\beta^{u}_{L,M}(\epsilon,t)\right]^{2}
\end{split}
\end{equation}
\sphinxAtStartPar
where \(\beta^{u}_{L,M}(\epsilon,t;\mathbb{I}^{\zeta\zeta'})\) denotes  the values from a model function, computed for a given set of (complex) matrix elements \(\mathbb{I}^{\zeta\zeta'}\), and \(\beta^{u}_{L,M}(\epsilon,t)\) the experimentally\sphinxhyphen{}measured parameters, for a given configuration \(u\). Implicit in the notation is that the matrix elements are independent of \(u\) (or otherwise averaged over \(u\)). Once the matrix elements are obtained in this manner then {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} observables, for any arbitrary \(u\), can be calculated. Generally fitting routines do not handle complex\sphinxhyphen{}valued functions, so the fitting parameter space is usually defined by parameters in magnitude\sphinxhyphen{}phase form (Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta-mag-phase}; see also discussion in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-channel-funcs}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-channel-funcs}}})

\sphinxAtStartPar
Although in principle a very general approach, outstanding questions with such protocols remain, in particular fit uniqueness and reproducibility, the optimal measurement space \(u\) \sphinxhyphen{} or associated information content \(M_u\) \sphinxhyphen{} for any given case or measurement schema, how well they will scale to larger problems (more matrix elements/partial waves), the most efficient fitting methodologies/strategies, and so forth. In general, determination of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} is \sphinxstyleemphasis{not} expected to be trivial, nor to always be successful, due to the complexity of the problem; one significant issue is the topology of the \(\chi^2\) hypersurface, which is of \(2N-1\) dimensions (where \(N\) is the number of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}), and may contain local minima. Exploration of these questions for various exemplar systems is the topic of the {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}, and further general discussion can be found in \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]}, see in particular \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} Sect. 8.2.2.


\subsection{Implementation in PEMtk}
\label{\detokenize{part1/numerics_070723:implementation-in-pemtk}}\label{\detokenize{part1/numerics_070723:sect-numerics-implementation-details}}
\sphinxAtStartPar
As outlined in \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}} and \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-general}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-general}}}, \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} uses the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} to implement general fitting routines, along with the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} for computation of the required basis sets and observables. The latter has already been illustrated in \hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chpt.\@ \ref{\detokenize{part1/theory_100723:chpt-theory}}}, and the illustration of the former is the subject of {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}. However, in these demonstrations only the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} case is investigated, and analysis routines used only a standard Levenberg\sphinxhyphen{}Marquardt least\sphinxhyphen{}squares minimization method.

\sphinxAtStartPar
More generally, it is of note that the routines are written to be (somewhat) general and modular, such that other optimization methods may readily be implemented \sphinxhyphen{} either via \sphinxhref{https://lmfit.github.io/lmfit-py/fitting.html}{those already supported} by \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} (e.g. Levenberg\sphinxhyphen{}Marquardt, basinhopping, Nelder\sphinxhyphen{}Mead and so on \sphinxhyphen{} see the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} documentation for supported methods), or by making use of other fitting libraries and methodologies.

\sphinxAtStartPar
Similarly, modification of the routines to other retrieval schemes should be fairly easy, and usually requires only:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
a function which computes the required basis set (e.g. {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}})

\item {} 
\sphinxAtStartPar
observables for the problem at hand.

\end{enumerate}

\sphinxAtStartPar
Examples are given in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} for the \sphinxstyleemphasis{generalised {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}}, and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} based retrieval is also implemented in the codebase. For further details see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_backends\_demo\_010922.html}{fitting model backends} and \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_demo\_multi-fit\_tests\_130621-MFtests\_120822-tidy-retest.html}{fitting MF and other datasets} pages.


\section{Fitting strategies}
\label{\detokenize{part1/numerics_070723:fitting-strategies}}\label{\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}}
\sphinxAtStartPar
The overall approach to complex non\sphinxhyphen{}linear fitting incorporates a number of aspects, broadly “fitting strategies”, which may influence the likelyhood of a successful {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval, and/or the time required to achieve this result:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The choice of numerical fitting method (\hyperref[\detokenize{part1/numerics_070723:sect-numerics-implementation-details}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-implementation-details}}}).

\item {} 
\sphinxAtStartPar
The choice of dataset to analyse (and/or the choice of experimental measurement).

\item {} 
\sphinxAtStartPar
Additional statistical and/or other meta\sphinxhyphen{}analysis.

\end{enumerate}

\sphinxAtStartPar
At the time of writing, work is ongoing in all these areas, and the illustrations in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} herein include further notes regarding limitations or expectations for specific cases. Clearly, there are many choices numerically, and detailed investigation is required to determine the optimal strategy in any given case (this is examined partially in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} in terms of limiting cases by symmetry). Emerging data analysis methods may also be useful here, in particular GPU\sphinxhyphen{}based routines and specialist high\sphinxhyphen{}dimensional space fitting methods.

\sphinxAtStartPar
One aspect that is intrinsic to these examples, but has not been discussed elsewhere, is the meta\sphinxhyphen{}analysis of the retrieved {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}. This is discussed generally in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} Sect. 8.2.2, and implemented numerically in the examples in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}} herein. The general aim in this type of analysis is to ascertain whether a given set of retrieved parameters is accurate and unique in a given case. Naturally, for test cases with synthetic data (as in {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}), testing against the known input {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} is the best solution and provides the most stringent test for the applicability of the retrieval method \sphinxhyphen{} but this is, of course, not generally useful for experimental datasets. Instead, as per previous analysis cases (see \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}), a statistical (or “numerical experiment”) approach can be used. In this type of approach, a number of fits \(n\) (typically on the order of \(10^2\)\sphinxhyphen{}\(10^4\)) are run independently, with different seed parameters and/or different input data (cf. Monte Carlo methods, and statistical bootstrap methods), and the set of results analysed for consistency and uniqueness over the retrieved parameter sets. As outined in \sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]} (updated to match the notation herein):
\begin{quote}

\sphinxAtStartPar
Each fit yields a solution set \(\mathbb{I}^{\zeta\zeta'}(n)\), with a final value of \(\chi^{2}(\mathbb{I}^{\zeta\zeta'}(n))\). Analysis of the fitted parameters \(\chi^{2}(\mathbb{I}^{\zeta\zeta'})\) can be employed to probe the behaviour of the fitting algorithm, and also to gain information on how well the experimental data defines each fitted parameter. Although it is non\sphinxhyphen{}trivial to visualize the full \(\chi^{2}\) hypersurface, aspects can be probed by plotting histograms and correlation plots of the fitted parameters. A large scatter in the value of a given fit parameter over a range of fits to the same data suggests a poorly defined parameter; a consistent result meanwhile shows that a particular parameter is well defined by the dataset. The experimental data can show different sensitivities to different parameters depending on the type of ionizing transitions present, because different transitions will (according to the magnitude of the geometrical parameters and symmetry constraints {[}i.e. {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} herein{]}) be more sensitive to certain partial\sphinxhyphen{}waves. Additionally, the presence of multiple minima in the fit may be revealed by the presence of more than one feature in the histogram, reflecting more than one “best” fit result, while correlations appearing between supposedly uncorrelated parameters can indicate emergent behaviours in the high\sphinxhyphen{}dimensional space or \sphinxhyphen{} more prosaically \sphinxhyphen{} issues with the fitting methodology or coding.

\begin{flushright}
---\sphinxstyleemphasis{Quantum Metrology} Vol. 2 {[}\hyperlink{cite.backmatter/bibliography:id678}{9}{]}, Chpt. 8
\end{flushright}
\end{quote}

\sphinxAtStartPar
The same approach is taken in the case\sphinxhyphen{}studies of {\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{\sphinxcrossref{\DUrole{std,std-ref}{Part II}}}}, which include statistical analysis to determine the “correct” {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} from a set of non\sphinxhyphen{}linear fits, and associated uncertainties, again with the hope of illustrating general methods.


\bigskip\hrule\bigskip


\sphinxstepscope


\part{Part II \sphinxhyphen{} Extracting matrix elements \sphinxhyphen{} numerical methods \& case studies}

\sphinxstepscope


\chapter{Extracting matrix elements overview}
\label{\detokenize{part2/extracting_matrix_elements_overview_270423:extracting-matrix-elements-overview}}\label{\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}}\label{\detokenize{part2/extracting_matrix_elements_overview_270423::doc}}
\sphinxAtStartPar
In this part, various case studies are presented. To provide context, and ensure that the examples are transparent and can be run directly from the source notebooks, there are also chapters covering the general setup and configuration for the fitting routines. These are, unavoidably, rather technical and code\sphinxhyphen{}heavy, so readers only interested in the results should skip these sections. Additionally, these sections may be rather truncated in hard\sphinxhyphen{}copy (or PDF) versions of the text, but are available in full in the \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)} and source notebooks for readers that wish to perform their own calculations.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
As {\hyperref[\detokenize{frontmatter/book_versions_note:sec-numerics-disclaimer}]{\sphinxcrossref{\DUrole{std,std-ref}{noted elsewhere}}}}, many components of the toolkit are still in active development, and some numerical details may change. This is particularly true for 3D alignment examples, which are here presented as new, and provisional, results.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\sphinxAtStartPar
The layout for this part is as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Technical introductions
\begin{itemize}
\item {} 
\sphinxAtStartPar
\hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chapter \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}:} {\hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{\sphinxcrossref{\DUrole{std,std-ref}{Basis sets for fitting}}}}: introduces methods for setting the basis set used for fitting, defined in terms of symmetrized harmonics.

\item {} 
\sphinxAtStartPar
\hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chapter \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}:} {\hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{\sphinxcrossref{\DUrole{std,std-ref}{General fit setup and numerics}}}}: introduces methods for setting up the data to fit, and running fits in various ways.

\end{itemize}

\item {} 
\sphinxAtStartPar
Case studies
\begin{itemize}
\item {} 
\sphinxAtStartPar
\hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{Chapter \ref{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}:} {\hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{\sphinxcrossref{\DUrole{std,std-ref}{Case study: Generalised bootstrapping for a homonuclear diatomic scattering system, N\_2\textasciitilde{}(D\_\{\textbackslash{}infty h\})}}}}: A “simple” 1D case, here the \(D_{\infty h}\) molecular symmetry matches the rotational wavepacket and detection symmetry.

\item {} 
\sphinxAtStartPar
\hyperref[\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}]{Chapter \ref{\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}}:} {\hyperref[\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}]{\sphinxcrossref{\DUrole{std,std-ref}{Case study: Generalised bootstrapping for a linear heteronuclear scattering system, OCS\textasciitilde{}(C\_\{\textbackslash{}infty v\})}}}}: A more complicated example. In this case, \(C_{\infty v}\), up\sphinxhyphen{}down symmetry is broken in the molecular frame. Fitting for various cases is explored, looking at 1D and 3D alignment.

\item {} 
\sphinxAtStartPar
\hyperref[\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}]{Chapter \ref{\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}}:} {\hyperref[\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}]{\sphinxcrossref{\DUrole{std,std-ref}{Case study: Generalised bootstrapping for a general asymmetric top scattering system, C\_2H\_4\textasciitilde{}(D\_\{2h\})}}}}: The most general example of an asymmetric top system, in this case \(C_2H_4\) (ethylene), \(C_{2h}\). Again various cases and limitations are examined, for 1D and 3D alignment.

\end{itemize}

\item {} 
\sphinxAtStartPar
Summary, discussion, conclusions and outlook: \hyperref[\detokenize{part2/case-study-summaries_240723:chpt-case-study-summaries}]{Chapter \ref{\detokenize{part2/case-study-summaries_240723:chpt-case-study-summaries}}} presents a general overview of the case study results \sphinxhyphen{} particularly the density matrix and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} \sphinxhyphen{} and conclusions.

\end{itemize}


\section{General notes on the case studies}
\label{\detokenize{part2/extracting_matrix_elements_overview_270423:general-notes-on-the-case-studies}}
\sphinxAtStartPar
The case studies presented herein represent various different types (classes or degrees\sphinxhyphen{}of\sphinxhyphen{}difficulty) of fitting problem. They are intended both to indicate ways to proceed in general, and also aim to address what is, and isn’t, possible in these given cases. The simplest case, \(N_2\), has been well\sphinxhyphen{}studied, and reconstruction of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} via the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} has proved successful in a range of valence ionization cases \sphinxhyphen{} see Ref. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]} for the initial experimental demonstration, and updated analysis using the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} in Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, as well as \hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{Chapter \ref{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}} herein.

\sphinxAtStartPar
The more complex cases, involving 3D alignment, are new, and very much work\sphinxhyphen{}in\sphinxhyphen{}progress. The current state\sphinxhyphen{}of\sphinxhyphen{}the\sphinxhyphen{}art is presented herein, but it is of note that these results are provisional, and work is ongoing. In particular, there are a large range of fitting configuration options and parameters which have yet to be explored in these cases, which may significantly improve on the current results in terms of computational effort required, reliability of the fitting protocol, and size of the required dataset. Nonetheless, these new results are interesting and present a stepping\sphinxhyphen{}stone for studies on {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval in complex systems, and a launching point for similar studies.

\sphinxAtStartPar
\sphinxstyleemphasis{Each case study has a setup script and associated data, which was used to create sample data and configure the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} in each case (the general procedure is outlined in \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chapter \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}}). However, since the fitting is computationally demanding, code execution for large fitting cases is not run upon building the book. Rather the code illustrates the general procedure (for a small batch), and existing fit data files are used if present. Each case study therefore contains an initial setup stage which can be used to run fits, or load existing data, prior to analysis.}

\sphinxAtStartPar
In each case study, {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} results sets are analysed at length; for a quick overview of results and fidelities in each case readers may consult the final subsection in each chapter, which provide visual summaries of the results as both density matrices and {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}}, and comparison with the reference case. These results form the basis for the summary and discussion in \hyperref[\detokenize{part2/case-study-summaries_240723:chpt-case-study-summaries}]{Chapter \ref{\detokenize{part2/case-study-summaries_240723:chpt-case-study-summaries}}}, readers not interested in the full technical details may skip directly to that chapter for general discussion, conclusions and outlook.

\sphinxAtStartPar
Finally, it is of note that \sphinxhyphen{} as discussed in the {\hyperref[\detokenize{frontmatter/book_versions_note:chpt-book-versions}]{\sphinxcrossref{\DUrole{std,std-ref}{preamble on book versions}}}} \sphinxhyphen{} output may be significantly truncated in some cases. Readers wishing to obtain all computational details should pull the source notebooks from \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}, or consult the online HTML version at \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)}. Each case study notebook is configured to pull the required data files to setup and run fits from the \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]} Github repo; data files for the specific example fit results examined in the chapters as published can be obtained separately from the \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}.

\sphinxstepscope


\chapter{Basis sets for fitting}
\label{\detokenize{part2/sym-fitting-intro_240723:basis-sets-for-fitting}}\label{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}\label{\detokenize{part2/sym-fitting-intro_240723::doc}}
\sphinxAtStartPar
As outlined in Part I, particularly \hyperref[\detokenize{part1/theory_100723:chpt-theory}]{Chpt.\@ \ref{\detokenize{part1/theory_100723:chpt-theory}}}, in order to compute and/or retrieve a set of matrix elements from experimental results, various physical properties of the system at hand are required. In particular, the symmetry of the system, the ionizing channel(s) of interest, and the properties of the ionizing radiation are all required to define the basis set used for {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval via fitting (\hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chpt.\@ \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}).

\sphinxAtStartPar
Numerically, there are two main methods to do this demonstrated herein:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The use of symmetry to define the basis set, in terms of symmetry\sphinxhyphen{}allowed components.

\item {} 
\sphinxAtStartPar
The use of \sphinxstyleemphasis{ab initio} calculations to define the basis functions. In the work presented here, it is specifically \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]} matrix elements that are used, since these are also used to generate the synthetic data used to test the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}.

\end{enumerate}

\sphinxAtStartPar
Manual creation of basis sets is also possible, and may be useful in some cases, particularly when exploring limiting cases.


\section{Symmetry\sphinxhyphen{}defined basis sets}
\label{\detokenize{part2/sym-fitting-intro_240723:symmetry-defined-basis-sets}}
\sphinxAtStartPar
As illustrated in \hyperref[\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}]{Sect.\@ \ref{\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}}}, a set of symmetry\sphinxhyphen{}allowed continuum functions can be determined, corresponding to a given ionizing transition and specific dipole symmetries. Such a basis set defines the allowed matrix elements in terms of a set of symmetrized harmonics, and these can be used as a basis for fitting with only minimal knowledge of the system required.

\sphinxAtStartPar
The main advantage of a purely symmetry\sphinxhyphen{}defined approach is that no additional \sphinxstyleemphasis{ab initio} computations are required, and that the resulting basis set is general. As discussed and illustrated in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}, the resulting {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} can also be used to guide analysis (and experiment if available prior to experimental work). The main disadvantage of such a blind approach is that initial data analysis may require significantly more effort than working from a computationally\sphinxhyphen{}defined basis, in particular the initial fitting space may be larger than required (leading to computationally more\sphinxhyphen{}demanding fitting runs), and testing for contributing/non\sphinxhyphen{}negligible terms by, e.g. using varying \(l_{max}\), may be required in initial fitting runs. For further discussion, see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]}.


\section{Computationally\sphinxhyphen{}defined basis sets}
\label{\detokenize{part2/sym-fitting-intro_240723:computationally-defined-basis-sets}}
\sphinxAtStartPar
In cases where photoionization calculations are available, the results can also be used to determine allowed basis components. Use of \sphinxstyleemphasis{ab initio} computational results is, of course, useful for simulation as well as direct analysis, and may lead to a reduced basis set relative to the symmetry\sphinxhyphen{}defined case, since some components may be small and can be ignored. However, it does also require that substantial calculations are performed (or results are available, e.g. from \sphinxhref{https://phockett.github.io/ePSdata/about.html}{ePSdata} {[}\hyperlink{cite.backmatter/bibliography:id679}{48}{]}), and \sphinxhyphen{} potentially \sphinxhyphen{} may bias the matrix element analysis/retrieval in cases where the experimental results and computational results are significantly different.


\section{Basis creation worked examples}
\label{\detokenize{part2/sym-fitting-intro_240723:basis-creation-worked-examples}}
\sphinxAtStartPar
In the case study chapters, basis functions are created for each case at hand, typically starting from \sphinxstyleemphasis{ab initio} computational results (since these are required to simulate the sample data). Here a more detailed worked example is given to illustrate the basic methodology behind the assignments, the differences between the approaches, and highlight some issues of convention which may arise.


\subsection{Simple case: \protect\(N_2~3\sigma_g^{-1}\protect\) ionization}
\label{\detokenize{part2/sym-fitting-intro_240723:simple-case-n-2-3-sigma-g-1-ionization}}
\sphinxAtStartPar
As a simple example, consider the case of a homonuclear diatomic (\(D_{\infty h}\) {\hyperref[\detokenize{backmatter/glossary:term-PG}]{\sphinxtermref{\DUrole{xref,std,std-term}{PG}}}}, cylindrically symmetric), and a totally symmetric ionizing orbital, e.g. the ionization of the \(\Sigma_{g}^{+}\) {\hyperref[\detokenize{backmatter/glossary:term-HOMO}]{\sphinxtermref{\DUrole{xref,std,std-term}{HOMO}}}} of \(N_2\). For this example,
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\Gamma^{i} = \Gamma^{+} = \Gamma^{s} = \Sigma_{g}^{+}\). Note that, for single\sphinxhyphen{}electron ionization from a fully\sphinxhyphen{}occupied valence orbitals, the ion symmetry will correspond to the hole symmetry, hence the symmetry of the ionized orbital. This simple picture may break down for more complicated cases, e.g. if multi\sphinxhyphen{}electron effects or substantial nuclear motions are involved; for radical systems the overall symmetry of all partially\sphinxhyphen{}occupied orbitals must be accounted for.

\item {} 
\sphinxAtStartPar
The dipole symmetries correspond to the Cartesian axes/translations given in the character tables, hence \(\Sigma_{u}^{+} = (z)\) and \(\Pi_{u} = (x,y)\) for \(D_{\infty h}\). Note that, in this cylindrically symmetric case, the Cartesian \((x,y)\) components are spanned by the doubly\sphinxhyphen{}degenerate \(\Pi_{u}\) irreducible representation \sphinxhyphen{} physically this corresponds to the arbitrary orientation of these axes in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} (i.e. no preferred direction is defined).

\end{itemize}

\sphinxAtStartPar
Following Eq. \eqref{equation:part1/theory_symmetry_140723:eq:ionization-symm-electronic}, the allowed components (irreducible representations) can be determined by hand making use of character and direct product tables, and substituting in for the terms defined above:
\label{equation:part2/sym-fitting-intro_240723:0a5b3f3a-1757-4995-a9c3-a71503b4200d}\begin{eqnarray}
\Gamma^{+}\otimes\Gamma^{e}\otimes\Gamma_{\mathrm{dipole}}\otimes\Gamma^{i} & \supseteq & \Sigma_{g}^{+}\\
\Sigma_{g}^{+}\otimes\Gamma^{e}\otimes\begin{array}{c}
\Pi_{u}~(x,y)\\
\Sigma_{u}^{+}~(z)
\end{array}\otimes\Sigma_{g}^{+} & \supseteq & \Sigma_{g}^{+}\\
\Sigma_{g}^{+}\otimes\Gamma^{e}\otimes\begin{array}{c}
\Pi_{u}~(x,y)\\
\Sigma_{u}^{+}~(z)
\end{array} & \supseteq & \Sigma_{g}^{+}\\
\Gamma^{e}\otimes\begin{array}{c}
\Pi_{u}~(x,y)\\
\Sigma_{u}^{+}~(z)
\end{array} & \supseteq & \Sigma_{g}^{+}
\end{eqnarray}
\begin{sphinxadmonition}{note}{Group theory character tables and related}

\sphinxAtStartPar
Character tables, direct product tables and related information can be found at various sources online, or in textbooks, e.g. Refs. {[}\hyperlink{cite.backmatter/bibliography:id515}{140}, \hyperlink{cite.backmatter/bibliography:id625}{141}, \hyperlink{cite.backmatter/bibliography:id718}{142}{]}. For \(D_{\infty h}\) the pages at \sphinxhref{http://symmetry.jacobs-university.de/cgi-bin/group.cgi?group=1001\&option=4}{symmetry.jacobs\sphinxhyphen{}university.de} provide a good quick reference; for extended tables \sphinxhref{http://www.gernot-katzers-spice-pages.com/character\_tables/index.html}{including spherical harmonic symmetries and direct products the pages from G. Katzers are useful}.
\end{sphinxadmonition}

\sphinxAtStartPar
Hence the allowed continuum components are given by:
\label{equation:part2/sym-fitting-intro_240723:1153b106-a8fc-4a1c-9d49-6c7de3b5ef56}\begin{equation}
\Gamma^{e}=\begin{array}{c}
\Pi_{u}~(x,y)\\
\Sigma_{u}^{+}~(z)
\end{array}
\end{equation}
\sphinxAtStartPar
As indicated above, this case is split by symmetry into a “parallel” and “perpendicular” continua, accessed by the \(z\) or \((x,y)\) dipole components in the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} respectively; these are often denote generically by appending \(\perp\) and \(\parallel\) symbols to derived quantities, e.g. \(\sigma_{\parallel}\) for the corresponding cross\sphinxhyphen{}section. In the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} or {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} these continua can be mixed according to the polarization state and geometry of the ionizing radiation, and the molecular alignment ({\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}).

\sphinxAtStartPar
The total scattering state symmetry is often also used to label continuum states, and is given by \(\Gamma_{\mathrm{scat}}=\Gamma^{+}\otimes\Gamma^{e}\):
\label{equation:part2/sym-fitting-intro_240723:81237784-7f3c-40e0-ad1d-3f31f3924414}\begin{equation}
\Gamma_{\mathrm{scat}}=\Sigma_{g}^{+}\otimes\begin{array}{c}
\Pi_{u}~(x,y)\\
\Sigma_{u}^{+}~(z)
\end{array}=\begin{array}{c}
\Pi_{u}~(x,y)\\
\Sigma_{u}^{+}~(z)
\end{array}
\end{equation}
\sphinxAtStartPar
This is identical to \(\Gamma^{e}\) in this simple case.


\subsection{Degenerate case example: \protect\(N_2~3\pi_u^{-1}\protect\) ionization}
\label{\detokenize{part2/sym-fitting-intro_240723:degenerate-case-example-n-2-3-pi-u-1-ionization}}
\sphinxAtStartPar
For more complicated cases, multiple symmetry components may be found. For example, the ionization from a \(\Pi_u\) orbital, e.g. \(N_2\) {\hyperref[\detokenize{backmatter/glossary:term-HOMO}]{\sphinxtermref{\DUrole{xref,std,std-term}{HOMO}}}}\sphinxhyphen{}1.

\sphinxAtStartPar
In this case, \(\Gamma^{+} = \Pi_u\), and \sphinxhyphen{} working through the direct products as above \sphinxhyphen{} yields the allowed continuum components:
\label{equation:part2/sym-fitting-intro_240723:080852b1-c84e-4f36-8b54-543d08e79521}\begin{equation}
\Gamma^{e}=\begin{array}{c}
\Sigma_{g}^{+} + \Delta_{g}~(x,y)\\
\Pi_{g}~(z)
\end{array}
\end{equation}
\sphinxAtStartPar
And total scattering state symmetries:
\label{equation:part2/sym-fitting-intro_240723:17708185-cf02-4a20-8235-7e9da7063ab2}\begin{equation}
\Gamma_{\mathrm{scat}}=\Pi_{u}\otimes\begin{array}{c}
\Sigma_{g}^{+} + \Delta_{g}~(x,y)\\
\Pi_{g}~(z)
\end{array}=\begin{array}{c}
\Pi_{u} + \Delta_{u} + \Phi_{u}~(x,y)\\
\Sigma_{u}^{+} + \Sigma_{u}^{-} + \Delta_{u}~(z)
\end{array}
\end{equation}
\sphinxAtStartPar
In this case, the direct product results give multiple components for each continua. However, since the continuum wavefunction is already defined for multiple components, as given by \(\Gamma^{e}\), only the first \(\Gamma_{\mathrm{scat}}\) symmetry is required as a unique label here. In this case, therefore, \(\Gamma_{\mathrm{scat}} = \Pi_{u}~(x,y)\) and \(\Gamma_{\mathrm{scat}} =\Sigma_{u}^{+}~(z)\) suffice to label the total scattering states.


\subsection{Defining symmetrized harmonics}
\label{\detokenize{part2/sym-fitting-intro_240723:defining-symmetrized-harmonics}}
\sphinxAtStartPar
In the examples above, the allowed irreducible representations are defined by hand from direct product tables for illustrative purposes. But, in general, it is tedious to categorize/define the allowed spherical harmonics and linear combinations. With the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}, both the direct products illustrated above, and the determination of associated spherical harmonics, can be automated and the full basis set rapidly defined numerically. This was illustrated briefly in \hyperref[\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}]{Sect.\@ \ref{\detokenize{part1/theory_symmetry_140723:sec-theory-symmetry-intro}}}, and is extended here for the example cases above.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Full tabulations of the parameters available in HTML or notebook formats only.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\sphinxAtStartPar
Computationally, the cylindrically\sphinxhyphen{}symmetric \(\infty\) groups can be approximated by a high\sphinxhyphen{}order group, e.g. \(D_{\infty h} \approx D_{10h}\). (For a cross\sphinxhyphen{}check, see the \sphinxhref{http://www.gernot-katzers-spice-pages.com/character\_tables/D10h.html}{full tables and direct products online}.)  Here the notational convention is \(A1 = \Sigma^{+}\), \(A2 = \Sigma^{-}\), \(E1 = \Pi\), \(E2 = \Delta\) and so forth (see the \sphinxhref{http://symmetry.jacobs-university.de/cgi-bin/group.cgi?group=1001\&option=4}{\(D_{\infty h}\) character table} for more details).

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Example following symmetrized harmonics demo}

\PYG{c+c1}{\PYGZsh{} Import class}
\PYG{k+kn}{from} \PYG{n+nn}{pemtk}\PYG{n+nn}{.}\PYG{n+nn}{sym}\PYG{n+nn}{.}\PYG{n+nn}{symHarm} \PYG{k+kn}{import} \PYG{n}{symHarm}

\PYG{c+c1}{\PYGZsh{} Compute hamronics for D10h, lmax=4}
\PYG{n}{sym} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D10h}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{lmax}\PYG{o}{=}\PYG{l+m+mi}{4}

\PYG{n}{symObjA1g} \PYG{o}{=} \PYG{n}{symHarm}\PYG{p}{(}\PYG{n}{sym}\PYG{p}{,}\PYG{n}{lmax}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Allowed terms and mappings are given in \PYGZsq{}dipoleSyms\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} symObj.dipole[\PYGZsq{}dipoleSyms\PYGZsq{}]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Mapping coeffs to ePSproc dataType = matE
Remapped dims: \PYGZob{}\PYGZsq{}C\PYGZsq{}: \PYGZsq{}Cont\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}: \PYGZsq{}it\PYGZsq{}\PYGZcb{}
Added dim Eke
Added dim Targ
Added dim Total
Added dim mu
Added dim Type
Found dipole symmetries: 
\PYGZob{}\PYGZsq{}A2u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [0], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}z\PYGZsq{}]\PYGZcb{}, \PYGZsq{}E1u\PYGZsq{}: \PYGZob{}\PYGZsq{}m\PYGZsq{}: [\PYGZhy{}1, 1, \PYGZhy{}1, 1], \PYGZsq{}pol\PYGZsq{}: [\PYGZsq{}x\PYGZsq{}, \PYGZsq{}y\PYGZsq{}]\PYGZcb{}\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Setting the symmetry for the neutral and ion allows direct products to be computed, }
\PYG{c+c1}{\PYGZsh{} and allowed terms to be determined.}

\PYG{n}{sNeutral} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A1g}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{sIonSG} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A1g}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{directProductContinuum}\PYG{p}{(}\PYG{p}{[}\PYG{n}{sNeutral}\PYG{p}{,} \PYG{n}{sIonSG}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Results are pushed to self.continuum, in dictionary and Pandas DataFrame formats, }
\PYG{c+c1}{\PYGZsh{} and can be manipulated using standard functionality.}
\PYG{c+c1}{\PYGZsh{} The subset of allowed values are also set to a separate DataFrame and list.}

\PYG{c+c1}{\PYGZsh{} Glue figure for later \PYGZhy{} real part only in this case}
\PYG{c+c1}{\PYGZsh{} Also clean up axis labels from default state labels (\PYGZsq{}LM\PYGZsq{} and \PYGZsq{}LM\PYGZus{}p\PYGZsq{} in this case).}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dipoleTermsD10hA1g}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{continuum}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{allowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{PD}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{lllllll}
\toprule
    &     & allowed &               m &     pol &           result &       terms \\
Dipole & Target &         &                 &         &                  &             \\
\midrule
A2u & A2u &    True &             [0] &     [z] &            [A1g] &  [A1g, A1g] \\
E1u & E1u &    True &  [-1, 1, -1, 1] &  [x, y] &  [A1g, A2g, E2g] &  [A1g, A1g] \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Dipole\sphinxhyphen{}allowed continuum symmetries (“Target”) for \(D_{10h}\), \(A_{1g}\) ionization.}\label{\detokenize{part2/sym-fitting-intro_240723:fig-dipoletermsd10ha1g}}\end{figure}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Setting the symmetry for the neutral and ion allows direct products to be computed, }
\PYG{c+c1}{\PYGZsh{} and allowed terms to be determined.}

\PYG{n}{sNeutral} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A1g}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{sIonPU} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{E1u}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Define new object for E1u case}
\PYG{n}{symObjE1u} \PYG{o}{=} \PYG{n}{symHarm}\PYG{p}{(}\PYG{n}{sym}\PYG{p}{,}\PYG{n}{lmax}\PYG{p}{)}
\PYG{n}{symObjE1u}\PYG{o}{.}\PYG{n}{directProductContinuum}\PYG{p}{(}\PYG{p}{[}\PYG{n}{sNeutral}\PYG{p}{,} \PYG{n}{sIonPU}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Results are pushed to self.continuum, in dictionary and Pandas DataFrame formats, }
\PYG{c+c1}{\PYGZsh{} and can be manipulated using standard functionality.}
\PYG{c+c1}{\PYGZsh{} The subset of allowed values are also set to a separate DataFrame and list.}

\PYG{c+c1}{\PYGZsh{} Glue table for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dipoleTermsD10hE1u}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{symObjE1u}\PYG{o}{.}\PYG{n}{continuum}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{allowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{PD}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{lllllll}
\toprule
    &     & allowed &               m &     pol &                result &       terms \\
Dipole & Target &         &                 &         &                       &             \\
\midrule
A2u & E1g &    True &             [0] &     [z] &       [A1g, A2g, E2g] &  [A1g, E1u] \\
E1u & A1g &    True &  [-1, 1, -1, 1] &  [x, y] &       [A1g, A2g, E2g] &  [A1g, E1u] \\
    & A2g &    True &  [-1, 1, -1, 1] &  [x, y] &       [A1g, A2g, E2g] &  [A1g, E1u] \\
    & E2g &    True &  [-1, 1, -1, 1] &  [x, y] &  [A1g, A2g, E2g, E4g] &  [A1g, E1u] \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Dipole\sphinxhyphen{}allowed continuum symmetries (“Target”) for \(D_{10h}\), \(E_{1u}\) ionization.}\label{\detokenize{part2/sym-fitting-intro_240723:fig-dipoletermsd10he1u}}\end{figure}

\sphinxAtStartPar
The allowed terms can be further expressed in terms of the spherical harmonic components.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Basis table with the Character values limited to those defined in }
\PYG{c+c1}{\PYGZsh{} self.continuum[\PYGZsq{}allowed\PYGZsq{}][\PYGZsq{}PD\PYGZsq{}] Target column}
\PYG{n}{symObjE1u}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{n}{symFilter} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{YlmType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{comp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 

\PYG{c+c1}{\PYGZsh{} Glue table for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{dipoleTermsD10hBasis}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{symObjE1u}\PYG{o}{.}\PYG{n}{displayXlm}\PYG{p}{(}\PYG{n}{symFilter} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} 
                                                  \PYG{n}{YlmType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{comp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{returnPD}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{lllllllll}
\toprule
    &   &   & {} & \multicolumn{5}{l}{b} \\
    &   &   & l &       0 & 1 &                         2 & 3 &                         4 \\
Character (\$\textbackslash Gamma\$) & SALC (h) & PFIX (\$\textbackslash mu\$) & m &         &   &                           &   &                           \\
\midrule
A1g & 0 & 0 &  0 &  (1+0j) &   &                           &   &                           \\
    & 1 & 0 &  0 &         &   &                    (1+0j) &   &                           \\
    & 2 & 0 &  0 &         &   &                           &   &                    (1+0j) \\
E1g & 0 & 0 & -1 &         &   &   (0.7071067811865475+0j) &   &                           \\
    &   &   &  1 &         &   &   (0.7071067811865475-0j) &   &                           \\
    &   & 1 & -1 &         &   &  (-0.7071067811865475-0j) &   &                           \\
    &   &   &  1 &         &   &   (0.7071067811865475-0j) &   &                           \\
    & 1 & 0 & -1 &         &   &                           &   &   (0.7071067811865475+0j) \\
    &   &   &  1 &         &   &                           &   &   (0.7071067811865475-0j) \\
    &   & 1 & -1 &         &   &                           &   &  (-0.7071067811865475-0j) \\
    &   &   &  1 &         &   &                           &   &   (0.7071067811865475-0j) \\
E2g & 0 & 0 & -2 &         &   &   (0.7071067811865475+0j) &   &                           \\
    &   &   &  2 &         &   &   (0.7071067811865475+0j) &   &                           \\
    &   & 1 & -2 &         &   &  (-0.7071067811865475+0j) &   &                           \\
    &   &   &  2 &         &   &   (0.7071067811865475+0j) &   &                           \\
    & 1 & 0 & -2 &         &   &                           &   &   (0.7071067811865475+0j) \\
    &   &   &  2 &         &   &                           &   &   (0.7071067811865475+0j) \\
    &   & 1 & -2 &         &   &                           &   &  (-0.7071067811865475+0j) \\
    &   &   &  2 &         &   &                           &   &   (0.7071067811865475+0j) \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Dipole\sphinxhyphen{}allowed basis set for \(D_{10h}\), \(E_{1u}\) ionization.}\label{\detokenize{part2/sym-fitting-intro_240723:fig-dipoletermsd10hbasis}}\end{figure}


\subsection{Mapping symmetrized harmonics to fit parameters}
\label{\detokenize{part2/sym-fitting-intro_240723:mapping-symmetrized-harmonics-to-fit-parameters}}\label{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-mapping-params}}
\sphinxAtStartPar
The final preparatory steps for tackling a specific retrieval problem is to map the allowed channels to photoionization matrix elements \sphinxhyphen{} including the assignment of any missing terms \sphinxhyphen{} and from these to fitting paramters. The matrix elements are currently defined in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} and the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} following the definitions in \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]}, and the symmetry\sphinxhyphen{}defined cases can be remapped to this format. (Further information can be found in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.) For a comparison with \sphinxstyleemphasis{ab initio} matrix elements, see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-comparison-with-abinitio}]{Sect.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-comparison-with-abinitio}}}.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
For symmetry\sphinxhyphen{}defined basis sets, these must first be mapped to an ePSproc data structure, although this step is not necessary when working from \sphinxstyleemphasis{ab initio} basis sets. This is explored in \hyperref[\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-eps}]{Sect.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-eps}}}.

\item {} 
\sphinxAtStartPar
From a given basis set, the parameters used for fitting data are determined. This converts the parameters to \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} objects in magnitude\sphinxhyphen{}phase form, and (optionally) sets various symmetry relations and constraints. This is explored in \hyperref[\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-fittingparams}]{Sect.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-fittingparams}}}.

\end{enumerate}

\sphinxAtStartPar
Further examples can be found in the remainder of this text, and also in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.


\subsubsection{Remapping to ePolyScat definitions}
\label{\detokenize{part2/sym-fitting-intro_240723:remapping-to-epolyscat-definitions}}\label{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-eps}}
\sphinxAtStartPar
In the remapping, the code attempts to assign all the symmetries matching ePolyScat definitions from the direct products. A worked example is given in the code blocks in this section, including a full output table and graphical illustration (\hyperref[\detokenize{part2/sym-fitting-intro_240723:fig-materemapd10ha1g}]{Fig.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:fig-materemapd10ha1g}}}).

\sphinxAtStartPar
The terms are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{Cont}} is the continuum (free electron) symmetry, \(\Gamma^{e}\).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{Targ}} is the target state symmetry, \(\Gamma^{+}\).

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{Total}} is the overall symmetry of the scattering state, \(\Gamma_{\mathrm{scat}}=\Gamma^{+}\otimes\Gamma^{e}\).

\end{enumerate}

\sphinxAtStartPar
Additionally, the current default remapping changes some of the terms defined by the symmetrized harmonics routines and conventions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Symmetry \sphinxcode{\sphinxupquote{C}} > \sphinxcode{\sphinxupquote{Cont}} (continuum symmetry label in ePSproc)

\item {} 
\sphinxAtStartPar
Index \sphinxcode{\sphinxupquote{h}} > \sphinxcode{\sphinxupquote{it}} (degeneracy index in ePSproc)

\item {} 
\sphinxAtStartPar
Index \sphinxcode{\sphinxupquote{mu}} > \sphinxcode{\sphinxupquote{muX}} (to avoid confusion with photon index \sphinxcode{\sphinxupquote{mu}} in ePSproc)

\end{itemize}

\sphinxAtStartPar
Note, in particular, that \(\mu\) is \sphinxhyphen{} unfortunately \sphinxhyphen{} the photon polarization term in the conventional photoionization equations, but also used in the standard definition of the symmetrized harmonics as a degeneracy index. In some cases, the symmetrization indicies \(\mu\) or \(h\) may be redundant, and can be dropped or summed over, but care must be taken here to avoid breaking the symmetry of the simplified basis set.

\sphinxAtStartPar
Finally, the remapping adds additional labels used by \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]}, but which are not necessarily required in general:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{Type}}: for ePolyScat results, this labels length or velocity gauge results; this is assigned as \sphinxcode{\sphinxupquote{U}} (unassigned) in the conversion.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{Eke}}: the photoelectron kinetic energy, for the basis states this is just set to 0.

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{mu}}: this is set to NaN by the main routine; if the ionizing channel symmetries are defined these values (the photon polarization) can be determined from the dipole\sphinxhyphen{}allowed terms, and this is done by the \sphinxcode{\sphinxupquote{assignSymMuTerms()}} method, as illustrated below.

\end{itemize}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run conversion with a different dimMap \PYGZam{} dataType \PYGZhy{} note this includes all symmetries, }
\PYG{c+c1}{\PYGZsh{} and both real and complex harmonic basis sets}
\PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} With custom dim mapping (optional)...}
\PYG{n}{dimMap} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cont}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{it}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}   \PYG{c+c1}{\PYGZsh{} Default dimMap = \PYGZob{}\PYGZsq{}C\PYGZsq{}:\PYGZsq{}Cont\PYGZsq{},\PYGZsq{}h\PYGZsq{}:\PYGZsq{}it\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}:\PYGZsq{}muX\PYGZsq{}\PYGZcb{}  }
\PYG{c+c1}{\PYGZsh{} dimMap = \PYGZob{}\PYGZsq{}C\PYGZsq{}:\PYGZsq{}Cont\PYGZsq{},\PYGZsq{}h\PYGZsq{}:\PYGZsq{}it\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}:\PYGZsq{}muX\PYGZsq{}\PYGZcb{}  \PYGZsh{} Default case}

\PYG{c+c1}{\PYGZsh{} Map to ePSproc definitions}
\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{toePSproc}\PYG{p}{(}\PYG{n}{dataType}\PYG{o}{=}\PYG{n}{dataType}\PYG{p}{,} \PYG{n}{dimMap}\PYG{o}{=}\PYG{n}{dimMap}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} To assign specific terms, use self.assignMissingSym}
\PYG{c+c1}{\PYGZsh{} Note this can take a single value, or a list which must match the size of the }
\PYG{c+c1}{\PYGZsh{} Sym multiindex defined in the Xarray dataset.}
\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{assignMissingSym}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Targ}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{sIonSG}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} To define terms from produts, use self.assignMissingSymProd}
\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{assignMissingSymProd}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} To attempt to assign mu values (by symmetry), use self.assignSymMuTerms()}
\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{assignSymMuTerms}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Show Pandas table of results}
\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symAllowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{PD}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{fillna}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Mapping coeffs to ePSproc dataType = matE
Remapped dims: \PYGZob{}\PYGZsq{}C\PYGZsq{}: \PYGZsq{}Cont\PYGZsq{}, \PYGZsq{}mu\PYGZsq{}: \PYGZsq{}it\PYGZsq{}\PYGZcb{}
Added dim Eke
Added dim Targ
Added dim Total
Added dim mu
Added dim Type
*** Updated self.coeffs[\PYGZsq{}matE\PYGZsq{}] with new coords.
Assigned \PYGZsq{}Total\PYGZsq{} from A1g x A1g = [\PYGZsq{}A1g\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from A2u x A1g = [\PYGZsq{}A2u\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E1g x A1g = [\PYGZsq{}E1g\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E1u x A1g = [\PYGZsq{}E1u\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E2g x A1g = [\PYGZsq{}E2g\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E2u x A1g = [\PYGZsq{}E2u\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E3g x A1g = [\PYGZsq{}E3g\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E3u x A1g = [\PYGZsq{}E3u\PYGZsq{}]
Assigned \PYGZsq{}Total\PYGZsq{} from E4g x A1g = [\PYGZsq{}E4g\PYGZsq{}]
*** Updated self.coeffs[\PYGZsq{}matE\PYGZsq{}] with new coords.
Assigned dipole\PYGZhy{}allowed terms for dim = \PYGZsq{}Cont\PYGZsq{} to self.coeffs[\PYGZsq{}symAllowed\PYGZsq{}]
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\begin{tabular}{lllllllllll}
\toprule
  &     &     &   &   &   &   &    & Cont &     A2u &                       E1u \\
Eke & Targ & Total & Type & h & it & l & m & mu &         &                           \\
\midrule
0 & A1g & A2u & U & 0 & 0 & 1 &  0 &  0 &  (1+0j) &                           \\
  &     &     &   & 1 & 0 & 3 &  0 &  0 &  (1+0j) &                           \\
  &     & E1u & U & 0 & 0 & 1 & -1 & -1 &         &   (0.7071067811865475+0j) \\
  &     &     &   &   &   &   &    &  1 &         &   (0.7071067811865475+0j) \\
  &     &     &   &   &   &   &  1 & -1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   &   &   &   &    &  1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   &   & 1 & 1 & -1 & -1 &         &  (-0.7071067811865475+0j) \\
  &     &     &   &   &   &   &    &  1 &         &  (-0.7071067811865475+0j) \\
  &     &     &   &   &   &   &  1 & -1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   &   &   &   &    &  1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   & 1 & 0 & 3 & -1 & -1 &         &   (0.7071067811865475+0j) \\
  &     &     &   &   &   &   &    &  1 &         &   (0.7071067811865475+0j) \\
  &     &     &   &   &   &   &  1 & -1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   &   &   &   &    &  1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   &   & 1 & 3 & -1 & -1 &         &  (-0.7071067811865475+0j) \\
  &     &     &   &   &   &   &    &  1 &         &  (-0.7071067811865475+0j) \\
  &     &     &   &   &   &   &  1 & -1 &         &  (-0.7071067811865475-0j) \\
  &     &     &   &   &   &   &    &  1 &         &  (-0.7071067811865475-0j) \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot values}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{n}{titleString}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Symmetrized matrix elements defined for }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{sym}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{, }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{sNeutral}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZdl{}\PYGZca{}}\PYG{l+s+se}{\PYGZob{}\PYGZob{}}\PYG{l+s+s1}{\PYGZhy{}1}\PYG{l+s+se}{\PYGZcb{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZdl{} ionization}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{o}{*}\PYG{n}{\PYGZus{}}\PYG{p}{,} \PYG{n}{gFig} \PYG{o}{=}  \PYG{n}{ep}\PYG{o}{.}\PYG{n}{lmPlot}\PYG{p}{(}\PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symAllowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{XR}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b (comp)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} 
                      \PYG{n}{titleString}\PYG{o}{=}\PYG{n}{titleString}\PYG{p}{,} \PYG{n}{xDim}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{LM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{l}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{sumDims}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{h}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{labelCols} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Glue figure for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{matEremapD10hA1g}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gFig}\PYG{o}{.}\PYG{n}{fig}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{8896575d1a3ed143693e38b575aa962f59770d2327eeb5043f112986f894ae0b}.png}
\caption{Dipole\sphinxhyphen{}allowed continuum matrix elements for \(D_{10h}\), \(A_{1g}\) ionization, arranged by \((l,m)\).}\label{\detokenize{part2/sym-fitting-intro_240723:fig-materemapd10ha1g}}\end{figure}


\subsubsection{Mapping to fitting parameters (and reduction)}
\label{\detokenize{part2/sym-fitting-intro_240723:mapping-to-fitting-parameters-and-reduction}}\label{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-fittingparams}}
\sphinxAtStartPar
Finally, the basis set of matrix elements can be assigned to a set of fitting parameters. In this case, as per Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:I-zeta-mag-phase}, the parameters are mapped to magnitude\sphinxhyphen{}phase form; additionally, the fitting routine allows for the definition of relationships between the parameters. This provides a way to reduce the effective size of the basis set to only the unique values, with other terms defined purely by their symmetry relations. Consequently, degenerate cases, as detailed above, as well as cases with defined phase relations, can be efficiently reduced to a smaller basis set for fitting. Note that the default routine labels parameters by the full set of quantum numbers, with an \sphinxcode{\sphinxupquote{m}} or \sphinxcode{\sphinxupquote{p}} prefix to denote the magnitude and phase terms corresponding to the partial\sphinxhyphen{}wave channel; this ensures a unique naming scheme, but is also rather unwieldy (as can be seen below). In cases where fewer quantum numbers are required these can be defined and the parameter names remapped, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for further details.

\sphinxAtStartPar
For quick setup, there is an automated routine to set relations if applicable. The automated routine currently checks for the following relationships: identity (equal complex values), magnitude and phase equality, complex rotations by \(\pm\pi\), where matrix elements are grouped by symmetry (specifically \sphinxcode{\sphinxupquote{Cont}}) and \sphinxcode{\sphinxupquote{l}} prior to pair\sphinxhyphen{}wise testing. For more control, additional functions can be passed. Alternatively, the automatic setting can be skipped and/or relationships redefined or set manually. This provides a way to test if the symmetry\sphinxhyphen{}definitions are manifest in experimental data, rather than imposing them during fitting, or to explore other possible correlations between fitted parameters. Note, however, that in some cases the number of unique parameters in an unsymmetrized case may be large, so care should also be taken to ensure that fit results are meaningful in such cases (e.g. by employing a sufficiently large dataset, and testing for reproducibility).

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Default matrix element relationship tests are set by symCheckDefns}
\PYG{k+kn}{from} \PYG{n+nn}{pemtk}\PYG{n+nn}{.}\PYG{n+nn}{fit}\PYG{n+nn}{.}\PYG{n+nn}{\PYGZus{}sym} \PYG{k+kn}{import} \PYG{n}{symCheckDefns}

\PYG{n}{symCheckDefns}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZob{}\PYGZsq{}i\PYGZsq{}: \PYGZob{}\PYGZsq{}name\PYGZsq{}: \PYGZsq{}identity\PYGZsq{},
  \PYGZsq{}lam\PYGZsq{}: \PYGZlt{}function pemtk.fit.\PYGZus{}sym.symCheckDefns.\PYGZlt{}locals\PYGZgt{}.\PYGZlt{}lambda\PYGZgt{}(x)\PYGZgt{},
  \PYGZsq{}transform\PYGZsq{}: False,
  \PYGZsq{}constraint\PYGZsq{}: \PYGZsq{}x\PYGZsq{}\PYGZcb{},
 \PYGZsq{}abs\PYGZsq{}: \PYGZob{}\PYGZsq{}name\PYGZsq{}: \PYGZsq{}abs\PYGZsq{},
  \PYGZsq{}lam\PYGZsq{}: \PYGZlt{}function pemtk.fit.\PYGZus{}sym.symCheckDefns.\PYGZlt{}locals\PYGZgt{}.\PYGZlt{}lambda\PYGZgt{}(x)\PYGZgt{},
  \PYGZsq{}transform\PYGZsq{}: True,
  \PYGZsq{}constraint\PYGZsq{}: \PYGZsq{}m\PYGZus{}x\PYGZsq{}\PYGZcb{},
 \PYGZsq{}phase\PYGZsq{}: \PYGZob{}\PYGZsq{}name\PYGZsq{}: \PYGZsq{}phase\PYGZsq{},
  \PYGZsq{}lam\PYGZsq{}: \PYGZlt{}function pemtk.fit.\PYGZus{}sym.symCheckDefns.\PYGZlt{}locals\PYGZgt{}.\PYGZlt{}lambda\PYGZgt{}(x)\PYGZgt{},
  \PYGZsq{}transform\PYGZsq{}: True,
  \PYGZsq{}constraint\PYGZsq{}: \PYGZsq{}p\PYGZus{}x\PYGZsq{}\PYGZcb{},
 \PYGZsq{}crot\PYGZus{}p\PYGZsq{}: \PYGZob{}\PYGZsq{}name\PYGZsq{}: \PYGZsq{}Complex rotation +pi/2\PYGZsq{},
  \PYGZsq{}lam\PYGZsq{}: \PYGZlt{}function pemtk.fit.\PYGZus{}sym.symCheckDefns.\PYGZlt{}locals\PYGZgt{}.\PYGZlt{}lambda\PYGZgt{}(x)\PYGZgt{},
  \PYGZsq{}transform\PYGZsq{}: False,
  \PYGZsq{}constraint\PYGZsq{}: \PYGZsq{}arctan2(sin(p\PYGZus{}x+pi/2), cos(p\PYGZus{}x+pi/2))\PYGZsq{}\PYGZcb{},
 \PYGZsq{}crot\PYGZus{}m\PYGZsq{}: \PYGZob{}\PYGZsq{}name\PYGZsq{}: \PYGZsq{}Complex rotation \PYGZhy{}pi/2\PYGZsq{},
  \PYGZsq{}lam\PYGZsq{}: \PYGZlt{}function pemtk.fit.\PYGZus{}sym.symCheckDefns.\PYGZlt{}locals\PYGZgt{}.\PYGZlt{}lambda\PYGZgt{}(x)\PYGZgt{},
  \PYGZsq{}transform\PYGZsq{}: False,
  \PYGZsq{}constraint\PYGZsq{}: \PYGZsq{}arctan2(sin(p\PYGZus{}x\PYGZhy{}pi/2), cos(p\PYGZus{}x\PYGZhy{}pi/2))\PYGZsq{}\PYGZcb{}\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
\sphinxstylestrong{Automated assignment from defined matrix elements}

\sphinxAtStartPar
The code blocks below illustrate the automated routine, and results are tabulated in \hyperref[\detokenize{part2/sym-fitting-intro_240723:fig-fittingparamsd10ha1g}]{Fig.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:fig-fittingparamsd10ha1g}}}.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pemtk}\PYG{n+nn}{.}\PYG{n+nn}{fit}\PYG{n+nn}{.}\PYG{n+nn}{fitClass} \PYG{k+kn}{import} \PYG{n}{pemtkFit}

\PYG{c+c1}{\PYGZsh{} Example using data class (setup in init script)}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pemtkFit}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set to new key in data class}
\PYG{n}{dataKey} \PYG{o}{=} \PYG{n}{sym}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}

\PYG{c+c1}{\PYGZsh{} Assign allowed matrix elements to fit object}
\PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} General case \PYGZhy{} just use complex coeffs directly}
\PYG{c+c1}{\PYGZsh{} data.data[dataKey][dataType] = symObj.coeffs[dataType][\PYGZsq{}b (comp)\PYGZsq{}]}

\PYG{c+c1}{\PYGZsh{} Specific case \PYGZhy{} e.g. sum over \PYGZsq{}h\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]} \PYG{o}{=} \PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symAllowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{XR}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b (comp)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{h}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Propagate attrs}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{dataKey}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{o}{.}\PYG{n}{attrs} \PYG{o}{=} \PYG{n}{symObjA1g}\PYG{o}{.}\PYG{n}{coeffs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{symAllowed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{XR}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{attrs}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Update selection with options}
\PYG{c+c1}{\PYGZsh{} E.g. Matrix element sub\PYGZhy{}selection}
\PYG{c+c1}{\PYGZsh{} data.selOpts[\PYGZsq{}matE\PYGZsq{}] = \PYGZob{}\PYGZsq{}thres\PYGZsq{}: 0.01, \PYGZsq{}inds\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}:\PYGZsq{}U\PYGZsq{},\PYGZsq{}Cont\PYGZsq{}:\PYGZsq{}A1\PYGZsq{}\PYGZcb{}\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{selOpts}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{thres}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.01}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{inds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{U}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{n}{dataKey} \PYG{o}{=} \PYG{n}{sym}\PYG{p}{,} \PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{}, resetSelectors=True)  \PYGZsh{} Subselect from \PYGZsq{}orb5\PYGZsq{} dataset, matrix elements}

\PYG{c+c1}{\PYGZsh{} And for the polarisation geometries...}
\PYG{c+c1}{\PYGZsh{} data.selOpts[\PYGZsq{}pol\PYGZsq{}] = \PYGZob{}\PYGZsq{}inds\PYGZsq{}: \PYGZob{}\PYGZsq{}Labels\PYGZsq{}: \PYGZsq{}z\PYGZsq{}\PYGZcb{}\PYGZcb{}}
\PYG{c+c1}{\PYGZsh{} data.setSubset(dataKey = \PYGZsq{}pol\PYGZsq{}, dataType = \PYGZsq{}pol\PYGZsq{})}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Subselected from dataset \PYGZsq{}D10h\PYGZsq{}, dataType \PYGZsq{}matE\PYGZsq{}: 72 from 540 points (13.33\PYGZpc{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set matrix elements to fitting parameters}
\PYG{c+c1}{\PYGZsh{} Running for the default case will attempt to automatically set the relations between }
\PYG{c+c1}{\PYGZsh{} matrix elements according to symmetry.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setMatEFit}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart
\begin{equation*}
\begin{split}\begin{tabular}{llrlllrrrll}
\toprule
{} &                       name &  value & stderr &   vary &                       expr &  init\_value &        min &    max & brute\_step & correl \\
\midrule
0  &    m\_A2u\_0\_A1g\_A2u\_1\_0\_0\_0 &  1.000 &   None &   True &                       None &       1.000 &  1.000e-04 &  5.000 &       None &   None \\
1  &    m\_A2u\_0\_A1g\_A2u\_3\_0\_0\_0 &  1.000 &   None &   True &                       None &       1.000 &  1.000e-04 &  5.000 &       None &   None \\
2  &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &  0.707 &   None &   True &                       None &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
3  &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &  0.707 &   None &   True &                       None &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
4  &   m\_E1u\_0\_A1g\_E1u\_1\_n1\_1\_0 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
5  &   m\_E1u\_0\_A1g\_E1u\_1\_n1\_1\_1 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
6  &   m\_E1u\_0\_A1g\_E1u\_1\_1\_n1\_0 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
7  &   m\_E1u\_0\_A1g\_E1u\_1\_1\_n1\_1 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
8  &    m\_E1u\_0\_A1g\_E1u\_1\_1\_1\_0 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
9  &    m\_E1u\_0\_A1g\_E1u\_1\_1\_1\_1 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
10 &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &  0.707 &   None &   True &                       None &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
11 &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &  0.707 &   None &   True &                       None &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
12 &   m\_E1u\_0\_A1g\_E1u\_3\_n1\_1\_0 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
13 &   m\_E1u\_0\_A1g\_E1u\_3\_n1\_1\_1 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
14 &   m\_E1u\_0\_A1g\_E1u\_3\_1\_n1\_0 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
15 &   m\_E1u\_0\_A1g\_E1u\_3\_1\_n1\_1 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
16 &    m\_E1u\_0\_A1g\_E1u\_3\_1\_1\_0 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
17 &    m\_E1u\_0\_A1g\_E1u\_3\_1\_1\_1 &  0.707 &   None &  False &  m\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.707 &  1.000e-04 &  5.000 &       None &   None \\
18 &    p\_A2u\_0\_A1g\_A2u\_1\_0\_0\_0 &  0.000 &   None &  False &                       None &       0.000 & -3.142e+00 &  3.142 &       None &   None \\
19 &    p\_A2u\_0\_A1g\_A2u\_3\_0\_0\_0 &  0.000 &   None &   True &                       None &       0.000 & -3.142e+00 &  3.142 &       None &   None \\
20 &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &  0.000 &   None &   True &                       None &       0.000 & -3.142e+00 &  3.142 &       None &   None \\
21 &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &  3.142 &   None &   True &                       None &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
22 &   p\_E1u\_0\_A1g\_E1u\_1\_n1\_1\_0 &  0.000 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_0 &       0.000 & -3.142e+00 &  3.142 &       None &   None \\
23 &   p\_E1u\_0\_A1g\_E1u\_1\_n1\_1\_1 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
24 &   p\_E1u\_0\_A1g\_E1u\_1\_1\_n1\_0 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
25 &   p\_E1u\_0\_A1g\_E1u\_1\_1\_n1\_1 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
26 &    p\_E1u\_0\_A1g\_E1u\_1\_1\_1\_0 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
27 &    p\_E1u\_0\_A1g\_E1u\_1\_1\_1\_1 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_1\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
28 &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &  0.000 &   None &   True &                       None &       0.000 & -3.142e+00 &  3.142 &       None &   None \\
29 &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &  3.142 &   None &   True &                       None &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
30 &   p\_E1u\_0\_A1g\_E1u\_3\_n1\_1\_0 &  0.000 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_0 &       0.000 & -3.142e+00 &  3.142 &       None &   None \\
31 &   p\_E1u\_0\_A1g\_E1u\_3\_n1\_1\_1 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
32 &   p\_E1u\_0\_A1g\_E1u\_3\_1\_n1\_0 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
33 &   p\_E1u\_0\_A1g\_E1u\_3\_1\_n1\_1 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
34 &    p\_E1u\_0\_A1g\_E1u\_3\_1\_1\_0 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
35 &    p\_E1u\_0\_A1g\_E1u\_3\_1\_1\_1 &  3.142 &   None &  False &  p\_E1u\_0\_A1g\_E1u\_3\_n1\_n1\_1 &       3.142 & -3.142e+00 &  3.142 &       None &   None \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}\caption{Fitting parameters as assigned for \(D_{10h}\), \(A_{1g}\) ionization. Note the \sphinxcode{\sphinxupquote{vary}} column, which defines the symmetry\sphinxhyphen{}unique values for fitting, whilst the \sphinxcode{\sphinxupquote{expression}} column indicates the relationships of the non\sphinxhyphen{}unique values to the floated parameters.}\label{\detokenize{part2/sym-fitting-intro_240723:fig-fittingparamsd10ha1g}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Modifying fitting basis parameters}

\sphinxAtStartPar
A brief illustration of defining constraints is given below, for more details see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_basic\_demo\_030621-full\_010922.html\#Setting-parameter-relations/constraints}{basic fitting guide}. For more details on the base lmfit parameters class that is used here, see \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]}, particularly the documentation on \sphinxhref{https://lmfit.github.io/lmfit-py/parameters.html}{parameters} and \sphinxhref{https://lmfit.github.io/lmfit-py/constraints.html}{constraints}.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Full tabulations of the parameters available in HTML or notebook formats only.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set parameters with NO constraints set (except a reference phase)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setMatEFit}\PYG{p}{(}\PYG{n}{paramsCons} \PYG{o}{=} \PYG{k+kc}{None}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To add manual constraints}
\PYG{c+c1}{\PYGZsh{} Set param constraints as dict}
\PYG{c+c1}{\PYGZsh{} Any basic mathematical relations can be set here, }
\PYG{c+c1}{\PYGZsh{} see https://lmfit.github.io/lmfit\PYGZhy{}py/constraints.html}
\PYG{n}{paramsCons} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{paramsCons}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m\PYGZus{}A2u\PYGZus{}0\PYGZus{}A1g\PYGZus{}A2u\PYGZus{}1\PYGZus{}0\PYGZus{}0\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{5*m\PYGZus{}A2u\PYGZus{}0\PYGZus{}A1g\PYGZus{}A2u\PYGZus{}3\PYGZus{}0\PYGZus{}0\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Missing settings will generate an error message}
\PYG{n}{paramsCons}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{test}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p\PYGZus{}PU\PYGZus{}SG\PYGZus{}PU\PYGZus{}3\PYGZus{}1\PYGZus{}n1\PYGZus{}1}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Init parameters with specified constraints}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setMatEFit}\PYG{p}{(}\PYG{n}{paramsCons} \PYG{o}{=} \PYG{n}{paramsCons}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Individual parameters can be addressed by name, }

\PYG{n}{data}\PYG{o}{.}\PYG{n}{params}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m\PYGZus{}E1u\PYGZus{}0\PYGZus{}A1g\PYGZus{}E1u\PYGZus{}1\PYGZus{}n1\PYGZus{}n1\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}Parameter \PYGZsq{}m\PYGZus{}E1u\PYGZus{}0\PYGZus{}A1g\PYGZus{}E1u\PYGZus{}1\PYGZus{}n1\PYGZus{}n1\PYGZus{}0\PYGZsq{}, value=0.7071067811865475, bounds=[0.0001:5.0]\PYGZgt{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Properties can be modified directly... }
\PYG{n}{data}\PYG{o}{.}\PYG{n}{params}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m\PYGZus{}A2u\PYGZus{}0\PYGZus{}A1g\PYGZus{}A2u\PYGZus{}3\PYGZus{}0\PYGZus{}0\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{value} \PYG{o}{=} \PYG{l+m+mf}{1.777}

\PYG{c+c1}{\PYGZsh{} ...or by using lmfit\PYGZsq{}s `.set()` method.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{params}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m\PYGZus{}E1u\PYGZus{}0\PYGZus{}A1g\PYGZus{}E1u\PYGZus{}1\PYGZus{}n1\PYGZus{}n1\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{n}{value} \PYG{o}{=} \PYG{l+m+mf}{1.36}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{params}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m\PYGZus{}E1u\PYGZus{}0\PYGZus{}A1g\PYGZus{}E1u\PYGZus{}1\PYGZus{}n1\PYGZus{}n1\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{n}{vary} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{params}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m\PYGZus{}E1u\PYGZus{}0\PYGZus{}A1g\PYGZus{}E1u\PYGZus{}1\PYGZus{}n1\PYGZus{}n1\PYGZus{}0}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}Parameter \PYGZsq{}m\PYGZus{}E1u\PYGZus{}0\PYGZus{}A1g\PYGZus{}E1u\PYGZus{}1\PYGZus{}n1\PYGZus{}n1\PYGZus{}0\PYGZsq{}, value=1.36 (fixed), bounds=[0.0001:5.0]\PYGZgt{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The full set can always be checked via self.params}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{params}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The full mapping of parameter names and indexes is given in self.lmmu}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{lmmu}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
\sphinxstylestrong{Manually setting fitting basis}

\sphinxAtStartPar
To modify and/or set a basis set manually, the same functions can be used with different inputs and/or options. A few examples are given here, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for more information.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Manual configuration of matrix elements}
\PYG{c+c1}{\PYGZsh{} Example using data class}
\PYG{n}{dataManual} \PYG{o}{=} \PYG{n}{pemtkFit}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Manual setting for matrix elements}
\PYG{c+c1}{\PYGZsh{} See API docs at https://epsproc.readthedocs.io/en/dev/modules/epsproc.util.setMatE.html}
\PYG{n}{EPoints} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{setMatE}\PYG{p}{(}\PYG{n}{data} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{EPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{EPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{EPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} 
             \PYG{n}{dataNames}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{l}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Matrix elements are set to Xarray and Pandas formats, under the \PYGZsq{}matE\PYGZsq{} key}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{pd}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To use manual settings for fitting, set `conformDims=True` to ensure ePSproc labelling}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{setMatE}\PYG{p}{(}\PYG{n}{data} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{EPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{n}{EPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{o}{*}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{EPoints}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} 
             \PYG{n}{dataNames}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{l}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{conformDims}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Then use as normal}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{selOpts}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{thres}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.01}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{inds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{U}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Eke}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mi}{1}\PYG{p}{\PYGZcb{}} \PYG{p}{\PYGZcb{}}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{data}\PYG{o}{.}\PYG{n}{subKey}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{it}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}   \PYG{c+c1}{\PYGZsh{} In some cases NaN values may need to be set for setMatEFit.}
\PYG{n}{dataManual}\PYG{o}{.}\PYG{n}{setMatEFit}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Comparison with symmetry\sphinxhyphen{}defined and computational matrix elements}
\label{\detokenize{part2/sym-fitting-intro_240723:comparison-with-symmetry-defined-and-computational-matrix-elements}}\label{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-comparison-with-abinitio}}
\sphinxAtStartPar
For comparison of a given symmetry\sphinxhyphen{}defined basis set with sample \sphinxstyleemphasis{ab initio} calculations using \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]} calculations, results can be computed locally or pulled from the web. Some sample/test datasets can be found as part of the \sphinxhref{https://github.com/phockett/ePSproc/tree/master/data}{ePSproc repo}, which includes the case study examples herein. Further \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]} datasets are available from \sphinxhref{https://github.com/phockett/ePSdata/}{ePSdata} {[}\hyperlink{cite.backmatter/bibliography:id679}{48}{]}, and \sphinxhref{https://epsproc.readthedocs.io/en/dev/demos/ePSdata\_download\_demo\_300720.html}{data can be pulled using the python ePSdata interface}.

\sphinxAtStartPar
In the following, the test case above for \(N_2~3\sigma_g^{-1}\) ionization is illustrated. Note that this comparison shows the results of a full \sphinxstyleemphasis{ab initio} computation of the matrix elements (Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:matE-dipole}) versus the symmetry\sphinxhyphen{}allowed harmonics and associated \(b_{hl\lambda}^{\Gamma\mu}\) parameters (Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:symHarm-defn}). In the former case, the \(b_{hl\lambda}^{\Gamma\mu}\) are incorporated into the numerical results, but the full angular momentum selection rules and dipole integrals are also included; in the latter case the \(b_{hl\lambda}^{\Gamma\mu}\) parameters serve to define the allowed matrix elements, and symmetry relations (e.g. phase, rotations and degeneracy), but \sphinxstyleemphasis{do not} include any other effects. Hence the comparison here indicates whether the symmetry\sphinxhyphen{}defined basis set is sufficient for a matrix element reconstruction, but it may contain terms which are zero in practice, or otherwise drop out from the complete photoionization treatment. Some conventions may also be different.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Pull N2 data from ePSproc Github repo}
\PYG{n}{dataName} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2Data}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Set data dir}
\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{Path}\PYG{o}{.}\PYG{n}{cwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dataName}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} For pulling data from Github, a utility function is available}
\PYG{c+c1}{\PYGZsh{} This requires the repo subpath, and optionally branch}
\PYG{n}{fDictMatE}\PYG{p}{,} \PYG{n}{fAllMatE} \PYG{o}{=} \PYG{n}{ep}\PYG{o}{.}\PYG{n}{util}\PYG{o}{.}\PYG{n}{io}\PYG{o}{.}\PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/photoionization/n2\PYGZus{}multiorb}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
                                                    \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{,} \PYG{n}{ref}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dev}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Optional settings}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/photoionization/n2\PYGZus{}multiorb?ref=dev
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2Data/n2\PYGZus{}1pu\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2Data/n2\PYGZus{}3sg\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out already exists
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Import data with PEMtk class}
\PYG{c+c1}{\PYGZsh{} For more details on ePSproc usage see }
\PYG{c+c1}{\PYGZsh{} https://epsproc.readthedocs.io/en/dev/demos/ePSproc\PYGZus{}class\PYGZus{}demo\PYGZus{}161020.html}

\PYG{c+c1}{\PYGZsh{} Instantiate class object.}
\PYG{c+c1}{\PYGZsh{} Minimally this needs just the dataPath, if verbose = 1 is set }
\PYG{c+c1}{\PYGZsh{} then some useful output will also be printed.}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pemtkFit}\PYG{p}{(}\PYG{n}{fileBase}\PYG{o}{=}\PYG{n}{dataPath}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} ScanFiles() \PYGZhy{} this will look for data files on the path provided, and read from them.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{scanFiles}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Job subset details
Key: subset
No \PYGZsq{}job\PYGZsq{} info set for self.data[subset].

*** Job orb6 details
Key: orb6
Dir /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2Data, 1 file(s).
\PYGZob{}   \PYGZsq{}batch\PYGZsq{}: \PYGZsq{}ePS n2, batch n2\PYGZus{}1pu\PYGZus{}0.1\PYGZhy{}50.1eV, orbital A2\PYGZsq{},
    \PYGZsq{}event\PYGZsq{}: \PYGZsq{} N2 A\PYGZhy{}state (1piu\PYGZhy{}1)\PYGZsq{},
    \PYGZsq{}orbE\PYGZsq{}: \PYGZhy{}17.09691397835426,
    \PYGZsq{}orbLabel\PYGZsq{}: \PYGZsq{}1piu\PYGZhy{}1\PYGZsq{}\PYGZcb{}

*** Job orb5 details
Key: orb5
Dir /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2Data, 1 file(s).
\PYGZob{}   \PYGZsq{}batch\PYGZsq{}: \PYGZsq{}ePS n2, batch n2\PYGZus{}3sg\PYGZus{}0.1\PYGZhy{}50.1eV, orbital A2\PYGZsq{},
    \PYGZsq{}event\PYGZsq{}: \PYGZsq{} N2 X\PYGZhy{}state (3sg\PYGZhy{}1)\PYGZsq{},
    \PYGZsq{}orbE\PYGZsq{}: \PYGZhy{}17.34181645456815,
    \PYGZsq{}orbLabel\PYGZsq{}: \PYGZsq{}3sg\PYGZhy{}1\PYGZsq{}\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Format and display results from previous cell (hidden in some formats)}
\PYG{n}{display\PYGZus{}html}\PYG{p}{(}\PYG{n}{df1\PYGZus{}styler}\PYG{o}{.}\PYG{n}{\PYGZus{}repr\PYGZus{}html\PYGZus{}}\PYG{p}{(}\PYG{p}{)}\PYG{o}{+}\PYG{n}{df2\PYGZus{}styler}\PYG{o}{.}\PYG{n}{\PYGZus{}repr\PYGZus{}html\PYGZus{}}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{raw}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Here (\(\Sigma_u\) case) the basis sets are identical, aside from the difference in \(l_{max}\).

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Here (\(\Pi_u\) case) the symmetry\sphinxhyphen{}defined basis has two degenerate continua, \sphinxcode{\sphinxupquote{it=0,1}}, with a phase rotation applied between them. For \sphinxcode{\sphinxupquote{it=0}} the \(\pm m\) terms are anti\sphinxhyphen{}phase, whilst for \sphinxcode{\sphinxupquote{it=1}} they are in\sphinxhyphen{}phase (all negative). For the ePS basis, only the anti\sphinxhyphen{}phase component is present, and is further reduced to terms with \(m\) and \(mu\) of opposite sign. These differences are due to additional restrictions imposed by angular momentum selection rules, which are not included in the symmetry\sphinxhyphen{}defined case.

\sphinxAtStartPar
In general, the current mappings should be suitable for simulation and reconstruction, but care should be taken to:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Confirm symmetry and angular momentum relations for a given case.

\item {} 
\sphinxAtStartPar
Apply additional transformations if comparison with computational results is required.

\item {} 
\sphinxAtStartPar
Add degeneracy factors if required (otherwise these will be subsumed into matrix element values).

\end{enumerate}

\sphinxstepscope


\chapter{General fit setup and numerics}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:general-fit-setup-and-numerics}}\label{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}\label{\detokenize{part2/basic_fitting_numerics_intro_260723::doc}}
\sphinxAtStartPar
For the case studies in \hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{Chapter \ref{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}} \sphinxhyphen{} \hyperref[\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}]{\ref{\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}}}, the same basic setup and fitting routine is used in all cases, and this is outlined below. In general, this requires the steps outlined in \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}} and, for the case studies, configuration additionally requires \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]} \sphinxstyleemphasis{ab initio} {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, and {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}, in order to define test datasets (\hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-afblm}]{Sect.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-afblm}}}). The \(N_2\) case study is use as an example in this case, and \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-fitting}]{Sect.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-fitting}}} illustrates both setting test data, and running fits. Additionally, for the case studies herein, the setup routines are wrapped in a basic script, with configuration options for each case included, this is illustrated in \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-demo-script}]{Sect.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-demo-script}}}.

\sphinxAtStartPar
For the case studies, all the sample data is available from the \sphinxhref{https://github.com/phockett/ePSproc}{ePSproc} {[}\hyperlink{cite.backmatter/bibliography:id608}{34}{]} Github repo, and the examples below include steps for pulling the required data files. Note that further \sphinxhref{https://epolyscat.droppages.com/}{ePolyScat (ePS)} {[}\hyperlink{cite.backmatter/bibliography:id764}{36}, \hyperlink{cite.backmatter/bibliography:id628}{37}, \hyperlink{cite.backmatter/bibliography:id805}{38}, \hyperlink{cite.backmatter/bibliography:id767}{39}{]} datasets are available from \sphinxhref{https://github.com/phockett/ePSdata/}{ePSdata} {[}\hyperlink{cite.backmatter/bibliography:id679}{48}{]}, and \sphinxhref{https://epsproc.readthedocs.io/en/dev/demos/ePSdata\_download\_demo\_300720.html}{data can be pulled using the python ePSdata interface}.


\section{Init and pulling data}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:init-and-pulling-data}}
\sphinxAtStartPar
Here the setup is mainly handled by some basic scripts, these follow the outline in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, see in particular \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_basic\_demo\_030621-full\_010922.html}{the intro to fitting}.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Pull data files as required from Github, note the path here is required}

\PYG{c+c1}{\PYGZsh{} *** Method using epsproc.util.io.getFilesFromGithub}
\PYG{c+c1}{\PYGZsh{} For pulling data from Github, a utility function is available}
\PYG{c+c1}{\PYGZsh{} This requires the repo subpath, and optionally branch}
\PYG{c+c1}{\PYGZsh{} The function will pull all files found in the repo path}
\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{util}\PYG{n+nn}{.}\PYG{n+nn}{io} \PYG{k+kn}{import} \PYG{n}{getFilesFromGithub}

\PYG{c+c1}{\PYGZsh{} Set dataName (will be used as download subdir)}
\PYG{n}{dataName} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2fitting}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} N2 matrix elements}
\PYG{n}{fDictMatE}\PYG{p}{,} \PYG{n}{fAllMatE} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/photoionization/n2\PYGZus{}multiorb}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{)}  
\PYG{c+c1}{\PYGZsh{} N2 alignment data}
\PYG{n}{fDictADM}\PYG{p}{,} \PYG{n}{fAllMatADM} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/alignment}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} *** Alternative method: supply URLs directly for file downloader}
\PYG{c+c1}{\PYGZsh{} E.g. Pull N2 data from ePSproc Github repo}

\PYG{c+c1}{\PYGZsh{} URLs for test ePSproc datasets \PYGZhy{} n2}
\PYG{c+c1}{\PYGZsh{} For more datasets use ePSdata, see https://epsproc.readthedocs.io/en/dev/demos/ePSdata\PYGZus{}download\PYGZus{}demo\PYGZus{}300720.html}
\PYG{n}{urls} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2PU}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://github.com/phockett/ePSproc/blob/master/data/photoionization/n2\PYGZus{}multiorb/n2\PYGZus{}1pu\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2SU}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://github.com/phockett/ePSproc/blob/master/data/photoionization/n2\PYGZus{}multiorb/n2\PYGZus{}3sg\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2ADMs}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://github.com/phockett/ePSproc/blob/master/data/alignment/N2\PYGZus{}ADM\PYGZus{}VM\PYGZus{}290816.mat}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{demoScript}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://github.com/phockett/PEMtk/blob/master/demos/fitting/setup\PYGZus{}fit\PYGZus{}demo.py}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}

\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{util}\PYG{n+nn}{.}\PYG{n+nn}{io} \PYG{k+kn}{import} \PYG{n}{getFilesFromURLs}
\PYG{n}{fList}\PYG{p}{,} \PYG{n}{fDict} \PYG{o}{=} \PYG{n}{getFilesFromURLs}\PYG{p}{(}\PYG{n}{urls}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/photoionization/n2\PYGZus{}multiorb
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/n2\PYGZus{}1pu\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/n2\PYGZus{}3sg\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out already exists
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/alignment
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}ADM\PYGZus{}VM\PYGZus{}290816.mat already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/n2\PYGZus{}1pu\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/n2\PYGZus{}3sg\PYGZus{}0.1\PYGZhy{}50.1eV\PYGZus{}A2.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}ADM\PYGZus{}VM\PYGZus{}290816.mat already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/setup\PYGZus{}fit\PYGZus{}demo.py already exists
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Setup with options}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:setup-with-options}}
\sphinxAtStartPar
Following the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, the fitting workspace can be configured by setting:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
A fitting basis set, either from computational matrix elements, from symmetry constraints, or manually. (See \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}} for more discussion.)

\item {} 
\sphinxAtStartPar
Data to fit. In the examples herein synthetic data will be created by adding noise to computational results.

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} to use for the fit. Again these may be from computational results, or set manually. If not specified these will default to an isotropic distribution, which may be appropriate in some cases.

\end{enumerate}

\sphinxAtStartPar
In the following subsections each aspect of the configuration is illustrated.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Initiation \PYGZhy{} a PEMtk fitting class object}

\PYG{c+c1}{\PYGZsh{} Set data dir}
\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{Path}\PYG{o}{.}\PYG{n}{cwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dataName}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Init class object}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pemtkFit}\PYG{p}{(}\PYG{n}{fileBase} \PYG{o}{=} \PYG{n}{dataPath}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Read data files}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{scanFiles}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Job subset details
Key: subset
No \PYGZsq{}job\PYGZsq{} info set for self.data[subset].

*** Job orb6 details
Key: orb6
Dir /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting, 1 file(s).
\PYGZob{}   \PYGZsq{}batch\PYGZsq{}: \PYGZsq{}ePS n2, batch n2\PYGZus{}1pu\PYGZus{}0.1\PYGZhy{}50.1eV, orbital A2\PYGZsq{},
    \PYGZsq{}event\PYGZsq{}: \PYGZsq{} N2 A\PYGZhy{}state (1piu\PYGZhy{}1)\PYGZsq{},
    \PYGZsq{}orbE\PYGZsq{}: \PYGZhy{}17.09691397835426,
    \PYGZsq{}orbLabel\PYGZsq{}: \PYGZsq{}1piu\PYGZhy{}1\PYGZsq{}\PYGZcb{}

*** Job orb5 details
Key: orb5
Dir /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting, 1 file(s).
\PYGZob{}   \PYGZsq{}batch\PYGZsq{}: \PYGZsq{}ePS n2, batch n2\PYGZus{}3sg\PYGZus{}0.1\PYGZhy{}50.1eV, orbital A2\PYGZsq{},
    \PYGZsq{}event\PYGZsq{}: \PYGZsq{} N2 X\PYGZhy{}state (3sg\PYGZhy{}1)\PYGZsq{},
    \PYGZsq{}orbE\PYGZsq{}: \PYGZhy{}17.34181645456815,
    \PYGZsq{}orbLabel\PYGZsq{}: \PYGZsq{}3sg\PYGZhy{}1\PYGZsq{}\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Alignment distribution moments (ADMs)}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:alignment-distribution-moments-adms}}
\sphinxAtStartPar
The class \sphinxhref{https://epsproc.readthedocs.io/en/dev/modules/epsproc.sphCalc.html\#epsproc.sphCalc.setADMs}{wraps ep.setADMs()} to set {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} to the class data structure. This returns an isotropic distribution by default, or values can be set explicitly from a list. Note: if this is not set, the default value will be used, which is likely not very useful for the fit!

\sphinxAtStartPar
Values are set in \sphinxcode{\sphinxupquote{self.data{[}'ADM'{]}}}, see \hyperref[\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}]{Sect.\@ \ref{\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}}} for more details on {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} and molecular alignment. For the \(N_2\) example case, the alignment data is as per the original experimental demonstration of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]}, and also \sphinxhref{https://doi.org/10.6084/m9.figshare.4480349}{available from the associated data repository} {[}\hyperlink{cite.backmatter/bibliography:id673}{143}{]}.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Default case \PYGZhy{} isotropic}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setADMs}\PYG{p}{(}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} data.ADM[\PYGZsq{}ADMX\PYGZsq{}]}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}xarray.DataArray \PYGZsq{}ADM\PYGZsq{} (ADM: 1, t: 1)\PYGZgt{}
array([[1]])
Coordinates:
  * ADM      (ADM) MultiIndex
  \PYGZhy{} K        (ADM) int64 0
  \PYGZhy{} Q        (ADM) int64 0
  \PYGZhy{} S        (ADM) int64 0
  * t        (t) int64 0
Attributes:
    dataType:   ADM
    long\PYGZus{}name:  Axis distribution moments
    units:      arb
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Full tabulations of the parameters, and some plots, available in HTML or notebook formats only.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Load time\PYGZhy{}dependent ADMs for N2 case}
\PYG{c+c1}{\PYGZsh{} These are in a Matlab/HDF5 file format}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{io} \PYG{k+kn}{import} \PYG{n}{loadmat}
\PYG{n}{ADMdataFile} \PYG{o}{=} \PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{dataPath}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{N2\PYGZus{}ADM\PYGZus{}VM\PYGZus{}290816.mat}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ADMs} \PYG{o}{=} \PYG{n}{loadmat}\PYG{p}{(}\PYG{n}{ADMdataFile}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set tOffset for calcs, 3.76ps!!!}
\PYG{c+c1}{\PYGZsh{} This is because this is 2\PYGZhy{}pulse case, and will set t=0 to 2nd pulse }
\PYG{c+c1}{\PYGZsh{} (and matches defn. in N2 experimental paper)}
\PYG{c+c1}{\PYGZsh{} Marceau, C. et al. (2017) ‘Molecular Frame Reconstruction Using Time\PYGZhy{}Domain Photoionization Interferometry’, Physical Review Letters, 119(8), p. 083401. Available at: https://doi.org/10.1103/PhysRevLett.119.083401.}
\PYG{n}{tOffset} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.76}
\PYG{n}{ADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{time}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{ADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{time}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{+} \PYG{n}{tOffset}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{setADMs}\PYG{p}{(}\PYG{n}{ADMs} \PYG{o}{=} \PYG{n}{ADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{t}\PYG{o}{=}\PYG{n}{ADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{time}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{KQSLabels} \PYG{o}{=} \PYG{n}{ADMs}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADMlist}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{addS} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}xarray.DataArray \PYGZsq{}ADM\PYGZsq{} (ADM: 4, t: 3691)\PYGZgt{}
array([[ 1.00000000e+00+0.00000000e+00j,  1.00000000e+00+0.00000000e+00j,
         1.00000000e+00+0.00000000e+00j, ...,
         1.00000000e+00+0.00000000e+00j,  1.00000000e+00+0.00000000e+00j,
         1.00000000e+00+0.00000000e+00j],
       [\PYGZhy{}2.26243113e\PYGZhy{}17+0.00000000e+00j,  2.43430608e\PYGZhy{}08+1.04125246e\PYGZhy{}20j,
         9.80188266e\PYGZhy{}08+6.89166168e\PYGZhy{}20j, ...,
         1.05433798e\PYGZhy{}01\PYGZhy{}1.62495135e\PYGZhy{}18j,  1.05433798e\PYGZhy{}01\PYGZhy{}1.62495135e\PYGZhy{}18j,
         1.05433798e\PYGZhy{}01\PYGZhy{}1.62495135e\PYGZhy{}18j],
       [ 1.55724057e\PYGZhy{}16+0.00000000e+00j, \PYGZhy{}3.37021111e\PYGZhy{}10\PYGZhy{}6.81416260e\PYGZhy{}20j,
         1.95424253e\PYGZhy{}10\PYGZhy{}3.10513374e\PYGZhy{}19j, ...,
         8.39913132e\PYGZhy{}02\PYGZhy{}5.12795441e\PYGZhy{}17j,  8.39913132e\PYGZhy{}02\PYGZhy{}5.12795441e\PYGZhy{}17j,
         8.39913132e\PYGZhy{}02\PYGZhy{}5.12795441e\PYGZhy{}17j],
       [\PYGZhy{}7.68430227e\PYGZhy{}16+0.00000000e+00j, \PYGZhy{}1.40177466e\PYGZhy{}11+1.04987400e\PYGZhy{}19j,
         6.33419102e\PYGZhy{}10+1.74747003e\PYGZhy{}18j, ...,
         3.78131657e\PYGZhy{}02+4.01318983e\PYGZhy{}16j,  3.78131657e\PYGZhy{}02+4.01318983e\PYGZhy{}16j,
         3.78131657e\PYGZhy{}02+4.01318983e\PYGZhy{}16j]])
Coordinates:
  * ADM      (ADM) MultiIndex
  \PYGZhy{} K        (ADM) int64 0 2 4 6
  \PYGZhy{} Q        (ADM) int64 0 0 0 0
  \PYGZhy{} S        (ADM) int64 0 0 0 0
  * t        (t) float64 \PYGZhy{}3.76 \PYGZhy{}3.76 \PYGZhy{}3.76 \PYGZhy{}3.759 \PYGZhy{}3.759 ... 10.1 10.1 10.1 10.1
Attributes:
    dataType:   ADM
    long\PYGZus{}name:  Axis distribution moments
    units:      arb
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Manual plot with hvplot for full control and interactive plot}
\PYG{c+c1}{\PYGZsh{} NOTE: HTML version only.}
\PYG{n}{key} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{dataType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{p}{[}\PYG{n}{dataType}\PYG{p}{]}\PYG{o}{.}\PYG{n}{unstack}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{real}\PYG{o}{.}\PYG{n}{hvplot}\PYG{o}{.}\PYG{n}{line}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{overlay}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{K}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Q}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{S}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
:NdOverlay   [S,Q,K]
   :Curve   [t]   (ADM)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} A basic self.ADMplot routine is also available}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{n}{data}\PYG{o}{.}\PYG{n}{ADMplot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset: ADM, ADM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{136fe3775cf95b44481b9e6bb839774734836188c3963b170c45c37f55cb896d}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Polarisation geometry/ies}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:polarisation-geometry-ies}}
\sphinxAtStartPar
This wraps \sphinxhref{https://epsproc.readthedocs.io/en/dev/modules/epsproc.sphCalc.html\#epsproc.sphCalc.setPolGeoms}{ep.setPolGeoms}. This defaults to (x,y,z) polarization geometries. Values are set in \sphinxcode{\sphinxupquote{self.data{[}'pol'{]}}}.

\sphinxAtStartPar
Note: if this is not set, the default value will be used, which is likely not very useful for the fit!

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setPolGeoms}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pol}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pol}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}xarray.DataArray (Labels: 3)\PYGZgt{}
array([quaternion(1, \PYGZhy{}0, 0, 0),
       quaternion(0.707106781186548, \PYGZhy{}0, 0.707106781186547, 0),
       quaternion(0.5, \PYGZhy{}0.5, 0.5, 0.5)], dtype=quaternion)
Coordinates:
    Euler    (Labels) object (0.0, 0.0, 0.0) ... (1.5707963267948966, 1.57079...
  * Labels   (Labels) \PYGZlt{}U32 \PYGZsq{}z\PYGZsq{} \PYGZsq{}x\PYGZsq{} \PYGZsq{}y\PYGZsq{}
Attributes:
    dataType:  Euler
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Subselect data}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:subselect-data}}
\sphinxAtStartPar
Currently handled in the class by setting \sphinxcode{\sphinxupquote{self.selOpts}}, this allows for simple reuse of settings as required. Subselected data is set to \sphinxcode{\sphinxupquote{self.data{[}'subset'{]}{[}dataType{]}}} by default (equivalently \sphinxcode{\sphinxupquote{self.data{[}self.subKey{]}{[}dataType{]}}}), and is the data the fitting routine will use.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Settings for type subselection are in selOpts[dataType]}

\PYG{c+c1}{\PYGZsh{} E.g. Matrix element sub\PYGZhy{}selection}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{selOpts}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{thres}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.01}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{inds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{L}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Eke}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{l+m+mf}{1.1}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{orb5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Subselect from \PYGZsq{}orb5\PYGZsq{} dataset, matrix elements}

\PYG{c+c1}{\PYGZsh{} And for the polarisation geometries...}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{selOpts}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pol}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{inds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Labels}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{z}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pol}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pol}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} And for the ADMs...}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{selOpts}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}   \PYG{c+c1}{\PYGZsh{}\PYGZob{}\PYGZsq{}thres\PYGZsq{}: 0.01, \PYGZsq{}inds\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}:\PYGZsq{}L\PYGZsq{}, \PYGZsq{}Eke\PYGZsq{}:1.1\PYGZcb{}\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{n}{dataKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{sliceParams} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{)} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Subselected from dataset \PYGZsq{}orb5\PYGZsq{}, dataType \PYGZsq{}matE\PYGZsq{}: 36 from 11016 points (0.33\PYGZpc{})
Subselected from dataset \PYGZsq{}pol\PYGZsq{}, dataType \PYGZsq{}pol\PYGZsq{}: 1 from 3 points (33.33\PYGZpc{})
Subselected from dataset \PYGZsq{}ADM\PYGZsq{}, dataType \PYGZsq{}ADM\PYGZsq{}: 52 from 14764 points (0.35\PYGZpc{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Note that the class uses data.subKey to reference the correct data internally}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Data dict key: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{data}\PYG{o}{.}\PYG{n}{subKey}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Data dict contents: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{data}\PYG{o}{.}\PYG{n}{subKey}\PYG{p}{]}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Data dict key: subset
Data dict contents: dict\PYGZus{}keys([\PYGZsq{}matE\PYGZsq{}, \PYGZsq{}pol\PYGZsq{}, \PYGZsq{}ADM\PYGZsq{}])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check subselected ADMs by plotting vs. full ADM data}
\PYG{c+c1}{\PYGZsh{} Plot from Xarray vs. full dataset}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{real}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{plot}\PYG{o}{.}\PYG{n}{line}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{marker} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dashed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{real}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{plot}\PYG{o}{.}\PYG{n}{line}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{d7a2e6bd08640ec12fa58dd5e897f2a4aab107b84356d5f61306d9d1545b81ac}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Compute AF\sphinxhyphen{}\protect\(\beta_{LM}\protect\) and simulate data}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:compute-af-beta-lm-and-simulate-data}}\label{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-afblm}}
\sphinxAtStartPar
With all the components set, some observables can be calculated. For testing, this will also be used to simulate an experimental trace (with noise added).

\sphinxAtStartPar
For both basic computation, and fitting, the class method \sphinxcode{\sphinxupquote{self.afblmMatEfit()}} can be used. This essentially wraps the main {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} computational routine, \sphinxcode{\sphinxupquote{epsproc.afblmXprod()}}, to compute AF\sphinxhyphen{}\(\beta_{LM}\)s (for more details, see the \sphinxhref{https://epsproc.readthedocs.io/en/dev/methods/geometric\_method\_dev\_pt3\_AFBLM\_090620\_010920\_dev\_bk100920.html}{ePSproc method development docs} and \sphinxhref{https://epsproc.readthedocs.io/en/dev/modules/epsproc.geomFunc.afblmGeom.html\#epsproc.geomFunc.afblmGeom.afblmXprod}{API docs}).

\sphinxAtStartPar
If called without reference data, the method returns computed AF\sphinxhyphen{}\(\beta_{LM}\)s based on the input subsets already created, and also a set of (product) basis functions generated \sphinxhyphen{} as illustrated in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}}, these can be examined to get a feel for the sensitivity of the geometric part of the problem, and will also be used as a basis in the fitting routine to limit repetitive computations.


\subsection{Compute AF\sphinxhyphen{}\protect\(\beta_{LM}\protect\)s}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:compute-af-beta-lm-s}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Compute with class method}
\PYG{c+c1}{\PYGZsh{} This uses all data as set to self.data[\PYGZsq{}subset\PYGZsq{}]}
\PYG{n}{BetaNormX}\PYG{p}{,} \PYG{n}{basis} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{afblmMatEfit}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}

\subsection{AF\sphinxhyphen{}\protect\(\beta_{LM}\protect\)s}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:af-beta-lm-s}}
\sphinxAtStartPar
The returned objects contain the \(\beta_{LM}\) parameters as an Xarray…

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Line\PYGZhy{}plot with Xarray/Matplotlib}
\PYG{c+c1}{\PYGZsh{} Note there is no filtering here, so this includes some invalid and null terms}
\PYG{n}{BetaNormX}\PYG{o}{.}\PYG{n}{sel}\PYG{p}{(}\PYG{n}{Labels}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{real}\PYG{o}{.}\PYG{n}{squeeze}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{plot}\PYG{o}{.}\PYG{n}{line}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{f5946ab49b65ef5ec508d361685e7531e118a477980b81f2ff714eb3534ebaa0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
… and the basis sets as a dictionary. (See \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}} for more details on the basis sets.)

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{basis}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}BLMtableResort\PYGZsq{}, \PYGZsq{}polProd\PYGZsq{}, \PYGZsq{}phaseConvention\PYGZsq{}, \PYGZsq{}BLMRenorm\PYGZsq{}])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Fitting the data: configuration}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:fitting-the-data-configuration}}\label{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-fitting}}
\sphinxAtStartPar
As discussed in \hyperref[\detokenize{part1/numerics_070723:chpt-numerical-details}]{Chpt.\@ \ref{\detokenize{part1/numerics_070723:chpt-numerical-details}}}, general non\sphinxhyphen{}linear fitting approaches are used for the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}. These are wrapped in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} for {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval problems, as shown below. (And, as discussed in \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}}, make use of the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} and \sphinxhref{https://scipy.org/}{\sphinxcode{\sphinxupquote{Scipy}}} {[}\hyperlink{cite.backmatter/bibliography:id876}{52}{]} base routines.)


\subsection{Set the data to fit}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:set-the-data-to-fit}}
\sphinxAtStartPar
To use the values calculated above as the test data, it currently needs to be set as \sphinxcode{\sphinxupquote{self.data{[}'subset'{]}{[}'AFBLM'{]}}} for fitting.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set computed results to main data structure}

\PYG{c+c1}{\PYGZsh{} Method 1: Set directly by manual assignment}
\PYG{c+c1}{\PYGZsh{} data.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}AFBLM\PYGZsq{}] = BetaNormX  }

\PYG{c+c1}{\PYGZsh{} Method 2: Set to main data structure and subset using methods as above}
\PYG{c+c1}{\PYGZsh{} Set simulated data to master structure as \PYGZdq{}sim\PYGZdq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setData}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{BetaNormX}\PYG{p}{)}  
\PYG{c+c1}{\PYGZsh{} Set to \PYGZsq{}subset\PYGZsq{} to use for fitting.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}   
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Subselected from dataset \PYGZsq{}sim\PYGZsq{}, dataType \PYGZsq{}AFBLM\PYGZsq{}: 52 from 52 points (100.00\PYGZpc{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set basis functions}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{basis} \PYG{o}{=} \PYG{n}{basis}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}

\subsection{Adding noise}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:adding-noise}}
\sphinxAtStartPar
For a more realistic test of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}, noise or other artifacts can be added to the data. Below is a routine for adding random (Gaussian) noise.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Add noise with np.random.normal}
\PYG{c+c1}{\PYGZsh{} https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.05}  \PYG{c+c1}{\PYGZsh{} Up to approx 10\PYGZpc{} noise (+/\PYGZhy{} 0.05)}
\PYG{c+c1}{\PYGZsh{} creating a noise with the same dimension as the dataset (2,2) }
\PYG{n}{noise} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma}\PYG{p}{,} 
                         \PYG{p}{[}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{t}\PYG{o}{.}\PYG{n}{size}\PYG{p}{,} 
                          \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{l}\PYG{o}{.}\PYG{n}{size}\PYG{p}{]}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} data.BLMfitPlot()}

\PYG{c+c1}{\PYGZsh{} Set noise in Xarray \PYGZam{} scale by l}
\PYG{k+kn}{import} \PYG{n+nn}{xarray} \PYG{k}{as} \PYG{n+nn}{xr}
\PYG{n}{noiseXR} \PYG{o}{=} \PYG{n}{xr}\PYG{o}{.}\PYG{n}{ones\PYGZus{}like}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)} \PYG{o}{*} \PYG{n}{noise}
\PYG{c+c1}{\PYGZsh{} Scale by L? This prevents too much high\PYGZhy{}order noise}
\PYG{n}{noiseXR} \PYG{o}{=} \PYG{n}{noiseXR}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{noiseXR}\PYG{o}{.}\PYG{n}{l}\PYG{o}{\PYGZlt{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{noiseXR}\PYG{o}{/}\PYG{p}{(}\PYG{n}{noiseXR}\PYG{o}{.}\PYG{n}{l}\PYG{p}{)}\PYG{p}{)}  
\PYG{c+c1}{\PYGZsh{} Update data for fitting}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{+} \PYG{n}{noiseXR}
\PYG{c+c1}{\PYGZsh{} Remove non\PYGZhy{}zero m terms?}
\PYG{c+c1}{\PYGZsh{} This removes additional noise\PYGZhy{}only channels}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{AFBLM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{m} \PYG{o}{==} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} The BLMfitPlot() routine can be used to plot data and fit outputs}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMfitPlot}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset: subset, AFBLM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{731b9d6f2fe6d06f93feccbfee6a0238e03017c160bed18a6fee1448867b8854}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Setting up the fit parameters}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:setting-up-the-fit-parameters}}
\sphinxAtStartPar
As detailed in \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}}, fitting requires a basis set and fit parameters. In this case, we can work from the existing matrix elements (as used for simulating data above) to speed up parameter creation, although in practice this may need to be approached \sphinxstyleemphasis{ab initio} or via symmetry \sphinxhyphen{} nonetheless, the method will be similar.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Set matrix elements from ab initio results}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setMatEFit}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matE}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
This sets \sphinxcode{\sphinxupquote{self.params}} from the matrix elements, which are a set of (real) parameters for lmfit, as \sphinxhref{https://lmfit.github.io/lmfit-py/parameters.html}{a Parameters object}.

\sphinxAtStartPar
Note that:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The input matrix elements are converted to magnitude\sphinxhyphen{}phase form, hence there are twice the number as the input array, and labelled \sphinxcode{\sphinxupquote{m}} or \sphinxcode{\sphinxupquote{p}} accordingly, along with a name based on the full set of QNs/indexes set.

\item {} 
\sphinxAtStartPar
One phase is set to \sphinxcode{\sphinxupquote{vary=False}}, which defines a reference phase. This defaults to the first phase item.

\item {} 
\sphinxAtStartPar
Min and max values are defined, by default the ranges are \(1e^{-4}<\)mag\(<5\), \(-\pi<\)phase\(<\pi\).

\item {} 
\sphinxAtStartPar
Relationships between the parameters are set by default, but can be set manually, or pass \sphinxcode{\sphinxupquote{paramsCons=None}} to skip.

\end{itemize}

\sphinxAtStartPar
For further details, including modification of parameter settings, see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-fittingparams}]{Sect.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sec-basis-sets-remapping-to-fittingparams}}} and the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.


\subsection{Quick setup with script}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:quick-setup-with-script}}\label{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-demo-script}}
\sphinxAtStartPar
The steps demonstrated above are also wrapped in a helper script, although some steps may need to be re\sphinxhyphen{}run to change selection properties or ranges. For the case studies, there are specific details for each configured in the script, including source data locations and the selection criteria as used in each demonstration.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run general config script with dataPath set above}
\PYG{o}{\PYGZpc{}}\PYG{k}{run} \PYGZob{}dataPath/\PYGZdq{}setup\PYGZus{}fit\PYGZus{}demo.py\PYGZdq{}\PYGZcb{} \PYGZhy{}d \PYGZob{}dataPath\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Fitting the data: Running fits}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:fitting-the-data-running-fits}}\label{\detokenize{part2/basic_fitting_numerics_intro_260723:sec-basic-fitting-running-fits}}

\subsection{Single fit}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:single-fit}}
\sphinxAtStartPar
With the parameters and data set, just call \sphinxcode{\sphinxupquote{self.fit()}}! For more control, options to the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]} \sphinxhref{https://lmfit.github.io/lmfit-py/fitting.html}{minimizer function} can be set. Statistics and outputs are also handled by the \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{\sphinxcode{\sphinxupquote{lmfit}} library} {[}\hyperlink{cite.backmatter/bibliography:id758}{66}, \hyperlink{cite.backmatter/bibliography:id806}{67}{]}, which includes uncertainty estimates and correlations in the fitted parameters.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run a fit}
\PYG{c+c1}{\PYGZsh{} data.randomizeParams()  \PYGZsh{} Randomize input parameters if desired}
                          \PYG{c+c1}{\PYGZsh{} For method testing using known initial params is also useful}

\PYG{c+c1}{\PYGZsh{} Run fit with defaults settings}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Additional keyword options can be pass, these are passed to the fitting routine.}
\PYG{c+c1}{\PYGZsh{} Args are passed to the lmfit minimizer, see https://lmfit.github.io/lmfit\PYGZhy{}py/fitting.html}
\PYG{c+c1}{\PYGZsh{} E.g. for scipy Least Squares, options can be found at}
\PYG{c+c1}{\PYGZsh{} https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least\PYGZus{}squares.html\PYGZsh{}scipy.optimize.least\PYGZus{}squares}
\PYG{c+c1}{\PYGZsh{} For example, pass convergence tolerances}
\PYG{c+c1}{\PYGZsh{} data.fit(ftol=1e\PYGZhy{}10, xtol=1e\PYGZhy{}10)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check fit outputs \PYGZhy{} self.result shows results from the last fit}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{result}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fit data is also set to the master data structure with an integer key}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}subset\PYGZsq{}, \PYGZsq{}orb6\PYGZsq{}, \PYGZsq{}orb5\PYGZsq{}, \PYGZsq{}ADM\PYGZsq{}, \PYGZsq{}pol\PYGZsq{}, \PYGZsq{}sim\PYGZsq{}, 0])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot results with data overlay}
\PYG{c+c1}{\PYGZsh{} data.BLMfitPlot(backend=\PYGZsq{}hv\PYGZsq{})   \PYGZsh{} Set backend=\PYGZsq{}hv\PYGZsq{} for interactive plots}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMfitPlot}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset: subset, AFBLM
Dataset: 0, AFBLM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{2f50806e785381a4a8af09df066ba2a57b0a678fb9d9d1d0e081e601db90fe1f}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Extended execution methods, including parallel and batched execution}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:extended-execution-methods-including-parallel-and-batched-execution}}
\sphinxAtStartPar
See the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for details, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_demo\_multi-fit\_tests\_130621-para\_010922.html}{batch runs demo page}.

\sphinxAtStartPar
\sphinxstylestrong{(1) serial execution}

\sphinxAtStartPar
Either:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Manually with a loop.

\item {} 
\sphinxAtStartPar
With \sphinxcode{\sphinxupquote{self.multiFit()}} method, although this is optimised for parallel execution (see below).

\end{itemize}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Basic serial example with a loop}
\PYG{k+kn}{import} \PYG{n+nn}{time}

\PYG{n}{start} \PYG{o}{=} \PYG{n}{time}\PYG{o}{.}\PYG{n}{time}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Maual execution}
\PYG{k}{for} \PYG{n}{n} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{randomizeParams}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{)}
    
\PYG{n}{end} \PYG{o}{=} \PYG{n}{time}\PYG{o}{.}\PYG{n}{time}\PYG{p}{(}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{p}{(}\PYG{n}{end} \PYG{o}{\PYGZhy{}} \PYG{n}{start}\PYG{p}{)}\PYG{o}{/}\PYG{l+m+mi}{60}\PYG{p}{)}
    
\PYG{c+c1}{\PYGZsh{} Or run with self.multiFit(parallel = False)}
\PYG{c+c1}{\PYGZsh{} data.multiFit(nRange = [0,10], parallel = False)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
1.6530285994211833
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} There are now 10 more fit results}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}subset\PYGZsq{}, \PYGZsq{}orb6\PYGZsq{}, \PYGZsq{}orb5\PYGZsq{}, \PYGZsq{}ADM\PYGZsq{}, \PYGZsq{}pol\PYGZsq{}, \PYGZsq{}sim\PYGZsq{}, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
\sphinxstylestrong{(b) parallel execution}

\sphinxAtStartPar
A basic parallel fitting routine is implemented via the \sphinxcode{\sphinxupquote{self.multiFit()}} method. This currently uses the \sphinxhref{https://xyzpy.readthedocs.io/en/latest/}{\sphinxcode{\sphinxupquote{xyzpy}} library} {[}\hyperlink{cite.backmatter/bibliography:id976}{68}{]} for quick parallelization, although there is some additional setup overhead in the currently implementation due to class init per fit batch. The default settings aims to set \textasciitilde{}90\% CPU usage, based on core\sphinxhyphen{}count.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Multifit wrapper with range of fits specified}
\PYG{c+c1}{\PYGZsh{} Set \PYGZsq{}num\PYGZus{}workers\PYGZsq{} to override the default (\PYGZti{}90\PYGZpc{} of available cores).}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{multiFit}\PYG{p}{(}\PYG{n}{nRange} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,} \PYG{n}{num\PYGZus{}workers}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
\sphinxstylestrong{(c) Dump data}

\sphinxAtStartPar
Various options are available. The most complete is to use Pickle (default case), which dumps the entire \sphinxcode{\sphinxupquote{self.data}} structure to file, although this is not suggested for archival use. For details see the \sphinxhref{https://epsproc.readthedocs.io}{ePSproc documentation} {[}\hyperlink{cite.backmatter/bibliography:id606}{35}{]}, particularly the \sphinxhref{https://epsproc.readthedocs.io/en/dev/dataStructures/ePSproc\_dataStructures\_demo\_070622.html}{data structures demo page}. For some data types HDF5 routines are available, and are demonstrated for post\sphinxhyphen{}processed fit data in the case studies (\hyperref[\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}]{Chapt.\@ \ref{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}} \sphinxhyphen{} \hyperref[\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}]{Chapt.\@ \ref{\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}}}).

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{outStem} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dataDump\PYGZus{}N2}\PYG{l+s+s1}{\PYGZsq{}}  \PYG{c+c1}{\PYGZsh{} Set for file save later}
\PYG{c+c1}{\PYGZsh{} Minimal case \PYGZhy{} timestamped filename}
\PYG{c+c1}{\PYGZsh{} data.writeFitData()}

\PYG{c+c1}{\PYGZsh{} Use \PYGZsq{}fName\PYGZsq{} to supply a filename}
\PYG{c+c1}{\PYGZsh{} data.writeFitData(fName=\PYGZsq{}N2\PYGZus{}datadump\PYGZsq{})}

\PYG{c+c1}{\PYGZsh{} Use \PYGZsq{}outStem\PYGZsq{} to define a filename which will be appended with a timestamp}
\PYG{c+c1}{\PYGZsh{} Set dataPath if desired, otherwise will use working dir}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{writeFitData}\PYG{p}{(}\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{dataPath}\PYG{p}{,} \PYG{n}{outStem}\PYG{o}{=}\PYG{n}{outStem}\PYG{p}{)}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
PosixPath(\PYGZsq{}/home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/dataDump\PYGZus{}N2\PYGZus{}261023\PYGZus{}06\PYGZhy{}08\PYGZhy{}04.pickle\PYGZsq{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Batch fit with sampling options}
\label{\detokenize{part2/basic_fitting_numerics_intro_260723:batch-fit-with-sampling-options}}
\sphinxAtStartPar
From the basic methods above, more sophisticated fitting strategies can be built. For example, the cell below implements batched fitting with Poission sampling of the data (for statistical bootstrapping).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Batch fit with data weighting example}
\PYG{n}{batchSize} \PYG{o}{=} \PYG{l+m+mi}{50}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{weights}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}  \PYG{c+c1}{\PYGZsh{} Use to log ref weights, will be overwritten otherwise}

\PYG{k}{for} \PYG{n}{n} \PYG{o+ow}{in} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{100}\PYG{p}{,}\PYG{n}{batchSize}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Running batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Reset weights}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{setWeights}\PYG{p}{(}\PYG{n}{wConfig} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{poission}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{keyExpt}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{setSubset}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{weights}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Set to \PYGZsq{}subset\PYGZsq{} to use for fitting.}

    \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{weights}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{n}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{weights}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{copy}\PYG{p}{(}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} Run fit batch}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{multiFit}\PYG{p}{(}\PYG{n}{nRange} \PYG{o}{=} \PYG{p}{[}\PYG{n}{n}\PYG{p}{,}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{num\PYGZus{}workers}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} Checkpoint \PYGZhy{} dump data to file}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{writeFitData}\PYG{p}{(}\PYG{n}{outStem}\PYG{o}{=}\PYG{n}{outStem}\PYG{p}{)}
    
\end{sphinxVerbatim}

\sphinxstepscope


\chapter{Case study: Generalised bootstrapping for a homonuclear diatomic scattering system, \protect\(N_2~(D_{\infty h})\protect\)}
\label{\detokenize{part2/case-study-N2_290723:case-study-generalised-bootstrapping-for-a-homonuclear-diatomic-scattering-system-n-2-d-infty-h}}\label{\detokenize{part2/case-study-N2_290723:chpt-n2-case-study}}\label{\detokenize{part2/case-study-N2_290723::doc}}
\sphinxAtStartPar
In this chapter, the full code and analysis details of the case study for \(N_2\) are given, including obtaining required data, running fits and analysis routines. For more details on the routines, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}; for the analysis see particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_analysis\_demo\_150621-tidy.html}{fit fidelity and analysis page}, and \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html}{molecular frame analysis data processing page} (full analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case).


\section{General setup}
\label{\detokenize{part2/case-study-N2_290723:general-setup}}
\sphinxAtStartPar
In the following code cells (see source notebooks for full details) the general setup routines (as per the outline in \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chpt.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}} are executed via a configuration script with presets for the case studies herein.

\sphinxAtStartPar
Additionally, the routines will either run fits, or load existing data if available. Since fitting can be computationally demanding, it is, in general, recommended to approach large fitting problems carefully.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{General note on fitting}

\sphinxAtStartPar
Computational outputs in this chapter are significantly truncated in the PDF, and some simplified plots are used; see source notebooks (via \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}) or \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)} for full details.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Configure settings for case study}

\PYG{c+c1}{\PYGZsh{} Set case study by name}
\PYG{n}{fitSystem}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{N2}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{fitStem}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{fit\PYGZus{}withNoise\PYGZus{}orb5}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Add noise?}
\PYG{n}{addNoise} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{y}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.05}  \PYG{c+c1}{\PYGZsh{} Up to approx 10\PYGZpc{} noise (+/\PYGZhy{} 0.05)}

\PYG{c+c1}{\PYGZsh{} Batching \PYGZhy{} number of fits to run between data dumps}
\PYG{n}{batchSize} \PYG{o}{=} \PYG{l+m+mi}{10}

\PYG{c+c1}{\PYGZsh{} Total fits to run}
\PYG{n}{nMax} \PYG{o}{=} \PYG{l+m+mi}{10}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Pull data from web (N2 case)}

\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{util}\PYG{n+nn}{.}\PYG{n+nn}{io} \PYG{k+kn}{import} \PYG{n}{getFilesFromGithub}

\PYG{c+c1}{\PYGZsh{} Set dataName (will be used as download subdir)}
\PYG{n}{dataName} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n2fitting}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} N2 matrix elements}
\PYG{n}{fDictMatE}\PYG{p}{,} \PYG{n}{fAllMatE} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/photoionization/n2\PYGZus{}multiorb}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{)}  
\PYG{c+c1}{\PYGZsh{} N2 alignment data}
\PYG{n}{fDictADM}\PYG{p}{,} \PYG{n}{fAllMatADM} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/alignment}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fitting setup including data generation and parameter creation}

\PYG{c+c1}{\PYGZsh{} Set datapath, }
\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{Path}\PYG{o}{.}\PYG{n}{cwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{dataName}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run general config script with dataPath set above}
\PYG{o}{\PYGZpc{}}\PYG{k}{run} \PYGZdq{}../scripts/setup\PYGZus{}fit\PYGZus{}case\PYGZhy{}studies\PYGZus{}270723.py\PYGZdq{} \PYGZhy{}d \PYGZob{}dataPath\PYGZcb{} \PYGZhy{}c \PYGZob{}fitSystem\PYGZcb{} \PYGZhy{}n \PYGZob{}addNoise\PYGZcb{} \PYGZhy{}\PYGZhy{}sigma \PYGZob{}sigma\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Load existing fit data or run fits}
\label{\detokenize{part2/case-study-N2_290723:load-existing-fit-data-or-run-fits}}
\sphinxAtStartPar
Note that running fits may be quite time\sphinxhyphen{}consuming and computationally intensive, depending on the size of the size of the problem. The default case here will run a small batch for testing if there is no existing data found on the \sphinxcode{\sphinxupquote{dataPath}}, otherwise the data is loaded for analysis.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Look for existing Pickle files on path?}
\PYG{c+c1}{\PYGZsh{} dataFiles = list(dataPath.expanduser().glob(\PYGZsq{}*.pickle\PYGZsq{}))}
\PYG{n}{dataFiles} \PYG{o}{=} \PYG{p}{[}\PYG{n}{Path}\PYG{p}{(}\PYG{n}{dataPath}\PYG{o}{.}\PYG{n}{expanduser}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}   \PYG{c+c1}{\PYGZsh{} Set reference dataset(s)}

\PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{dataFiles}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{No data found, executing minimal fitting run...}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} Run fit batch \PYGZhy{} single}
    \PYG{c+c1}{\PYGZsh{} data.multiFit(nRange = [n,n+batchSize\PYGZhy{}1], num\PYGZus{}workers=batchSize)}

    \PYG{c+c1}{\PYGZsh{} Run fit batches with checkpoint files}
    \PYG{k}{for} \PYG{n}{n} \PYG{o+ow}{in} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{nMax}\PYG{p}{,}\PYG{n}{batchSize}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{*** Running batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{], }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{now}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strftime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{m}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{y\PYGZus{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{H\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{M\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{S}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Run fit batch}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{multiFit}\PYG{p}{(}\PYG{n}{nRange} \PYG{o}{=} \PYG{p}{[}\PYG{n}{n}\PYG{p}{,}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{num\PYGZus{}workers}\PYG{o}{=}\PYG{n}{batchSize}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Dump data so far}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{writeFitData}\PYG{p}{(}\PYG{n}{outStem}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitSystem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitStem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Finished batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{], }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{now}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strftime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{m}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{y\PYGZus{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{H\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{M\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{S}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Written to file }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitSystem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitStem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{k}{else}\PYG{p}{:}
    \PYG{n}{dataFileIn} \PYG{o}{=} \PYG{n}{dataFiles}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}   \PYG{c+c1}{\PYGZsh{} Add index to select file, although loadFitData will concat multiple files}
                                    \PYG{c+c1}{\PYGZsh{} Note that concat currently only works for fixed batch sizes however.}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Set dataFiles: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dataFileIn}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{loadFitData}\PYG{p}{(}\PYG{n}{fList}\PYG{o}{=}\PYG{n}{dataFileIn}\PYG{p}{,} \PYG{n}{dataPath}\PYG{o}{=}\PYG{n}{dataPath}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{}.expanduser())}
    
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMfitPlot}\PYG{p}{(}\PYG{n}{keys}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
    
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set dataFiles: /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle
Read data from /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle with pickle.
Dataset: subset, AFBLM
Dataset: sim, AFBLM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{5253c68ed9c5d772ecfea5b3a2474a9ebd60bc82898f5722c903ca7162551d02}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check ADMs}
\PYG{c+c1}{\PYGZsh{} Basic plotter}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{ADMplot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset: subset, ADM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{d896ff576d79aedb00cc3f9c4f77d8aa6dbef051edcd606d2cdf27ce49ab23d3}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fits appear as integer indexed items in the main data structure.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Post\sphinxhyphen{}processing and data overview}
\label{\detokenize{part2/case-study-N2_290723:post-processing-and-data-overview}}
\sphinxAtStartPar
Post\sphinxhyphen{}processing involves aggregation of all the fit run results into a single data structure. This can then be analysed statistically and examined for for best\sphinxhyphen{}fit results. In the statistical sense, this is essentailly a search for candidate {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, based on the assumption that some of the minima found in the \(\chi^2\) hyperspace will be the true results. Even if a clear global minima does not exist, searching for candidate {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} sets based on clustering of results and multiple local minima is still expected to lead to viable candidates provided that the information content of the dataset is sufficient. However, as discussed elsewhere (see \hyperref[\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}}}), in some cases this may not be the case, and other limitations may apply (e.g. certain parameters may be undefined), or additional data required for unique determination of the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}.

\sphinxAtStartPar
For more details on the analysis routines, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_analysis\_demo\_150621-tidy.html}{fit fidelity and analysis page}, and \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html}{molecular frame analysis data processing page} (full analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case).

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} General stats \PYGZam{} post\PYGZhy{}processing to data tables}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{analyseFits}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\PYGZob{} \PYGZsq{}Fits\PYGZsq{}: 1170,
  \PYGZsq{}Minima\PYGZsq{}: \PYGZob{}\PYGZsq{}chisqr\PYGZsq{}: 0.07137430989515783, \PYGZsq{}redchi\PYGZsq{}: 0.000479022214061462\PYGZcb{},
  \PYGZsq{}Stats\PYGZsq{}: \PYGZob{} \PYGZsq{}chisqr\PYGZsq{}: min       0.071
mean      0.084
median    0.071
max       2.594
std       0.089
var       0.008
Name: chisqr, dtype: float64,
             \PYGZsq{}redchi\PYGZsq{}: min       4.790e\PYGZhy{}04
mean      5.652e\PYGZhy{}04
median    4.790e\PYGZhy{}04
max       1.741e\PYGZhy{}02
std       6.002e\PYGZhy{}04
var       3.602e\PYGZhy{}07
Name: redchi, dtype: float64\PYGZcb{},
  \PYGZsq{}Success\PYGZsq{}: 1169\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The BLMsetPlot routine will output aggregate fit results.}
\PYG{c+c1}{\PYGZsh{} Here the spread can be taken as a general indication of the uncertainty of }
\PYG{c+c1}{\PYGZsh{} the fitting, and indicate whether the fit is well\PYGZhy{}characterised/the information }
\PYG{c+c1}{\PYGZsh{} content of the data is sufficient.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMsetPlot}\PYG{p}{(}\PYG{n}{xDim} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}6}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} With xDim and thres set, for more control over outputs}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{N2\PYGZhy{}fitResultsBLM}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMsetPlot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{6fbb7759965ad497ad7ae53fcdfaab530b98542cd31beb20d8a5b89fc3a5426c}.png}
\caption{Fit overview plot \sphinxhyphen{} \(\beta_{L,M}(t)\). Here dashed lines with ‘+’ markers indicates the input data, and bands indicate the mean fit results, where the width is the standard deviation in the fit model results. (See the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for details, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_multiproc\_class\_analysis\_141121-tidy.html\#Fit-set-plotters}{analysis routines page}.)}\label{\detokenize{part2/case-study-N2_290723:fig-n2-fitresultsblm}}\end{figure}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Write aggregate datasets to HDF5 format}
\PYG{c+c1}{\PYGZsh{} This is more robust than Pickled data, but PEMtk currently only support output for aggregate (post\PYGZhy{}processed) fit data.}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{processedToHDF5}\PYG{p}{(}\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{dataPath}\PYG{p}{,} \PYG{n}{outStem} \PYG{o}{=} \PYG{n}{dataFileIn}\PYG{o}{.}\PYG{n}{name}\PYG{p}{,} \PYG{n}{timeStamp}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dumped self.data[fits][dfLong] to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle\PYGZus{}dfLong.pdHDF with Pandas .to\PYGZus{}hdf() routine.
Dumped data to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle\PYGZus{}dfLong.pdHDF with pdHDF.
Dumped self.data[fits][AFxr] to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle\PYGZus{}AFxr.pdHDF with Pandas .to\PYGZus{}hdf() routine.
Dumped data to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/n2fitting/N2\PYGZus{}1199\PYGZus{}fit\PYGZus{}withNoise\PYGZus{}orb5\PYGZus{}280723\PYGZus{}11\PYGZhy{}39\PYGZhy{}26.pickle\PYGZus{}AFxr.pdHDF with pdHDF.
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Histogram fit results (reduced chi\PYGZca{}2 vs. fit index)}
\PYG{c+c1}{\PYGZsh{} This may be quite slow for large datasets, setting limited ranges may help}

\PYG{c+c1}{\PYGZsh{} Use default auto binning}
\PYG{c+c1}{\PYGZsh{} data.fitHist()}

\PYG{c+c1}{\PYGZsh{} Example with range set}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{fitHist}\PYG{p}{(}\PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1.5e\PYGZhy{}3}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{N2\PYGZhy{}fitHist}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fitHistPlot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{30bc0e1b3616e288660a1f43ea7f80b32e544b89185d50e64d353571a26433e7}.png}
\caption{Fit overview plot \sphinxhyphen{} \(\chi^2\) vs. fit index. Here bands indicate groupings (local minima) are consistently found.}\label{\detokenize{part2/case-study-N2_290723:fig-n2-fithist}}\end{figure}

\sphinxAtStartPar
Here, \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-fitresultsblm}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-fitresultsblm}}} shows an overview of the results compared with the input data, and \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-fithist}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-fithist}}} an overview of \(\chi^2\) vs. fit index. Bands in the \(\chi^2\) dimension can indicate groupings (local minima) are consistently found. Assuming each grouping is a viable fit candidate parameter set, these can then be explored in further detail.


\section{Data exploration}
\label{\detokenize{part2/case-study-N2_290723:data-exploration}}
\sphinxAtStartPar
The general aim in this procedure is to ascertain whether there was a good spread of parameters explored, and a single (or few sets) of best\sphinxhyphen{}fit results. There are a few procedures and helper methods for this…


\subsection{View results}
\label{\detokenize{part2/case-study-N2_290723:view-results}}
\sphinxAtStartPar
Single results sets can be viewed in the main data structure, indexed by integers.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check keys}
\PYG{n}{fitNumber} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{fitNumber}\PYG{p}{]}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}AFBLM\PYGZsq{}, \PYGZsq{}residual\PYGZsq{}, \PYGZsq{}results\PYGZsq{}])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Here \sphinxcode{\sphinxupquote{results}} is an \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{lmFit object}, which includes final fit results and information, and \sphinxcode{\sphinxupquote{AFBLM}} contains the model (fit) output (i.e. resultant AF\sphinxhyphen{}\(\beta_{LM}\) values).

\sphinxAtStartPar
An example is shown below. Of particular note here is which parameters have \sphinxcode{\sphinxupquote{vary=True}} \sphinxhyphen{} these are included in the fitting \sphinxhyphen{} and if there is a column \sphinxcode{\sphinxupquote{expression}}, which indicates any parameters defined to have specific relationships (see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}}). Any correlations found during fitting are also shown, which can also indicate parameters which are related (even if this is not predefined or known a priori).

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Show some results}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{fitNumber}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{results}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Classify candidate sets}
\label{\detokenize{part2/case-study-N2_290723:classify-candidate-sets}}
\sphinxAtStartPar
To probe the minima found, the \sphinxcode{\sphinxupquote{classifyFits}} method can be used. This bins results into “candidate” groups, which can then be examined in detail.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run with defaults}
\PYG{c+c1}{\PYGZsh{} data.classifyFits()}

\PYG{c+c1}{\PYGZsh{} For more control, pass bins}
\PYG{c+c1}{\PYGZsh{} Here the minima is set at one end, and a \PYGZpc{}age range used for bins}
\PYG{n}{minVal} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{fitsSummary}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Stats}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{min}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}    
\PYG{n}{binRangePC} \PYG{o}{=} \PYG{l+m+mf}{1e\PYGZhy{}8}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{classifyFits}\PYG{p}{(}\PYG{n}{bins} \PYG{o}{=} \PYG{p}{[}\PYG{n}{minVal}\PYG{p}{,} \PYG{n}{minVal} \PYG{o}{+} \PYG{n}{binRangePC}\PYG{o}{*}\PYG{n}{minVal} \PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllllrrrrrrrr}
\toprule
{} & \multicolumn{4}{l}{success} & \multicolumn{4}{l}{chisqr} & \multicolumn{4}{l}{redchi} \\
{} &   count & unique &   top & freq &  count & unique &    top & freq &  count & unique &        top & freq \\
redchiGroup &         &        &       &      &        &        &        &      &        &        &            &      \\
\midrule
A           &      31 &      1 &  True &   31 &   31.0 &   31.0 &  0.071 &  1.0 &   31.0 &   31.0 &  4.790e-04 &  1.0 \\
B           &      18 &      1 &  True &   18 &   18.0 &   18.0 &  0.071 &  1.0 &   18.0 &   18.0 &  4.790e-04 &  1.0 \\
C           &      25 &      1 &  True &   25 &   25.0 &   25.0 &  0.071 &  1.0 &   25.0 &   25.0 &  4.790e-04 &  1.0 \\
D           &      25 &      1 &  True &   25 &   25.0 &   25.0 &  0.071 &  1.0 &   25.0 &   25.0 &  4.790e-04 &  1.0 \\
E           &      25 &      1 &  True &   25 &   25.0 &   25.0 &  0.071 &  1.0 &   25.0 &   25.0 &  4.790e-04 &  1.0 \\
F           &      21 &      1 &  True &   21 &   21.0 &   21.0 &  0.071 &  1.0 &   21.0 &   21.0 &  4.790e-04 &  1.0 \\
G           &      17 &      1 &  True &   17 &   17.0 &   17.0 &  0.071 &  1.0 &   17.0 &   17.0 &  4.790e-04 &  1.0 \\
H           &      19 &      1 &  True &   19 &   19.0 &   19.0 &  0.071 &  1.0 &   19.0 &   19.0 &  4.790e-04 &  1.0 \\
I           &      27 &      1 &  True &   27 &   27.0 &   27.0 &  0.071 &  1.0 &   27.0 &   27.0 &  4.790e-04 &  1.0 \\
J           &      21 &      1 &  True &   21 &   21.0 &   21.0 &  0.071 &  1.0 &   21.0 &   21.0 &  4.790e-04 &  1.0 \\
K           &      27 &      1 &  True &   27 &   27.0 &   27.0 &  0.071 &  1.0 &   27.0 &   27.0 &  4.790e-04 &  1.0 \\
L           &      22 &      1 &  True &   22 &   22.0 &   22.0 &  0.071 &  1.0 &   22.0 &   22.0 &  4.790e-04 &  1.0 \\
M           &      18 &      1 &  True &   18 &   18.0 &   18.0 &  0.071 &  1.0 &   18.0 &   18.0 &  4.790e-04 &  1.0 \\
N           &      18 &      1 &  True &   18 &   18.0 &   18.0 &  0.071 &  1.0 &   18.0 &   18.0 &  4.790e-04 &  1.0 \\
O           &      22 &      1 &  True &   22 &   22.0 &   22.0 &  0.071 &  1.0 &   22.0 &   22.0 &  4.790e-04 &  1.0 \\
P           &      18 &      1 &  True &   18 &   18.0 &   18.0 &  0.071 &  1.0 &   18.0 &   18.0 &  4.790e-04 &  1.0 \\
Q           &      16 &      1 &  True &   16 &   16.0 &   16.0 &  0.071 &  1.0 &   16.0 &   16.0 &  4.790e-04 &  1.0 \\
R           &      20 &      1 &  True &   20 &   20.0 &   20.0 &  0.071 &  1.0 &   20.0 &   20.0 &  4.790e-04 &  1.0 \\
S           &      23 &      1 &  True &   23 &   23.0 &   23.0 &  0.071 &  1.0 &   23.0 &   23.0 &  4.790e-04 &  1.0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{ac118835318d4c409273a59269c8d65aab3973d0864b41ede148121bb41fb6e7}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Explore candidate result sets}
\label{\detokenize{part2/case-study-N2_290723:explore-candidate-result-sets}}
\sphinxAtStartPar
Drill\sphinxhyphen{}down on a candidate set of results, and examine values and spreads. For more details see \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, especially the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_multiproc\_class\_analysis\_141121-tidy.html}{analysis routines page}. (See also \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}} for details on the plotting libaries implemented here.)


\subsection{Raw results}
\label{\detokenize{part2/case-study-N2_290723:raw-results}}
\sphinxAtStartPar
Plot spreads in magnitude and phase parameters. Statistical plots are available for Seaborn and Holoviews backends, with some slightly different options.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} From the candidates, select a group for analysis}
\PYG{n}{selGroup} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} paramPlot can be used to check the spread on each parameter.}
\PYG{c+c1}{\PYGZsh{} Plots use Seaborn or Holoviews/Bokeh}
\PYG{c+c1}{\PYGZsh{} Colour\PYGZhy{}mapping is controlled by the \PYGZsq{}hue\PYGZsq{} paramter, additionally pass hRound for sig. fig control.}
\PYG{c+c1}{\PYGZsh{} The remap setting allows for short\PYGZhy{}hand labels as set in data.lmmu}

\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Set for (m)agnitude or (p)hase parameters}
\PYG{n}{hRound} \PYG{o}{=} \PYG{l+m+mi}{14} \PYG{c+c1}{\PYGZsh{} Set for cmapping, default may be too small (leads to all grey cmap on points)}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f56041ca7a0\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{56962bc4eec23fdd508869a1fc8ed633ceb3afcc82a5ffb7351a312a20bef255}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Set for (m)agnitude or (p)hase parameters}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f55e4509fc0\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{ae25dc4e7644a9edf227e280716e80d0c28122d2ba4538af5cc56645c86cd05f}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Phases, phase shifts \& corrections}
\label{\detokenize{part2/case-study-N2_290723:phases-phase-shifts-corrections}}
\sphinxAtStartPar
Depending on how the fit was configured, phases may be defined in different ways. To set the phases relative to a speific parameter, and wrap to a specified range, use the \sphinxcode{\sphinxupquote{phaseCorrection()}} method. This defaults to using the first parameter as a reference phase, and wraps to \(-\pi:\pi\). The phase\sphinxhyphen{}corrected values are output to a new Type, ‘pc’, and a set of normalised magnitudes to ‘n’. Additional settings can be passed for more control, as shown below.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run phase correction routine}
\PYG{c+c1}{\PYGZsh{} Set absFlag=True for unsigned phases (mapped to 0:pi)}
\PYG{c+c1}{\PYGZsh{} Set useRef=False to set ref phase as 0, otherwise the reference value is set.}
\PYG{n}{phaseCorrParams}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{absFlag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{k+kc}{True}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{useRef}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{k+kc}{False}\PYG{p}{\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{phaseCorrection}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{phaseCorrParams}\PYG{p}{)}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Examine new data types…

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{kind}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{box}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f561fd53cd0\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{3b3e49e8f1ee8d2e2ed73386614df43aebe86c1f9138de888e5975896703887d}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pc}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{kind}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{box}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f55c46cc520\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{d23c0ca66682f1aef64986f2ac86abe192289a5eadf0385689aba2eb72552f10}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Parameter estimation \& fidelity}
\label{\detokenize{part2/case-study-N2_290723:parameter-estimation-fidelity}}
\sphinxAtStartPar
For case studies, the fit results can be directly compared to the known input parameters. This should give a feel for how well the data defines the matrix elements (parameters) in this case. In general, probing the correlations and spread of results, and comparing to other (unfitted) results is required to estimate fidelity, see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} for further discussion.


\subsection{Best values and statistics}
\label{\detokenize{part2/case-study-N2_290723:best-values-and-statistics}}
\sphinxAtStartPar
To get a final parameter set and associated statistics, based on a subset of the fit results, the \sphinxcode{\sphinxupquote{paramsReport()}} method is available. If reference data is available, as for the case studies herein, the \sphinxcode{\sphinxupquote{paramsCompare()}} method can also be used to compare with the reference case.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Parameter summary}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsReport}\PYG{p}{(}\PYG{n}{inds} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Parameter comparison}
\PYG{c+c1}{\PYGZsh{} Note this uses phaseCorrParams as set previously for consistency}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsCompare}\PYG{p}{(}\PYG{n}{phaseCorrParams}\PYG{o}{=}\PYG{n}{phaseCorrParams}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Display above results With column name remapping to (l,m) labels only}

\PYG{c+c1}{\PYGZsh{} With Pandas functionality}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsSummaryComp}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{n}{columns}\PYG{o}{=}\PYG{n}{data}\PYG{o}{.}\PYG{n}{lmmu}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} With utility method}
\PYG{c+c1}{\PYGZsh{} summaryRenamed = pemtk.fit.\PYGZus{}util.renameParams(data.paramsSummaryComp, data.lmmu[\PYGZsq{}lmMap\PYGZsq{}]) }
\PYG{c+c1}{\PYGZsh{} summaryRenamed}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllrrrrrr}
\toprule
   &          & Param &        1,1 &       1,-1 &        3,1 &       3,-1 &        1,0 &        3,0 \\
Type & Source & dType &            &            &            &            &            &            \\
\midrule
m & mean & num &  1.815e+00 &  1.815e+00 &  8.959e-01 &  8.959e-01 &  2.473e+00 &  1.361e+00 \\
   & ref & num &  1.785e+00 &  1.785e+00 &  8.029e-01 &  8.029e-01 &  2.686e+00 &  1.109e+00 \\
   & diff & \% &  1.662e+00 &  1.662e+00 &  1.038e+01 &  1.038e+01 &  8.617e+00 &  1.851e+01 \\
   &          & num &  3.016e-02 &  3.016e-02 &  9.304e-02 &  9.304e-02 & -2.131e-01 &  2.520e-01 \\
   & std & \% &  1.021e-03 &  1.021e-03 &  4.377e-03 &  4.377e-03 &  2.025e-03 &  6.889e-03 \\
   &          & num &  1.853e-05 &  1.853e-05 &  3.921e-05 &  3.921e-05 &  5.007e-05 &  9.377e-05 \\
   & diff/std & \% &  1.628e+05 &  1.628e+05 &  2.373e+05 &  2.373e+05 &  4.256e+05 &  2.688e+05 \\
n & mean & num &  4.514e-01 &  4.514e-01 &  2.229e-01 &  2.229e-01 &  6.152e-01 &  3.386e-01 \\
   & ref & num &  4.447e-01 &  4.447e-01 &  2.001e-01 &  2.001e-01 &  6.693e-01 &  2.764e-01 \\
   & diff & \% &  1.490e+00 &  1.490e+00 &  1.023e+01 &  1.023e+01 &  8.807e+00 &  1.837e+01 \\
   &          & num &  6.725e-03 &  6.725e-03 &  2.279e-02 &  2.279e-02 & -5.418e-02 &  6.221e-02 \\
   & std & \% &  1.023e-03 &  1.023e-03 &  4.375e-03 &  4.375e-03 &  2.021e-03 &  6.892e-03 \\
   &          & num &  4.618e-06 &  4.618e-06 &  9.750e-06 &  9.750e-06 &  1.243e-05 &  2.334e-05 \\
   & diff/std & \% &  1.456e+05 &  1.456e+05 &  2.338e+05 &  2.338e+05 &  4.357e+05 &  2.666e+05 \\
p & mean & num & -8.610e-01 & -8.610e-01 &  1.230e-01 &  1.230e-01 &  2.025e+00 & -6.796e-01 \\
   & ref & num & -8.610e-01 & -8.610e-01 & -3.120e+00 & -3.120e+00 &  2.611e+00 & -7.868e-02 \\
   & diff & \% &  0.000e+00 &  0.000e+00 &  2.637e+03 &  2.637e+03 &  2.896e+01 &  8.842e+01 \\
   &          & num &  0.000e+00 &  0.000e+00 &  3.243e+00 &  3.243e+00 & -5.864e-01 & -6.009e-01 \\
   & std & \% &  0.000e+00 &  0.000e+00 &  1.240e+03 &  1.240e+03 &  1.957e+01 &  4.139e+01 \\
   &          & num &  0.000e+00 &  0.000e+00 &  1.525e+00 &  1.525e+00 &  3.963e-01 &  2.813e-01 \\
   & diff/std & \% &        NaN &        NaN &  2.126e+02 &  2.126e+02 &  1.480e+02 &  2.136e+02 \\
pc & mean & num &  0.000e+00 &  0.000e+00 &  1.794e+00 &  1.794e+00 &  2.675e+00 &  3.309e-01 \\
   & ref & num &  0.000e+00 &  0.000e+00 &  2.259e+00 &  2.259e+00 &  2.811e+00 &  7.824e-01 \\
   & diff & \% &        NaN &        NaN &  2.591e+01 &  2.591e+01 &  5.067e+00 &  1.364e+02 \\
   &          & num &  0.000e+00 &  0.000e+00 & -4.649e-01 & -4.649e-01 & -1.356e-01 & -4.515e-01 \\
   & std & \% &        NaN &        NaN &  1.074e-03 &  1.074e-03 &  1.812e-03 &  9.418e-03 \\
   &          & num &  0.000e+00 &  0.000e+00 &  1.928e-05 &  1.928e-05 &  4.848e-05 &  3.116e-05 \\
   & diff/std & \% &        NaN &        NaN &  2.412e+06 &  2.412e+06 &  2.796e+05 &  1.449e+06 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Using the reconstructed matrix elements}
\label{\detokenize{part2/case-study-N2_290723:using-the-reconstructed-matrix-elements}}
\sphinxAtStartPar
The results tables are accessible directly, and there are also methods to reformat the best fit results for use in further calculations.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} self.paramsSummary contains the results above as Pandas Dataframe, usual Pandas methods can be applied.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsSummary}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{describe}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrr}
\toprule
Param &  PU\_SG\_PU\_1\_1\_n1\_1 &  PU\_SG\_PU\_1\_n1\_1\_1 &  PU\_SG\_PU\_3\_1\_n1\_1 &  PU\_SG\_PU\_3\_n1\_1\_1 &  SU\_SG\_SU\_1\_0\_0\_1 &  SU\_SG\_SU\_3\_0\_0\_1 \\
\midrule
count &            124.000 &            124.000 &            124.000 &            124.000 &           124.000 &           124.000 \\
mean  &              0.351 &              0.351 &              0.759 &              0.759 &             1.947 &             0.338 \\
std   &              0.972 &              0.972 &              1.008 &              1.008 &             0.831 &             0.738 \\
min   &             -0.861 &             -0.861 &             -2.656 &             -2.656 &             0.615 &            -1.192 \\
25\%   &             -0.215 &             -0.215 &              0.223 &              0.223 &             1.514 &             0.116 \\
50\%   &              0.226 &              0.226 &              0.896 &              0.896 &             2.473 &             0.335 \\
75\%   &              0.792 &              0.792 &              1.149 &              1.149 &             2.675 &             0.594 \\
max   &              1.815 &              1.815 &              1.794 &              1.794 &             2.747 &             1.361 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To set matrix elements from aggregate fit results, use `seetAggMatE` for Pandas}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setAggMatE}\PYG{p}{(}\PYG{n}{simpleForm} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{agg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matEpd}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set reformatted aggregate data to self.data[agg][matEpd].
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\begin{tabular}{llllrrrrrrl}
\toprule
   &   &    & Type &      m &      n &      p &     pc &          comp &         compC & labels \\
Cont & l & m & mu &        &        &        &        &               &               &        \\
\midrule
PU & 1 & -1 &  1 &  1.815 &  0.451 & -0.861 &  0.000 &  1.183-1.377j &  0.451+0.000j &   1,-1 \\
   &   &  1 & -1 &  1.815 &  0.451 & -0.861 &  0.000 &  1.183-1.377j &  0.451+0.000j &    1,1 \\
   & 3 & -1 &  1 &  0.896 &  0.223 &  0.123 &  1.794 &  0.889+0.110j & -0.049+0.217j &   3,-1 \\
   &   &  1 & -1 &  0.896 &  0.223 &  0.123 &  1.794 &  0.889+0.110j & -0.049+0.217j &    3,1 \\
SU & 1 &  0 &  0 &  2.473 &  0.615 &  2.025 &  2.675 & -1.085+2.222j & -0.550+0.277j &    1,0 \\
   & 3 &  0 &  0 &  1.361 &  0.339 & -0.680 &  0.331 &  1.059-0.855j &  0.320+0.110j &    3,0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To set matrix elements from aggregate fit results, use `aggToXR` for Xarray}
\PYG{c+c1}{\PYGZsh{} data.aggToXR(refKey = \PYGZsq{}orb5\PYGZsq{}, returnType = \PYGZsq{}ds\PYGZsq{}, conformDims=True)   \PYGZsh{} use full ref dataset}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{aggToXR}\PYG{p}{(}\PYG{n}{refKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{returnType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{conformDims}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Subselected matE}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Added dim Total
Added dim Targ
Added dim Total
Added dim Targ
Set XR dataset for self.data[\PYGZsq{}agg\PYGZsq{}][\PYGZsq{}matE\PYGZsq{}]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Density matrices}
\label{\detokenize{part2/case-study-N2_290723:density-matrices}}
\sphinxAtStartPar
New (experimental) code for density matrix plots and comparison. See \hyperref[\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}]{Sect.\@ \ref{\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}}} for discussion. Code adapted from the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html\#Density-matrix-plotting}{MF reconstruction page}, original analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case. If the reconstruction is good, the differences (fidelity) should be on the order of the experimental noise level/reconstruction uncertainty, around 10\% in the case studies herein; in general the values and patterns of the matrices can also indicate aspects of the retrieval that worked well, or areas where values are poorly defined/recovered from the given dataset.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{531e98bd434c75dc61483e0a5b20b7dd0f23256a6029e2884d276272260eb887}.png}
\caption{Density matrix comparison \sphinxhyphen{} rows show (a) reference case (with signs of phases removed), (b) reconstructed case, (c) differences. Columns are (left) imaginary component, (right) real component. If the reconstruction is good, the differences (fidelity) should be on the order of the experimental noise level/reconstruction uncertainty, around 10\% in the case studies herein.}\label{\detokenize{part2/case-study-N2_290723:fig-n2-densitycomp}}\end{figure}


\subsection{Plot MF PADs}
\label{\detokenize{part2/case-study-N2_290723:plot-mf-pads}}
\sphinxAtStartPar
Routines below adapted from the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/MFPAD\_replotting\_from\_file\_190722-dist.html}{MF reconstruction data processing page} (original analysis page for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case). The routines include calls to \sphinxcode{\sphinxupquote{self.mfpadNumeric()}} for numerical expansion of the MF\sphinxhyphen{}PADs, and \sphinxcode{\sphinxupquote{self.padPlot()}} for plotting. Results are illustrated for the retrieved and reference cases in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-compc}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-compc}}} and \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-ref}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-ref}}} respectively, and the differential results (reference minus fitted results) in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-diff}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{2f9fabf9e65f03df71bd269a59ef53e826bfa78539a24bb063b3ff2235abb208}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} computed from retrieved matrix elements for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis.}\label{\detokenize{part2/case-study-N2_290723:fig-n2-compc}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{0fbcd3ca976c1f3d160757acb2b1a137fd804cd882e3d237198565b78f473bb2}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} computed from reference \sphinxstyleemphasis{ab initio} matrix elements for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis.}\label{\detokenize{part2/case-study-N2_290723:fig-n2-ref}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{84106b0c45473f709407d62407c705279a6d8b0a9d6c356364f024c773fbd52e}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} differences between retrieved and reference cases for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis. Note diffs are normalised to emphasize the shape, but not mangnitudes, of the differences \sphinxhyphen{} see the density matrix comparisons for a more rigourous fidelity analysis.}\label{\detokenize{part2/case-study-N2_290723:fig-n2-diff}}\end{figure}

\sphinxstepscope


\chapter{Case study: Generalised bootstrapping for a linear heteronuclear scattering system, \protect\(OCS~(C_{\infty v})\protect\)}
\label{\detokenize{part2/case-study-OCS_290723:case-study-generalised-bootstrapping-for-a-linear-heteronuclear-scattering-system-ocs-c-infty-v}}\label{\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}}\label{\detokenize{part2/case-study-OCS_290723::doc}}
\sphinxAtStartPar
In this chapter, the full code and analysis details of the case study for \(OCS\) are given, including obtaining required data, running fits and analysis routines. For more details on the routines, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}; for the analysis see particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_analysis\_demo\_150621-tidy.html}{fit fidelity and analysis page}, and \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html}{molecular frame analysis data processing page} (full analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case).


\section{General setup}
\label{\detokenize{part2/case-study-OCS_290723:general-setup}}
\sphinxAtStartPar
In the following code cells (see source notebooks for full details) the general setup routines (as per the outline in \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chpt.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}} are executed via a configuration script with presets for the case studies herein.

\sphinxAtStartPar
Additionally, the routines will either run fits, or load existing data if available. Since fitting can be computationally demanding, it is, in general, recommended to approach large fitting problems carefully.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{General note on fitting}

\sphinxAtStartPar
Computational outputs in this chapter are significantly truncated in the PDF, and some simplified plots are used; see source notebooks (via \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}) or \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)} for full details.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Configure settings for case study}

\PYG{c+c1}{\PYGZsh{} Set case study by name}
\PYG{n}{fitSystem}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{OCS}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{fitStem}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{fit\PYGZus{}withNoise\PYGZus{}orb13}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Add noise?}
\PYG{n}{addNoise} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{y}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.05}  \PYG{c+c1}{\PYGZsh{} Up to approx 10\PYGZpc{} noise (+/\PYGZhy{} 0.05)}

\PYG{c+c1}{\PYGZsh{} Batching \PYGZhy{} number of fits to run between data dumps}
\PYG{n}{batchSize} \PYG{o}{=} \PYG{l+m+mi}{10}

\PYG{c+c1}{\PYGZsh{} Total fits to run}
\PYG{n}{nMax} \PYG{o}{=} \PYG{l+m+mi}{10}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Pull data from web (OCS case)}
\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{util}\PYG{n+nn}{.}\PYG{n+nn}{io} \PYG{k+kn}{import} \PYG{n}{getFilesFromGithub}

\PYG{c+c1}{\PYGZsh{} Set dataName (will be used as download subdir)}
\PYG{n}{dataName} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{OCSfitting}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} OCS matrix elements}
\PYG{n}{fDictMatE}\PYG{p}{,} \PYG{n}{fAllMatE} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/photoionization/OCS\PYGZus{}multiorb}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{,} \PYG{n}{ref}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dev}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} OCS alignment data}
\PYG{n}{fDictADM}\PYG{p}{,} \PYG{n}{fAllADM} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/alignment/OCS\PYGZus{}ADMs\PYGZus{}28K\PYGZus{}VM\PYGZus{}070722}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{,} \PYG{n}{ref}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dev}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/photoionization/OCS\PYGZus{}multiorb?ref=dev
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}survey.orb10\PYGZus{}E0.1\PYGZus{}2.0\PYGZus{}30.1eV.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}survey.orb10\PYGZus{}E1.1\PYGZus{}2.0\PYGZus{}31.1eV.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}survey.orb11\PYGZus{}E0.1\PYGZus{}2.0\PYGZus{}30.1eV.inp.out already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}survey.orb11\PYGZus{}E1.1\PYGZus{}2.0\PYGZus{}31.1eV.inp.out already exists
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/alignment/OCS\PYGZus{}ADMs\PYGZus{}28K\PYGZus{}VM\PYGZus{}070722?ref=dev
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/A20\PYGZus{}300fs\PYGZus{}4p2TW\PYGZus{}28K.dat already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/A40\PYGZus{}300fs\PYGZus{}4p2TW\PYGZus{}28K.dat already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/A60\PYGZus{}300fs\PYGZus{}4p2TW\PYGZus{}28K.dat already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/c2t\PYGZus{}300fs\PYGZus{}4p2TW\PYGZus{}28K.dat already exists
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/time\PYGZus{}300fs\PYGZus{}4p2TW\PYGZus{}28K.dat already exists
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fitting setup including data generation and parameter creation}

\PYG{c+c1}{\PYGZsh{} Set datapath, }
\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{Path}\PYG{o}{.}\PYG{n}{cwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{dataName}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run general config script with dataPath set above}
\PYG{o}{\PYGZpc{}}\PYG{k}{run} \PYGZdq{}../scripts/setup\PYGZus{}fit\PYGZus{}case\PYGZhy{}studies\PYGZus{}270723.py\PYGZdq{} \PYGZhy{}d \PYGZob{}dataPath\PYGZcb{} \PYGZhy{}a \PYGZob{}dataPath\PYGZcb{} \PYGZhy{}c \PYGZob{}fitSystem\PYGZcb{} \PYGZhy{}n \PYGZob{}addNoise\PYGZcb{} \PYGZhy{}\PYGZhy{}sigma \PYGZob{}sigma\PYGZcb{} \PYGZhy{}a3D \PYGZsq{}y\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Load existing fit data or run fits}
\label{\detokenize{part2/case-study-OCS_290723:load-existing-fit-data-or-run-fits}}
\sphinxAtStartPar
Note that running fits may be quite time\sphinxhyphen{}consuming and computationally intensive, depending on the size of the size of the problem. The default case here will run a small batch for testing if there is no existing data found on the \sphinxcode{\sphinxupquote{dataPath}}, otherwise the data is loaded for analysis.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Look for existing Pickle files on path}
\PYG{n}{dataFiles} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{dataPath}\PYG{o}{.}\PYG{n}{expanduser}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{glob}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{*.pickle}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{dataFiles}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{No data found, executing minimal fitting run...}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} Run fit batch \PYGZhy{} single}
    \PYG{c+c1}{\PYGZsh{} data.multiFit(nRange = [n,n+batchSize\PYGZhy{}1], num\PYGZus{}workers=batchSize)}

    \PYG{c+c1}{\PYGZsh{} Run fit batches with checkpoint files}
    \PYG{k}{for} \PYG{n}{n} \PYG{o+ow}{in} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{nMax}\PYG{p}{,}\PYG{n}{batchSize}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{*** Running batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{], }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{now}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strftime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{m}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{y\PYGZus{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{H\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{M\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{S}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Run fit batch}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{multiFit}\PYG{p}{(}\PYG{n}{nRange} \PYG{o}{=} \PYG{p}{[}\PYG{n}{n}\PYG{p}{,}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{num\PYGZus{}workers}\PYG{o}{=}\PYG{n}{batchSize}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Dump data so far}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{writeFitData}\PYG{p}{(}\PYG{n}{outStem}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitSystem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitStem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Finished batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{], }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{now}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strftime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{m}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{y\PYGZus{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{H\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{M\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{S}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Written to file }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitSystem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitStem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{k}{else}\PYG{p}{:}
    \PYG{n}{dataFileIn} \PYG{o}{=} \PYG{n}{dataFiles}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}   \PYG{c+c1}{\PYGZsh{} Add index to select file, although loadFitData will concat multiple files}
                                    \PYG{c+c1}{\PYGZsh{} Note that concat currently only works for fixed batch sizes however.}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Set dataFiles: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dataFileIn}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{loadFitData}\PYG{p}{(}\PYG{n}{fList}\PYG{o}{=}\PYG{n}{dataFileIn}\PYG{p}{,} \PYG{n}{dataPath}\PYG{o}{=}\PYG{n}{dataPath}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{}.expanduser())}
    
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMfitPlot}\PYG{p}{(}\PYG{n}{keys}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} \PYGZsh{} Check ADMs}
    \PYG{c+c1}{\PYGZsh{} data.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}ADM\PYGZsq{}].unstack().where(data.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}ADM\PYGZsq{}].unstack().K\PYGZgt{}0) \PYGZbs{}}
    \PYG{c+c1}{\PYGZsh{}     .real.hvplot.line(x=\PYGZsq{}t\PYGZsq{}).overlay([\PYGZsq{}K\PYGZsq{},\PYGZsq{}Q\PYGZsq{},\PYGZsq{}S\PYGZsq{}])}
    
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set dataFiles: /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}999\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb13\PYGZus{}200723\PYGZus{}05\PYGZhy{}47\PYGZhy{}50.pickle
Read data from /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}999\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb13\PYGZus{}200723\PYGZus{}05\PYGZhy{}47\PYGZhy{}50.pickle with pickle.
Dataset: subset, AFBLM
Dataset: sim, AFBLM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{46a81ce37ff372ec048d090a0fd63634a441e75dfa992b4e043b02722b9597da}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check ADMs}
\PYG{c+c1}{\PYGZsh{} Basic plotter}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{ADMplot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset: subset, ADM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{f535bb88d4225dcd57b58af0f1eb3407102cf1b7c47fcbd171975d898401463d}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fits appear as integer indexed items in the main data structure.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Post\sphinxhyphen{}processing and data overview}
\label{\detokenize{part2/case-study-OCS_290723:post-processing-and-data-overview}}
\sphinxAtStartPar
Post\sphinxhyphen{}processing involves aggregation of all the fit run results into a single data structure. This can then be analysed statistically and examined for for best\sphinxhyphen{}fit results. In the statistical sense, this is essentailly a search for candidate {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, based on the assumption that some of the minima found in the \(\chi^2\) hyperspace will be the true results. Even if a clear global minima does not exist, searching for candidate {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} sets based on clustering of results and multiple local minima is still expected to lead to viable candidates provided that the information content of the dataset is sufficient. However, as discussed elsewhere (see \hyperref[\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}}}), in some cases this may not be the case, and other limitations may apply (e.g. certain parameters may be undefined), or additional data required for unique determination of the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}.

\sphinxAtStartPar
For more details on the analysis routines, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_analysis\_demo\_150621-tidy.html}{fit fidelity and analysis page}, and \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html}{molecular frame analysis data processing page} (full analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case).

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} General stats \PYGZam{} post\PYGZhy{}processing to data tables}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{analyseFits}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\PYGZob{} \PYGZsq{}Fits\PYGZsq{}: 975,
  \PYGZsq{}Minima\PYGZsq{}: \PYGZob{}\PYGZsq{}chisqr\PYGZsq{}: 0.2510827613766783, \PYGZsq{}redchi\PYGZsq{}: 0.00011080439601795158\PYGZcb{},
  \PYGZsq{}Stats\PYGZsq{}: \PYGZob{} \PYGZsq{}chisqr\PYGZsq{}: min       0.251
mean      0.253
median    0.251
max       2.304
std       0.066
var       0.004
Name: chisqr, dtype: float64,
             \PYGZsq{}redchi\PYGZsq{}: min       1.108e\PYGZhy{}04
mean      1.117e\PYGZhy{}04
median    1.108e\PYGZhy{}04
max       1.017e\PYGZhy{}03
std       2.902e\PYGZhy{}05
var       8.420e\PYGZhy{}10
Name: redchi, dtype: float64\PYGZcb{},
  \PYGZsq{}Success\PYGZsq{}: 971\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The BLMsetPlot routine will output aggregate fit results.}
\PYG{c+c1}{\PYGZsh{} Here the spread can be taken as a general indication of the uncertainty of }
\PYG{c+c1}{\PYGZsh{} the fitting, and indicate whether the fit is well\PYGZhy{}characterised/the information }
\PYG{c+c1}{\PYGZsh{} content of the data is sufficient.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMsetPlot}\PYG{p}{(}\PYG{n}{xDim} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}6}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} With xDim and thres set, for more control over outputs}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OCS\PYGZhy{}fitResultsBLM}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMsetPlot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{74b649717675a0ca5d235d7dbacd8fd1f630294c18711c102ccaa1b91c0454fa}.png}
\caption{Fit overview plot \sphinxhyphen{} \(\beta_{L,M}(t)\). Here dashed lines with ‘+’ markers indicates the input data, and bands indicate the mean fit results, where the width is the standard deviation in the fit model results. (See the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for details, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_multiproc\_class\_analysis\_141121-tidy.html\#Fit-set-plotters}{analysis routines page}.)}\label{\detokenize{part2/case-study-OCS_290723:fig-ocs-fitresultsblm}}\end{figure}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Write aggregate datasets to HDF5 format}
\PYG{c+c1}{\PYGZsh{} This is more robust than Pickled data, but PEMtk currently only support output for aggregate (post\PYGZhy{}processed) fit data.}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{processedToHDF5}\PYG{p}{(}\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{dataPath}\PYG{p}{,} \PYG{n}{outStem} \PYG{o}{=} \PYG{n}{dataFileIn}\PYG{o}{.}\PYG{n}{name}\PYG{p}{,} \PYG{n}{timeStamp}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dumped self.data[fits][dfLong] to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}999\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb13\PYGZus{}200723\PYGZus{}05\PYGZhy{}47\PYGZhy{}50.pickle\PYGZus{}dfLong.pdHDF with Pandas .to\PYGZus{}hdf() routine.
Dumped data to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}999\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb13\PYGZus{}200723\PYGZus{}05\PYGZhy{}47\PYGZhy{}50.pickle\PYGZus{}dfLong.pdHDF with pdHDF.
Dumped self.data[fits][AFxr] to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}999\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb13\PYGZus{}200723\PYGZus{}05\PYGZhy{}47\PYGZhy{}50.pickle\PYGZus{}AFxr.pdHDF with Pandas .to\PYGZus{}hdf() routine.
Dumped data to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/OCSfitting/OCS\PYGZus{}999\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb13\PYGZus{}200723\PYGZus{}05\PYGZhy{}47\PYGZhy{}50.pickle\PYGZus{}AFxr.pdHDF with pdHDF.
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Histogram fit results (reduced chi\PYGZca{}2 vs. fit index)}
\PYG{c+c1}{\PYGZsh{} This may be quite slow for large datasets, setting limited ranges may help}

\PYG{c+c1}{\PYGZsh{} Use default auto binning}
\PYG{c+c1}{\PYGZsh{} data.fitHist()}

\PYG{c+c1}{\PYGZsh{} Example with range set}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{fitHist}\PYG{p}{(}\PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1.11e\PYGZhy{}4}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OCS\PYGZhy{}fitHist}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fitHistPlot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Mask selected 974 results (from 975).
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
:AdjointLayout
   :Scatter   [redchi]   (Fit)
   :Histogram   [Fit]   (Fit\PYGZus{}count)
   :Histogram   [redchi]   (redchi\PYGZus{}count)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{6ae531dd2e7143f9e4eb00315898499abdf7c40177c4706ce9e1ae62c85e5136}.png}
\caption{Fit overview plot \sphinxhyphen{} \(\chi^2\) vs. fit index. Here bands indicate groupings (local minima) are consistently found.}\label{\detokenize{part2/case-study-OCS_290723:fig-ocs-fithist}}\end{figure}

\sphinxAtStartPar
Here, \hyperref[\detokenize{part2/case-study-OCS_290723:fig-ocs-fitresultsblm}]{Fig.\@ \ref{\detokenize{part2/case-study-OCS_290723:fig-ocs-fitresultsblm}}} shows an overview of the results compared with the input data, and \hyperref[\detokenize{part2/case-study-OCS_290723:fig-ocs-fithist}]{Fig.\@ \ref{\detokenize{part2/case-study-OCS_290723:fig-ocs-fithist}}} an overview of \(\chi^2\) vs. fit index. Bands in the \(\chi^2\) dimension can indicate groupings (local minima) are consistently found. Assuming each grouping is a viable fit candidate parameter set, these can then be explored in further detail.


\section{Data exploration}
\label{\detokenize{part2/case-study-OCS_290723:data-exploration}}
\sphinxAtStartPar
The general aim in this procedure is to ascertain whether there was a good spread of parameters explored, and a single (or few sets) of best\sphinxhyphen{}fit results. There are a few procedures and helper methods for this…


\subsection{View results}
\label{\detokenize{part2/case-study-OCS_290723:view-results}}
\sphinxAtStartPar
Single results sets can be viewed in the main data structure, indexed by integers.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check keys}
\PYG{n}{fitNumber} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{fitNumber}\PYG{p}{]}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}AFBLM\PYGZsq{}, \PYGZsq{}residual\PYGZsq{}, \PYGZsq{}results\PYGZsq{}])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Here \sphinxcode{\sphinxupquote{results}} is an \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{lmFit object}, which includes final fit results and information, and \sphinxcode{\sphinxupquote{AFBLM}} contains the model (fit) output (i.e. resultant AF\sphinxhyphen{}\(\beta_{LM}\) values).

\sphinxAtStartPar
An example is shown below. Of particular note here is which parameters have \sphinxcode{\sphinxupquote{vary=True}} \sphinxhyphen{} these are included in the fitting \sphinxhyphen{} and if there is a column \sphinxcode{\sphinxupquote{expression}}, which indicates any parameters defined to have specific relationships (see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}}). Any correlations found during fitting are also shown, which can also indicate parameters which are related (even if this is not predefined or known a priori).

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Show some results}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{fitNumber}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{results}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Classify candidate sets}
\label{\detokenize{part2/case-study-OCS_290723:classify-candidate-sets}}
\sphinxAtStartPar
To probe the minima found, the \sphinxcode{\sphinxupquote{classifyFits}} method can be used. This bins results into “candidate” groups, which can then be examined in detail.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run with defaults}
\PYG{c+c1}{\PYGZsh{} data.classifyFits()}

\PYG{c+c1}{\PYGZsh{} For more control, pass bins}
\PYG{c+c1}{\PYGZsh{} Here the minima is set at one end, and a \PYGZpc{}age range used for bins}
\PYG{n}{minVal} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{fitsSummary}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Stats}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{min}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}    
\PYG{n}{binRangePC} \PYG{o}{=} \PYG{l+m+mf}{1e\PYGZhy{}5}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{classifyFits}\PYG{p}{(}\PYG{n}{bins} \PYG{o}{=} \PYG{p}{[}\PYG{n}{minVal}\PYG{p}{,} \PYG{n}{minVal} \PYG{o}{+} \PYG{n}{binRangePC}\PYG{o}{*}\PYG{n}{minVal} \PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllllrrrrrrrr}
\toprule
{} & \multicolumn{4}{l}{success} & \multicolumn{4}{l}{chisqr} & \multicolumn{4}{l}{redchi} \\
{} &   count & unique &   top & freq &  count & unique &    top & freq &  count & unique &        top & freq \\
redchiGroup &         &        &       &      &        &        &        &      &        &        &            &      \\
\midrule
A           &      47 &      1 &  True &   47 &   47.0 &   47.0 &  0.251 &  1.0 &   47.0 &   47.0 &  1.108e-04 &  1.0 \\
B           &      82 &      1 &  True &   82 &   82.0 &   82.0 &  0.251 &  1.0 &   82.0 &   82.0 &  1.108e-04 &  1.0 \\
C           &      65 &      1 &  True &   65 &   65.0 &   65.0 &  0.251 &  1.0 &   65.0 &   65.0 &  1.108e-04 &  1.0 \\
D           &      76 &      1 &  True &   76 &   76.0 &   76.0 &  0.251 &  1.0 &   76.0 &   76.0 &  1.108e-04 &  1.0 \\
E           &      51 &      1 &  True &   51 &   51.0 &   51.0 &  0.251 &  1.0 &   51.0 &   51.0 &  1.108e-04 &  1.0 \\
F           &      54 &      1 &  True &   54 &   54.0 &   54.0 &  0.251 &  1.0 &   54.0 &   54.0 &  1.108e-04 &  1.0 \\
G           &      28 &      1 &  True &   28 &   28.0 &   28.0 &  0.251 &  1.0 &   28.0 &   28.0 &  1.108e-04 &  1.0 \\
H           &      24 &      1 &  True &   24 &   24.0 &   24.0 &  0.251 &  1.0 &   24.0 &   24.0 &  1.108e-04 &  1.0 \\
I           &      23 &      1 &  True &   23 &   23.0 &   23.0 &  0.251 &  1.0 &   23.0 &   23.0 &  1.108e-04 &  1.0 \\
J           &      10 &      1 &  True &   10 &   10.0 &   10.0 &  0.251 &  1.0 &   10.0 &   10.0 &  1.108e-04 &  1.0 \\
K           &      12 &      1 &  True &   12 &   12.0 &   12.0 &  0.251 &  1.0 &   12.0 &   12.0 &  1.108e-04 &  1.0 \\
L           &       7 &      1 &  True &    7 &    7.0 &    7.0 &  0.251 &  1.0 &    7.0 &    7.0 &  1.108e-04 &  1.0 \\
M           &       3 &      1 &  True &    3 &    3.0 &    3.0 &  0.251 &  1.0 &    3.0 &    3.0 &  1.108e-04 &  1.0 \\
N           &       7 &      1 &  True &    7 &    7.0 &    7.0 &  0.251 &  1.0 &    7.0 &    7.0 &  1.108e-04 &  1.0 \\
O           &       7 &      1 &  True &    7 &    7.0 &    7.0 &  0.251 &  1.0 &    7.0 &    7.0 &  1.108e-04 &  1.0 \\
P           &       7 &      1 &  True &    7 &    7.0 &    7.0 &  0.251 &  1.0 &    7.0 &    7.0 &  1.108e-04 &  1.0 \\
Q           &       5 &      1 &  True &    5 &    5.0 &    5.0 &  0.251 &  1.0 &    5.0 &    5.0 &  1.108e-04 &  1.0 \\
R           &       7 &      1 &  True &    7 &    7.0 &    7.0 &  0.251 &  1.0 &    7.0 &    7.0 &  1.108e-04 &  1.0 \\
S           &       3 &      1 &  True &    3 &    3.0 &    3.0 &  0.251 &  1.0 &    3.0 &    3.0 &  1.108e-04 &  1.0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{433498643557ad70cc8ad28008fd103fc9633d838c9bc114f9ff5cb775810caa}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Explore candidate result sets}
\label{\detokenize{part2/case-study-OCS_290723:explore-candidate-result-sets}}
\sphinxAtStartPar
Drill\sphinxhyphen{}down on a candidate set of results, and examine values and spreads. For more details see \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, especially the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_multiproc\_class\_analysis\_141121-tidy.html}{analysis routines page}. (See also \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}} for details on the plotting libaries implemented here.)


\subsection{Raw results}
\label{\detokenize{part2/case-study-OCS_290723:raw-results}}
\sphinxAtStartPar
Plot spreads in magnitude and phase parameters. Statistical plots are available for Seaborn and Holoviews backends, with some slightly different options.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} From the candidates, select a group for analysis}
\PYG{n}{selGroup} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} paramPlot can be used to check the spread on each parameter.}
\PYG{c+c1}{\PYGZsh{} Plots use Seaborn or Holoviews/Bokeh}
\PYG{c+c1}{\PYGZsh{} Colour\PYGZhy{}mapping is controlled by the \PYGZsq{}hue\PYGZsq{} paramter, additionally pass hRound for sig. fig control.}
\PYG{c+c1}{\PYGZsh{} The remap setting allows for short\PYGZhy{}hand labels as set in data.lmmu}

\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Set for (m)agnitude or (p)hase parameters}
\PYG{n}{hRound} \PYG{o}{=} \PYG{l+m+mi}{14} \PYG{c+c1}{\PYGZsh{} Set for cmapping, default may be too small (leads to all grey cmap on points)}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7fcec8514340\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{22d92678bb10a390459612e6a31627917f97343e5e12a058212673fbbdfcb878}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Set for (m)agnitude or (p)hase parameters}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7fcec86c07f0\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{d3c7c416ef324923a00526d4779bd6f53a619b947027d036294c7cccc9f8ff2b}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Phases, phase shifts \& corrections}
\label{\detokenize{part2/case-study-OCS_290723:phases-phase-shifts-corrections}}
\sphinxAtStartPar
Depending on how the fit was configured, phases may be defined in different ways. To set the phases relative to a speific parameter, and wrap to a specified range, use the \sphinxcode{\sphinxupquote{phaseCorrection()}} method. This defaults to using the first parameter as a reference phase, and wraps to \(-\pi:\pi\). The phase\sphinxhyphen{}corrected values are output to a new Type, ‘pc’, and a set of normalised magnitudes to ‘n’. Additional settings can be passed for more control, as shown below.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run phase correction routine}
\PYG{c+c1}{\PYGZsh{} Set absFlag=True for unsigned phases (mapped to 0:pi)}
\PYG{c+c1}{\PYGZsh{} Set useRef=False to set ref phase as 0, otherwise the reference value is set.}
\PYG{n}{phaseCorrParams}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{absFlag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{k+kc}{True}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{useRef}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{k+kc}{False}\PYG{p}{\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{phaseCorrection}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{phaseCorrParams}\PYG{p}{)}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Examine new data types…

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{kind}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{box}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7fcec87aee60\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{260689f9945007745f5ff260e2621267c60eeb1ae95ec05528c8f9eb174ec167}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pc}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{kind}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{box}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7fcec84e6b00\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{c8a1b94c008baa9dc631d1b18728c4d4969389647b63deea3bd985734a7660ca}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Parameter estimation \& fidelity}
\label{\detokenize{part2/case-study-OCS_290723:parameter-estimation-fidelity}}
\sphinxAtStartPar
For case studies, the fit results can be directly compared to the known input parameters. This should give a feel for how well the data defines the matrix elements (parameters) in this case. In general, probing the correlations and spread of results, and comparing to other (unfitted) results is required to estimate fidelity, see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} for further discussion.


\subsection{Best values and statistics}
\label{\detokenize{part2/case-study-OCS_290723:best-values-and-statistics}}
\sphinxAtStartPar
To get a final parameter set and associated statistics, based on a subset of the fit results, the \sphinxcode{\sphinxupquote{paramsReport()}} method is available. If reference data is available, as for the case studies herein, the \sphinxcode{\sphinxupquote{paramsCompare()}} method can also be used to compare with the reference case.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Parameter summary}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsReport}\PYG{p}{(}\PYG{n}{inds} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Parameter comparison}
\PYG{c+c1}{\PYGZsh{} Note this uses phaseCorrParams as set previously for consistency}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsCompare}\PYG{p}{(}\PYG{n}{phaseCorrParams}\PYG{o}{=}\PYG{n}{phaseCorrParams}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Display above results With column name remapping to (l,m) labels only}

\PYG{c+c1}{\PYGZsh{} With Pandas functionality}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsSummaryComp}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{n}{columns}\PYG{o}{=}\PYG{n}{data}\PYG{o}{.}\PYG{n}{lmmu}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} With utility method}
\PYG{c+c1}{\PYGZsh{} summaryRenamed = pemtk.fit.\PYGZus{}util.renameParams(data.paramsSummaryComp, data.lmmu[\PYGZsq{}lmMap\PYGZsq{}]) }
\PYG{c+c1}{\PYGZsh{} summaryRenamed}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllrrrrrrrrrrrrrrrrrrrrrr}
\toprule
   &          & Param &      1,1 &     1,-1 &       2,1 &      2,-1 &       3,1 &      3,-1 &       4,1 &      4,-1 &      5,1 &     5,-1 &      6,1 &     6,-1 &        7,1 &       7,-1 &       0,0 &      1,0 &       2,0 &      3,0 &       4,0 &      5,0 &      6,0 &        7,0 \\
Type & Source & dType &          &          &           &           &           &           &           &           &          &          &          &          &            &            &           &          &           &          &           &          &          &            \\
\midrule
m & mean & num &    0.395 &    0.395 &     0.384 &     0.384 &     1.041 &     1.041 &     0.378 &     0.378 &    0.239 &    0.239 &    0.439 &    0.439 &      0.853 &      0.853 &     0.752 &    0.305 &     0.860 &    0.954 &     0.615 &    0.402 &    0.455 &      1.098 \\
   & ref & num &    0.299 &    0.299 &     0.735 &     0.735 &     0.966 &     0.966 &     0.875 &     0.875 &    0.541 &    0.541 &    0.108 &    0.108 &      0.036 &      0.036 &     0.607 &    0.855 &     0.967 &    1.204 &     0.563 &    0.535 &    0.147 &      0.026 \\
   & diff & \% &   24.383 &   24.383 &    91.513 &    91.513 &     7.275 &     7.275 &   131.508 &   131.508 &  126.743 &  126.743 &   75.476 &   75.476 &     95.786 &     95.786 &    19.306 &  180.049 &    12.502 &   26.162 &     8.467 &   33.241 &   67.712 &     97.652 \\
   &          & num &    0.096 &    0.096 &    -0.351 &    -0.351 &     0.076 &     0.076 &    -0.497 &    -0.497 &   -0.302 &   -0.302 &    0.331 &    0.331 &      0.817 &      0.817 &     0.145 &   -0.549 &    -0.108 &   -0.250 &     0.052 &   -0.134 &    0.308 &      1.072 \\
   & std & \% &   19.952 &   19.952 &    35.782 &    35.782 &     3.929 &     3.929 &     9.266 &     9.266 &   17.524 &   17.524 &   16.566 &   16.566 &      0.862 &      0.862 &    14.208 &   19.475 &     5.556 &    6.039 &     9.625 &   10.877 &   18.151 &      0.574 \\
   &          & num &    0.079 &    0.079 &     0.137 &     0.137 &     0.041 &     0.041 &     0.035 &     0.035 &    0.042 &    0.042 &    0.073 &    0.073 &      0.007 &      0.007 &     0.107 &    0.059 &     0.048 &    0.058 &     0.059 &    0.044 &    0.083 &      0.006 \\
   & diff/std & \% &  122.212 &  122.212 &   255.754 &   255.754 &   185.143 &   185.143 &  1419.210 &  1419.210 &  723.234 &  723.234 &  455.606 &  455.606 &  11115.642 &  11115.642 &   135.881 &  924.509 &   225.018 &  433.192 &    87.969 &  305.597 &  373.043 &  17012.358 \\
n & mean & num &    0.129 &    0.129 &     0.125 &     0.125 &     0.340 &     0.340 &     0.123 &     0.123 &    0.078 &    0.078 &    0.143 &    0.143 &      0.278 &      0.278 &     0.246 &    0.100 &     0.281 &    0.312 &     0.201 &    0.131 &    0.149 &      0.359 \\
   & ref & num &    0.097 &    0.097 &     0.240 &     0.240 &     0.315 &     0.315 &     0.286 &     0.286 &    0.177 &    0.177 &    0.035 &    0.035 &      0.012 &      0.012 &     0.198 &    0.279 &     0.316 &    0.393 &     0.184 &    0.175 &    0.048 &      0.008 \\
   & diff & \% &   24.386 &   24.386 &    91.506 &    91.506 &     7.278 &     7.278 &   131.499 &   131.499 &  126.734 &  126.734 &   75.477 &   75.477 &     95.786 &     95.786 &    19.309 &  180.038 &    12.498 &   26.158 &     8.470 &   33.236 &   67.713 &     97.652 \\
   &          & num &    0.031 &    0.031 &    -0.115 &    -0.115 &     0.025 &     0.025 &    -0.162 &    -0.162 &   -0.099 &   -0.099 &    0.108 &    0.108 &      0.267 &      0.267 &     0.047 &   -0.179 &    -0.035 &   -0.082 &     0.017 &   -0.044 &    0.101 &      0.350 \\
   & std & \% &   19.952 &   19.952 &    35.782 &    35.782 &     3.929 &     3.929 &     9.266 &     9.266 &   17.524 &   17.524 &   16.566 &   16.566 &      0.862 &      0.862 &    14.208 &   19.475 &     5.556 &    6.039 &     9.625 &   10.877 &   18.151 &      0.574 \\
   &          & num &    0.026 &    0.026 &     0.045 &     0.045 &     0.013 &     0.013 &     0.011 &     0.011 &    0.014 &    0.014 &    0.024 &    0.024 &      0.002 &      0.002 &     0.035 &    0.019 &     0.016 &    0.019 &     0.019 &    0.014 &    0.027 &      0.002 \\
   & diff/std & \% &  122.226 &  122.226 &   255.734 &   255.734 &   185.231 &   185.231 &  1419.117 &  1419.117 &  723.186 &  723.186 &  455.611 &  455.611 &  11115.592 &  11115.592 &   135.902 &  924.455 &   224.942 &  433.115 &    88.005 &  305.551 &  373.049 &  17012.501 \\
p & mean & num &   -2.200 &   -2.200 &     0.091 &     0.091 &    -0.054 &    -0.054 &    -0.139 &    -0.139 &    0.979 &    0.979 &    0.515 &    0.515 &      0.490 &      0.490 &     0.161 &    0.966 &     0.177 &    0.380 &     0.095 &    1.237 &    0.763 &      0.494 \\
   & ref & num &   -2.200 &   -2.200 &    -1.410 &    -1.410 &    -2.100 &    -2.100 &    -0.800 &    -0.800 &    0.131 &    0.131 &    1.218 &    1.218 &      2.855 &      2.855 &    -2.003 &    0.983 &     2.679 &   -0.535 &     0.343 &    2.065 &    2.594 &     -1.519 \\
   & diff & \% &    0.000 &    0.000 &  1646.083 &  1646.083 &  3757.652 &  3757.652 &   475.859 &   475.859 &   86.591 &   86.591 &  136.728 &  136.728 &    483.135 &    483.135 &  1341.919 &    1.698 &  1417.730 &  240.975 &   261.343 &   67.010 &  239.854 &    407.175 \\
   &          & num &    0.000 &    0.000 &     1.501 &     1.501 &     2.046 &     2.046 &     0.661 &     0.661 &    0.848 &    0.848 &   -0.704 &   -0.704 &     -2.366 &     -2.366 &     2.164 &   -0.016 &    -2.503 &    0.915 &    -0.248 &   -0.829 &   -1.830 &      2.013 \\
   & std & \% &    0.000 &    0.000 &  1572.473 &  1572.473 &  4976.382 &  4976.382 &  1110.494 &  1110.494 &   19.054 &   19.054 &  462.998 &  462.998 &    191.036 &    191.036 &   986.064 &   21.018 &  1332.830 &  307.217 &  1581.735 &  125.579 &  300.904 &    183.068 \\
   &          & num &    0.000 &    0.000 &     1.434 &     1.434 &     2.709 &     2.709 &     1.542 &     1.542 &    0.187 &    0.187 &    2.383 &    2.383 &      0.935 &      0.935 &     1.590 &    0.203 &     2.353 &    1.166 &     1.500 &    1.553 &    2.296 &      0.905 \\
   & diff/std & \% &      NaN &      NaN &   104.681 &   104.681 &    75.510 &    75.510 &    42.851 &    42.851 &  454.443 &  454.443 &   29.531 &   29.531 &    252.903 &    252.903 &   136.088 &    8.079 &   106.370 &   78.438 &    16.523 &   53.361 &   79.711 &    222.417 \\
pc & mean & num &    0.000 &    0.000 &     1.796 &     1.796 &     0.888 &     0.888 &     1.816 &     1.816 &    2.979 &    2.979 &    1.374 &    1.374 &      2.125 &      2.125 &     1.826 &    2.965 &     1.348 &    1.875 &     1.810 &    1.739 &    1.402 &      2.156 \\
   & ref & num &    0.000 &    0.000 &     0.790 &     0.790 &     0.100 &     0.100 &     1.401 &     1.401 &    2.332 &    2.332 &    2.865 &    2.865 &      1.228 &      1.228 &     0.197 &    3.100 &     1.404 &    1.665 &     2.543 &    2.018 &    1.489 &      0.682 \\
   & diff & \% &      NaN &      NaN &    56.010 &    56.010 &    88.748 &    88.748 &    22.861 &    22.861 &   21.725 &   21.725 &  108.515 &  108.515 &     42.228 &     42.228 &    89.190 &    4.549 &     4.115 &   11.173 &    40.498 &   16.025 &    6.220 &     68.373 \\
   &          & num &    0.000 &    0.000 &     1.006 &     1.006 &     0.788 &     0.788 &     0.415 &     0.415 &    0.647 &    0.647 &   -1.491 &   -1.491 &      0.897 &      0.897 &     1.629 &   -0.135 &    -0.055 &    0.209 &    -0.733 &   -0.279 &   -0.087 &      1.474 \\
   & std & \% &      NaN &      NaN &    46.193 &    46.193 &    17.279 &    17.279 &    36.044 &    36.044 &    3.214 &    3.214 &   49.061 &   49.061 &      7.845 &      7.845 &    37.182 &    3.392 &    47.113 &   10.955 &    35.471 &   13.679 &   48.485 &      7.998 \\
   &          & num &    0.000 &    0.000 &     0.830 &     0.830 &     0.153 &     0.153 &     0.654 &     0.654 &    0.096 &    0.096 &    0.674 &    0.674 &      0.167 &      0.167 &     0.679 &    0.101 &     0.635 &    0.205 &     0.642 &    0.238 &    0.680 &      0.172 \\
   & diff/std & \% &      NaN &      NaN &   121.253 &   121.253 &   513.612 &   513.612 &    63.425 &    63.425 &  676.042 &  676.042 &  221.181 &  221.181 &    538.275 &    538.275 &   239.873 &  134.102 &     8.735 &  101.990 &   114.173 &  117.152 &   12.828 &    854.857 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Using the reconstructed matrix elements}
\label{\detokenize{part2/case-study-OCS_290723:using-the-reconstructed-matrix-elements}}
\sphinxAtStartPar
The results tables are accessible directly, and there are also methods to reformat the best fit results for use in further calculations.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} self.paramsSummary contains the results above as Pandas Dataframe, usual Pandas methods can be applied.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsSummary}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{describe}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrr}
\toprule
Param &  P\_S\_P\_1\_1\_n1\_1 &  P\_S\_P\_1\_n1\_1\_1 &  P\_S\_P\_2\_1\_n1\_1 &  P\_S\_P\_2\_n1\_1\_1 &  P\_S\_P\_3\_1\_n1\_1 &  P\_S\_P\_3\_n1\_1\_1 &  P\_S\_P\_4\_1\_n1\_1 &  P\_S\_P\_4\_n1\_1\_1 &  P\_S\_P\_5\_1\_n1\_1 &  P\_S\_P\_5\_n1\_1\_1 &  P\_S\_P\_6\_1\_n1\_1 &  P\_S\_P\_6\_n1\_1\_1 &  P\_S\_P\_7\_1\_n1\_1 &  P\_S\_P\_7\_n1\_1\_1 &  S\_S\_S\_0\_0\_0\_1 &  S\_S\_S\_1\_0\_0\_1 &  S\_S\_S\_2\_0\_0\_1 &  S\_S\_S\_3\_0\_0\_1 &  S\_S\_S\_4\_0\_0\_1 &  S\_S\_S\_5\_0\_0\_1 &  S\_S\_S\_6\_0\_0\_1 &  S\_S\_S\_7\_0\_0\_1 \\
\midrule
count &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &         188.000 &        188.000 &        188.000 &        188.000 &        188.000 &        188.000 &        188.000 &        188.000 &        188.000 \\
mean  &          -0.419 &          -0.419 &           0.599 &           0.599 &           0.554 &           0.554 &           0.545 &           0.545 &           1.069 &           1.069 &           0.618 &           0.618 &           0.937 &           0.937 &          0.746 &          1.084 &          0.666 &          0.880 &          0.680 &          0.877 &          0.692 &          1.027 \\
std   &           1.042 &           1.042 &           1.083 &           1.083 &           1.416 &           1.416 &           1.125 &           1.125 &           1.162 &           1.162 &           1.312 &           1.312 &           0.859 &           0.859 &          1.087 &          1.141 &          1.298 &          0.860 &          1.059 &          1.012 &          1.276 &          0.845 \\
min   &          -2.200 &          -2.200 &          -3.142 &          -3.142 &          -3.142 &          -3.142 &          -3.139 &          -3.139 &           0.045 &           0.045 &          -3.142 &          -3.142 &          -0.348 &          -0.348 &         -3.142 &          0.046 &         -3.142 &         -0.677 &         -2.994 &         -3.005 &         -3.142 &         -0.358 \\
25\%   &          -0.550 &          -0.550 &           0.113 &           0.113 &           0.337 &           0.337 &           0.121 &           0.121 &           0.128 &           0.128 &           0.152 &           0.152 &           0.277 &           0.277 &          0.235 &          0.137 &          0.274 &          0.310 &          0.198 &          0.138 &          0.158 &          0.358 \\
50\%   &           0.033 &           0.033 &           0.322 &           0.322 &           0.928 &           0.928 &           0.359 &           0.359 &           0.447 &           0.447 &           0.457 &           0.457 &           0.849 &           0.849 &          0.700 &          0.469 &          0.820 &          0.941 &          0.571 &          0.422 &          0.479 &          1.095 \\
75\%   &           0.177 &           0.177 &           1.063 &           1.063 &           1.039 &           1.039 &           0.952 &           0.952 &           1.771 &           1.771 &           0.974 &           0.974 &           1.956 &           1.956 &          1.025 &          1.684 &          0.996 &          1.754 &          1.150 &          1.831 &          1.086 &          1.950 \\
max   &           0.516 &           0.516 &           3.121 &           3.121 &           3.142 &           3.142 &           3.142 &           3.142 &           3.116 &           3.116 &           3.142 &           3.142 &           2.709 &           2.709 &          3.142 &          3.138 &          3.142 &          2.642 &          3.142 &          2.540 &          3.142 &          2.736 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To set matrix elements from aggregate fit results, use `seetAggMatE` for Pandas}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setAggMatE}\PYG{p}{(}\PYG{n}{simpleForm} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{agg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matEpd}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set reformatted aggregate data to self.data[agg][matEpd].
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\begin{tabular}{llllrrrrrrl}
\toprule
  &   &    & Type &      m &      n &      p &     pc &          comp &         compC & labels \\
Cont & l & m & mu &        &        &        &        &               &               &        \\
\midrule
P & 1 & -1 &  1 &  0.395 &  0.129 & -2.200 &  0.000 & -0.232-0.319j &  0.129+0.000j &   1,-1 \\
  &   &  1 & -1 &  0.395 &  0.129 & -2.200 &  0.000 & -0.232-0.319j &  0.129+0.000j &    1,1 \\
  & 2 & -1 &  1 &  0.384 &  0.125 &  0.091 &  1.796 &  0.382+0.035j & -0.028+0.122j &   2,-1 \\
  &   &  1 & -1 &  0.384 &  0.125 &  0.091 &  1.796 &  0.382+0.035j & -0.028+0.122j &    2,1 \\
  & 3 & -1 &  1 &  1.041 &  0.340 & -0.054 &  0.888 &  1.040-0.057j &  0.215+0.264j &   3,-1 \\
  &   &  1 & -1 &  1.041 &  0.340 & -0.054 &  0.888 &  1.040-0.057j &  0.215+0.264j &    3,1 \\
  & 4 & -1 &  1 &  0.378 &  0.123 & -0.139 &  1.816 &  0.374-0.052j & -0.030+0.120j &   4,-1 \\
  &   &  1 & -1 &  0.378 &  0.123 & -0.139 &  1.816 &  0.374-0.052j & -0.030+0.120j &    4,1 \\
  & 5 & -1 &  1 &  0.239 &  0.078 &  0.979 &  2.979 &  0.133+0.198j & -0.077+0.013j &   5,-1 \\
  &   &  1 & -1 &  0.239 &  0.078 &  0.979 &  2.979 &  0.133+0.198j & -0.077+0.013j &    5,1 \\
  & 6 & -1 &  1 &  0.439 &  0.143 &  0.515 &  1.374 &  0.382+0.216j &  0.028+0.141j &   6,-1 \\
  &   &  1 & -1 &  0.439 &  0.143 &  0.515 &  1.374 &  0.382+0.216j &  0.028+0.141j &    6,1 \\
  & 7 & -1 &  1 &  0.853 &  0.278 &  0.490 &  2.125 &  0.753+0.401j & -0.147+0.237j &   7,-1 \\
  &   &  1 & -1 &  0.853 &  0.278 &  0.490 &  2.125 &  0.753+0.401j & -0.147+0.237j &    7,1 \\
S & 0 &  0 &  0 &  0.752 &  0.246 &  0.161 &  1.826 &  0.742+0.121j & -0.062+0.238j &    0,0 \\
  & 1 &  0 &  0 &  0.305 &  0.100 &  0.966 &  2.965 &  0.173+0.251j & -0.098+0.017j &    1,0 \\
  & 2 &  0 &  0 &  0.860 &  0.281 &  0.177 &  1.348 &  0.847+0.151j &  0.062+0.274j &    2,0 \\
  & 3 &  0 &  0 &  0.954 &  0.312 &  0.380 &  1.875 &  0.886+0.354j & -0.093+0.297j &    3,0 \\
  & 4 &  0 &  0 &  0.615 &  0.201 &  0.095 &  1.810 &  0.612+0.058j & -0.048+0.195j &    4,0 \\
  & 5 &  0 &  0 &  0.402 &  0.131 &  1.237 &  1.739 &  0.132+0.380j & -0.022+0.129j &    5,0 \\
  & 6 &  0 &  0 &  0.455 &  0.149 &  0.763 &  1.402 &  0.329+0.314j &  0.025+0.146j &    6,0 \\
  & 7 &  0 &  0 &  1.098 &  0.359 &  0.494 &  2.156 &  0.967+0.521j & -0.198+0.299j &    7,0 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To set matrix elements from aggregate fit results, use `aggToXR` for Xarray}
\PYG{c+c1}{\PYGZsh{} data.aggToXR(refKey = \PYGZsq{}orb5\PYGZsq{}, returnType = \PYGZsq{}ds\PYGZsq{}, conformDims=True)   \PYGZsh{} use full ref dataset}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{aggToXR}\PYG{p}{(}\PYG{n}{refKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{returnType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{conformDims}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Subselected matE}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Added dim Total
Added dim Targ
Added dim Total
Added dim Targ
Set XR dataset for self.data[\PYGZsq{}agg\PYGZsq{}][\PYGZsq{}matE\PYGZsq{}]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Density matrices}
\label{\detokenize{part2/case-study-OCS_290723:density-matrices}}
\sphinxAtStartPar
New (experimental) code for density matrix plots and comparison. See \hyperref[\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}]{Sect.\@ \ref{\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}}} for discussion. Code adapted from the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html\#Density-matrix-plotting}{MF reconstruction page}, original analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case. If the reconstruction is good, the differences (fidelity) should be on the order of the experimental noise level/reconstruction uncertainty, around 10\% in the case studies herein; in general the values and patterns of the matrices can also indicate aspects of the retrieval that worked well, or areas where values are poorly defined/recovered from the given dataset.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{3d2333ab161f2f4815c9ec09d01f773dc6fd1ad0fb1c785aba7f9282b25de8f3}.png}
\caption{Density matrix comparison \sphinxhyphen{} rows show (a) reference case (with signs of phases removed), (b) reconstructed case, (c) differences. Columns are (left) imaginary component, (right) real component. If the reconstruction is good, the differences (fidelity) should be on the order of the experimental noise level/reconstruction uncertainty, around 10\% in the case studies herein.}\label{\detokenize{part2/case-study-OCS_290723:fig-ocs-densitycomp}}\end{figure}


\subsection{Plot MF PADs}
\label{\detokenize{part2/case-study-OCS_290723:plot-mf-pads}}
\sphinxAtStartPar
Routines below adapted from the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/MFPAD\_replotting\_from\_file\_190722-dist.html}{MF reconstruction data processing page} (original analysis page for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case). The routines include calls to \sphinxcode{\sphinxupquote{self.mfpadNumeric()}} for numerical expansion of the MF\sphinxhyphen{}PADs, and \sphinxcode{\sphinxupquote{self.padPlot()}} for plotting. Results are illustrated for the retrieved and reference cases in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-compc}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-compc}}} and \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-ref}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-ref}}} respectively, and the differential results (reference minus fitted results) in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-diff}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{74f35eb34e8860b9113a4afb773246ef1491e113d89fb94750cfb6c808c0205d}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} computed from retrieved matrix elements for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis.}\label{\detokenize{part2/case-study-OCS_290723:fig-ocs-compc}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{81f46e104b594deb8a9622e6ef1151b5411037015a3f180aea45cca12cdf2f44}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} computed from reference \sphinxstyleemphasis{ab initio} matrix elements for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis.}\label{\detokenize{part2/case-study-OCS_290723:fig-ocs-ref}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{0301529d9b8bc7d083c7b3e3cc459a63cfc789cdff0034c1c3dfb38b15bf5a96}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} differences between retrieved and reference cases for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis. Note diffs are normalised to emphasize the shape, but not mangnitudes, of the differences \sphinxhyphen{} see the density matrix comparisons for a more rigourous fidelity analysis.}\label{\detokenize{part2/case-study-OCS_290723:fig-ocs-diff}}\end{figure}

\sphinxstepscope


\chapter{Case study: Generalised bootstrapping for a general asymmetric top scattering system, \protect\(C_2H_4~(D_{2h})\protect\)}
\label{\detokenize{part2/case-study-C2H4_290723:case-study-generalised-bootstrapping-for-a-general-asymmetric-top-scattering-system-c-2h-4-d-2h}}\label{\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}}\label{\detokenize{part2/case-study-C2H4_290723::doc}}
\sphinxAtStartPar
In this chapter, the full code and analysis details of the case study for \(C_2H_4\) are given, including obtaining required data, running fits and analysis routines. For more details on the routines, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}; for the analysis see particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_analysis\_demo\_150621-tidy.html}{fit fidelity and analysis page}, and \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html}{molecular frame analysis data processing page} (full analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case).


\section{General setup}
\label{\detokenize{part2/case-study-C2H4_290723:general-setup}}
\sphinxAtStartPar
In the following code cells (see source notebooks for full details) the general setup routines (as per the outline in \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chpt.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}} are executed via a configuration script with presets for the case studies herein.

\sphinxAtStartPar
Additionally, the routines will either run fits, or load existing data if available. Since fitting can be computationally demanding, it is, in general, recommended to approach large fitting problems carefully.

\begin{sphinxShadowBox}
\sphinxstylesidebartitle{}

\begin{sphinxadmonition}{note}{General note on fitting}

\sphinxAtStartPar
Computational outputs in this chapter are significantly truncated in the PDF, and some simplified plots are used; see source notebooks (via \sphinxhref{https://github.com/phockett/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (Github repo)}) or \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)} for full details.
\end{sphinxadmonition}
\end{sphinxShadowBox}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Configure settings for case study}

\PYG{c+c1}{\PYGZsh{} Set case study by name}
\PYG{n}{fitSystem}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C2H4}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{fitStem}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Add noise?}
\PYG{n}{addNoise} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{y}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.05}  \PYG{c+c1}{\PYGZsh{} Up to approx 10\PYGZpc{} noise (+/\PYGZhy{} 0.05)}

\PYG{c+c1}{\PYGZsh{} Batching \PYGZhy{} number of fits to run between data dumps}
\PYG{n}{batchSize} \PYG{o}{=} \PYG{l+m+mi}{10}

\PYG{c+c1}{\PYGZsh{} Total fits to run}
\PYG{n}{nMax} \PYG{o}{=} \PYG{l+m+mi}{10}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Pull data from web (C2H4 case)}
\PYG{k+kn}{from} \PYG{n+nn}{epsproc}\PYG{n+nn}{.}\PYG{n+nn}{util}\PYG{n+nn}{.}\PYG{n+nn}{io} \PYG{k+kn}{import} \PYG{n}{getFilesFromGithub}

\PYG{c+c1}{\PYGZsh{} Set dataName (will be used as download subdir)}
\PYG{n}{dataName} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C2H4fitting}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{c+c1}{\PYGZsh{} C2H4 matrix elements}
\PYG{n}{GHbranch}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{3d\PYGZhy{}AFPAD\PYGZhy{}dev}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{fDictMatE}\PYG{p}{,} \PYG{n}{fAllMatE} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/photoionization/C2H4}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{,} \PYG{n}{ref}\PYG{o}{=}\PYG{n}{GHbranch}\PYG{p}{)} 
\PYG{c+c1}{\PYGZsh{} C2H4 alignment data}
\PYG{n}{fDictADM}\PYG{p}{,} \PYG{n}{fAllADM} \PYG{o}{=} \PYG{n}{getFilesFromGithub}\PYG{p}{(}\PYG{n}{subpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data/alignment/C2H4\PYGZus{}ADMs\PYGZus{}8TW\PYGZus{}120fs\PYGZus{}VM}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dataName}\PYG{o}{=}\PYG{n}{dataName}\PYG{p}{,} \PYG{n}{ref}\PYG{o}{=}\PYG{n}{GHbranch}\PYG{p}{)} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/photoionization/C2H4?ref=3d\PYGZhy{}AFPAD\PYGZhy{}dev
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}1.0\PYGZhy{}100.0eV\PYGZus{}orb8\PYGZus{}B3u.inp.out already exists
Querying URL: https://api.github.com/repos/phockett/epsproc/contents/data/alignment/C2H4\PYGZus{}ADMs\PYGZus{}8TW\PYGZus{}120fs\PYGZus{}VM?ref=3d\PYGZhy{}AFPAD\PYGZhy{}dev
Local file /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/ADMs\PYGZus{}8TW\PYGZus{}120fs\PYGZus{}5K.mat already exists
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fitting setup including data generation and parameter creation}

\PYG{c+c1}{\PYGZsh{} Set datapath, }
\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{Path}\PYG{p}{(}\PYG{n}{Path}\PYG{o}{.}\PYG{n}{cwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{dataName}\PYG{p}{)}
\PYG{n}{ADMfile} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ADMs\PYGZus{}8TW\PYGZus{}120fs\PYGZus{}5K.mat}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Run general config script with dataPath set above}
\PYG{o}{\PYGZpc{}}\PYG{k}{run} \PYGZdq{}../scripts/setup\PYGZus{}fit\PYGZus{}case\PYGZhy{}studies\PYGZus{}270723.py\PYGZdq{} \PYGZhy{}d \PYGZob{}dataPath\PYGZcb{} \PYGZhy{}a \PYGZob{}ADMfile\PYGZcb{} \PYGZhy{}c \PYGZob{}fitSystem\PYGZcb{} \PYGZhy{}n \PYGZob{}addNoise\PYGZcb{} \PYGZhy{}\PYGZhy{}sigma \PYGZob{}sigma\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Load existing fit data or run fits}
\label{\detokenize{part2/case-study-C2H4_290723:load-existing-fit-data-or-run-fits}}
\sphinxAtStartPar
Note that running fits may be quite time\sphinxhyphen{}consuming and computationally intensive, depending on the size of the size of the problem. The default case here will run a small batch for testing if there is no existing data found on the \sphinxcode{\sphinxupquote{dataPath}}, otherwise the data is loaded for analysis.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Look for existing Pickle files on path}
\PYG{n}{dataFiles} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{dataPath}\PYG{o}{.}\PYG{n}{expanduser}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{glob}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{*.pickle}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{if} \PYG{o+ow}{not} \PYG{n}{dataFiles}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{No data found, executing minimal fitting run...}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} Run fit batch \PYGZhy{} single}
    \PYG{c+c1}{\PYGZsh{} data.multiFit(nRange = [n,n+batchSize\PYGZhy{}1], num\PYGZus{}workers=batchSize)}

    \PYG{c+c1}{\PYGZsh{} Run fit batches with checkpoint files}
    \PYG{k}{for} \PYG{n}{n} \PYG{o+ow}{in} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{nMax}\PYG{p}{,}\PYG{n}{batchSize}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{*** Running batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{], }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{now}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strftime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{m}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{y\PYGZus{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{H\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{M\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{S}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Run fit batch}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{multiFit}\PYG{p}{(}\PYG{n}{nRange} \PYG{o}{=} \PYG{p}{[}\PYG{n}{n}\PYG{p}{,}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{num\PYGZus{}workers}\PYG{o}{=}\PYG{n}{batchSize}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Dump data so far}
        \PYG{n}{data}\PYG{o}{.}\PYG{n}{writeFitData}\PYG{p}{(}\PYG{n}{outStem}\PYG{o}{=}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitSystem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitStem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
        
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Finished batch [}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{,}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{], }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{now}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{strftime}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}d}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{m}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{y\PYGZus{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{H\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{M\PYGZhy{}}\PYG{l+s+s2}{\PYGZpc{}}\PYG{l+s+s2}{S}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
        \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Written to file }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitSystem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{n}\PYG{o}{+}\PYG{n}{batchSize}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZus{}}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{fitStem}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{k}{else}\PYG{p}{:}
    \PYG{n}{dataFileIn} \PYG{o}{=} \PYG{n}{dataFiles}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}   \PYG{c+c1}{\PYGZsh{} Add index to select file, although loadFitData will concat multiple files}
                                    \PYG{c+c1}{\PYGZsh{} Note that concat currently only works for fixed batch sizes however.}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Set dataFiles: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{dataFileIn}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{loadFitData}\PYG{p}{(}\PYG{n}{fList}\PYG{o}{=}\PYG{n}{dataFileIn}\PYG{p}{,} \PYG{n}{dataPath}\PYG{o}{=}\PYG{n}{dataPath}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{}.expanduser())}
    
    \PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMfitPlot}\PYG{p}{(}\PYG{n}{keys}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sim}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
    
    \PYG{c+c1}{\PYGZsh{} \PYGZsh{} Check ADMs}
    \PYG{c+c1}{\PYGZsh{} data.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}ADM\PYGZsq{}].unstack().where(data.data[\PYGZsq{}subset\PYGZsq{}][\PYGZsq{}ADM\PYGZsq{}].unstack().K\PYGZgt{}0) \PYGZbs{}}
    \PYG{c+c1}{\PYGZsh{}     .real.hvplot.line(x=\PYGZsq{}t\PYGZsq{}).overlay([\PYGZsq{}K\PYGZsq{},\PYGZsq{}Q\PYGZsq{},\PYGZsq{}S\PYGZsq{}])}
    
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set dataFiles: /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}399\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8\PYGZus{}270723\PYGZus{}13\PYGZhy{}45\PYGZhy{}22.pickle
Read data from /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}399\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8\PYGZus{}270723\PYGZus{}13\PYGZhy{}45\PYGZhy{}22.pickle with pickle.
Dataset: subset, AFBLM
Dataset: sim, AFBLM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{43a348ebd8201a0ba85d4235fd1f3db089e5b94e280f4a84f10331df5e881c4e}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check ADMs}
\PYG{c+c1}{\PYGZsh{} Basic plotter}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{ADMplot}\PYG{p}{(}\PYG{n}{keys} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dataset: subset, ADM
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{86d22f01cff16e5cbd69f2fe3bc4daa813f801c1c999e228c440b6f4e1906e3a}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fits appear as integer indexed items in the main data structure.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Post\sphinxhyphen{}processing and data overview}
\label{\detokenize{part2/case-study-C2H4_290723:post-processing-and-data-overview}}
\sphinxAtStartPar
Post\sphinxhyphen{}processing involves aggregation of all the fit run results into a single data structure. This can then be analysed statistically and examined for for best\sphinxhyphen{}fit results. In the statistical sense, this is essentailly a search for candidate {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, based on the assumption that some of the minima found in the \(\chi^2\) hyperspace will be the true results. Even if a clear global minima does not exist, searching for candidate {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} sets based on clustering of results and multiple local minima is still expected to lead to viable candidates provided that the information content of the dataset is sufficient. However, as discussed elsewhere (see \hyperref[\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}]{Sect.\@ \ref{\detokenize{part1/numerics_070723:sect-numerics-fitting-strategies}}}), in some cases this may not be the case, and other limitations may apply (e.g. certain parameters may be undefined), or additional data required for unique determination of the {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}.

\sphinxAtStartPar
For more details on the analysis routines, see the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_analysis\_demo\_150621-tidy.html}{fit fidelity and analysis page}, and \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html}{molecular frame analysis data processing page} (full analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case).

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} General stats \PYGZam{} post\PYGZhy{}processing to data tables}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{analyseFits}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\PYGZob{} \PYGZsq{}Fits\PYGZsq{}: 390,
  \PYGZsq{}Minima\PYGZsq{}: \PYGZob{}\PYGZsq{}chisqr\PYGZsq{}: 5.901473330378771e\PYGZhy{}05, \PYGZsq{}redchi\PYGZsq{}: 8.901166410827708e\PYGZhy{}08\PYGZcb{},
  \PYGZsq{}Stats\PYGZsq{}: \PYGZob{} \PYGZsq{}chisqr\PYGZsq{}: min       5.901e\PYGZhy{}05
mean      2.760e\PYGZhy{}04
median    6.259e\PYGZhy{}05
max       3.133e\PYGZhy{}02
std       1.935e\PYGZhy{}03
var       3.746e\PYGZhy{}06
Name: chisqr, dtype: float64,
             \PYGZsq{}redchi\PYGZsq{}: min       8.901e\PYGZhy{}08
mean      4.164e\PYGZhy{}07
median    9.440e\PYGZhy{}08
max       4.726e\PYGZhy{}05
std       2.919e\PYGZhy{}06
var       8.521e\PYGZhy{}12
Name: redchi, dtype: float64\PYGZcb{},
  \PYGZsq{}Success\PYGZsq{}: 390\PYGZcb{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} The BLMsetPlot routine will output aggregate fit results.}
\PYG{c+c1}{\PYGZsh{} Here the spread can be taken as a general indication of the uncertainty of }
\PYG{c+c1}{\PYGZsh{} the fitting, and indicate whether the fit is well\PYGZhy{}characterised/the information }
\PYG{c+c1}{\PYGZsh{} content of the data is sufficient.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{BLMsetPlot}\PYG{p}{(}\PYG{n}{xDim} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{t}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}6}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} With xDim and thres set, for more control over outputs}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{C2H4\PYGZhy{}fitResultsBLM}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{BLMsetPlot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{efdd5a1dce75ba279f67639ce1e490463cc5fce5bc9fd0f2ec02123a8feeefb8}.png}
\caption{Fit overview plot \sphinxhyphen{} \(\beta_{L,M}(t)\). Here dashed lines with ‘+’ markers indicates the input data, and bands indicate the mean fit results, where the width is the standard deviation in the fit model results. (See the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} for details, particularly the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_multiproc\_class\_analysis\_141121-tidy.html\#Fit-set-plotters}{analysis routines page}.)}\label{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-fitresultsblm}}\end{figure}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Write aggregate datasets to HDF5 format}
\PYG{c+c1}{\PYGZsh{} This is more robust than Pickled data, but PEMtk currently only support output for aggregate (post\PYGZhy{}processed) fit data.}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{processedToHDF5}\PYG{p}{(}\PYG{n}{dataPath} \PYG{o}{=} \PYG{n}{dataPath}\PYG{p}{,} \PYG{n}{outStem} \PYG{o}{=} \PYG{n}{dataFileIn}\PYG{o}{.}\PYG{n}{name}\PYG{p}{,} \PYG{n}{timeStamp}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Dumped self.data[fits][dfLong] to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}399\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8\PYGZus{}270723\PYGZus{}13\PYGZhy{}45\PYGZhy{}22.pickle\PYGZus{}dfLong.pdHDF with Pandas .to\PYGZus{}hdf() routine.
Dumped data to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}399\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8\PYGZus{}270723\PYGZus{}13\PYGZhy{}45\PYGZhy{}22.pickle\PYGZus{}dfLong.pdHDF with pdHDF.
Dumped self.data[fits][AFxr] to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}399\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8\PYGZus{}270723\PYGZus{}13\PYGZhy{}45\PYGZhy{}22.pickle\PYGZus{}AFxr.pdHDF with Pandas .to\PYGZus{}hdf() routine.
Dumped data to /home/jovyan/jake\PYGZhy{}home/buildTmp/\PYGZus{}latest\PYGZus{}build/pdf/doc\PYGZhy{}source/part2/C2H4fitting/C2H4\PYGZus{}399\PYGZus{}fit\PYGZus{}3D\PYGZhy{}test\PYGZus{}withNoise\PYGZus{}orb8\PYGZus{}270723\PYGZus{}13\PYGZhy{}45\PYGZhy{}22.pickle\PYGZus{}AFxr.pdHDF with pdHDF.
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Histogram fit results (reduced chi\PYGZca{}2 vs. fit index)}
\PYG{c+c1}{\PYGZsh{} This may be quite slow for large datasets, setting limited ranges may help}

\PYG{c+c1}{\PYGZsh{} Use default auto binning}
\PYG{c+c1}{\PYGZsh{} data.fitHist()}

\PYG{c+c1}{\PYGZsh{} Example with range set}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{fitHist}\PYG{p}{(}\PYG{n}{thres}\PYG{o}{=}\PYG{l+m+mf}{3e\PYGZhy{}7}\PYG{p}{,} \PYG{n}{bins}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Glue plot for later}
\PYG{n}{glue}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{C2H4\PYGZhy{}fitHist}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plots}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fitHistPlot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Mask selected 361 results (from 390).
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
:AdjointLayout
   :Scatter   [redchi]   (Fit)
   :Histogram   [Fit]   (Fit\PYGZus{}count)
   :Histogram   [redchi]   (redchi\PYGZus{}count)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{4fc302d849399a85bd82ecbaadfba121f304a9c8fcbec0606abef8df757be498}.png}
\caption{Fit overview plot \sphinxhyphen{} \(\chi^2\) vs. fit index. Here bands indicate groupings (local minima) are consistently found.}\label{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-fithist}}\end{figure}

\sphinxAtStartPar
Here, \hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-fitresultsblm}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-fitresultsblm}}} shows an overview of the results compared with the input data, and \hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-fithist}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-fithist}}} an overview of \(\chi^2\) vs. fit index. Bands in the \(\chi^2\) dimension can indicate groupings (local minima) are consistently found. Assuming each grouping is a viable fit candidate parameter set, these can then be explored in further detail.


\section{Data exploration}
\label{\detokenize{part2/case-study-C2H4_290723:data-exploration}}
\sphinxAtStartPar
The general aim in this procedure is to ascertain whether there was a good spread of parameters explored, and a single (or few sets) of best\sphinxhyphen{}fit results. There are a few procedures and helper methods for this…


\subsection{View results}
\label{\detokenize{part2/case-study-C2H4_290723:view-results}}
\sphinxAtStartPar
Single results sets can be viewed in the main data structure, indexed by integers.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check keys}
\PYG{n}{fitNumber} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{fitNumber}\PYG{p}{]}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
dict\PYGZus{}keys([\PYGZsq{}AFBLM\PYGZsq{}, \PYGZsq{}residual\PYGZsq{}, \PYGZsq{}results\PYGZsq{}])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Here \sphinxcode{\sphinxupquote{results}} is an \sphinxhref{https://lmfit.github.io/lmfit-py/intro.html}{lmFit object}, which includes final fit results and information, and \sphinxcode{\sphinxupquote{AFBLM}} contains the model (fit) output (i.e. resultant AF\sphinxhyphen{}\(\beta_{LM}\) values).

\sphinxAtStartPar
An example is shown below. Of particular note here is which parameters have \sphinxcode{\sphinxupquote{vary=True}} \sphinxhyphen{} these are included in the fitting \sphinxhyphen{} and if there is a column \sphinxcode{\sphinxupquote{expression}}, which indicates any parameters defined to have specific relationships (see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}}). Any correlations found during fitting are also shown, which can also indicate parameters which are related (even if this is not predefined or known a priori).

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Show some results}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{fitNumber}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{results}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Classify candidate sets}
\label{\detokenize{part2/case-study-C2H4_290723:classify-candidate-sets}}
\sphinxAtStartPar
To probe the minima found, the \sphinxcode{\sphinxupquote{classifyFits}} method can be used. This bins results into “candidate” groups, which can then be examined in detail.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run with defaults}
\PYG{c+c1}{\PYGZsh{} data.classifyFits()}

\PYG{c+c1}{\PYGZsh{} For more control, pass bins}
\PYG{c+c1}{\PYGZsh{} Here the minima is set at one end, and a \PYGZpc{}age range used for bins}
\PYG{n}{minVal} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{fitsSummary}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Stats}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{min}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}    
\PYG{n}{binRangePC} \PYG{o}{=} \PYG{l+m+mf}{1e\PYGZhy{}5}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{classifyFits}\PYG{p}{(}\PYG{n}{bins} \PYG{o}{=} \PYG{p}{[}\PYG{n}{minVal}\PYG{p}{,} \PYG{n}{minVal} \PYG{o}{+} \PYG{n}{binRangePC}\PYG{o}{*}\PYG{n}{minVal} \PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllllllllllll}
\toprule
{} & \multicolumn{4}{l}{success} & \multicolumn{4}{l}{chisqr} & \multicolumn{4}{l}{redchi} \\
{} &   count & unique &   top & freq &  count & unique &  top & freq &  count & unique &  top & freq \\
redchiGroup &         &        &       &      &        &        &      &      &        &        &      &      \\
\midrule
A           &       5 &      1 &  True &    5 &    5.0 &    5.0 &  0.0 &  1.0 &    5.0 &    5.0 &  0.0 &  1.0 \\
B           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
C           &       3 &      1 &  True &    3 &    3.0 &    3.0 &  0.0 &  1.0 &    3.0 &    3.0 &  0.0 &  1.0 \\
D           &       3 &      1 &  True &    3 &    3.0 &    3.0 &  0.0 &  1.0 &    3.0 &    3.0 &  0.0 &  1.0 \\
E           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
F           &       1 &      1 &  True &    1 &    1.0 &    1.0 &  0.0 &  1.0 &    1.0 &    1.0 &  0.0 &  1.0 \\
G           &       1 &      1 &  True &    1 &    1.0 &    1.0 &  0.0 &  1.0 &    1.0 &    1.0 &  0.0 &  1.0 \\
H           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
I           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
J           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
K           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
L           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
M           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
N           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
O           &       1 &      1 &  True &    1 &    1.0 &    1.0 &  0.0 &  1.0 &    1.0 &    1.0 &  0.0 &  1.0 \\
P           &       1 &      1 &  True &    1 &    1.0 &    1.0 &  0.0 &  1.0 &    1.0 &    1.0 &  0.0 &  1.0 \\
Q           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
R           &       2 &      1 &  True &    2 &    2.0 &    2.0 &  0.0 &  1.0 &    2.0 &    2.0 &  0.0 &  1.0 \\
S           &       0 &      0 &   NaN &  NaN &      0 &      0 &  NaN &  NaN &      0 &      0 &  NaN &  NaN \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{d459d538ceb286e85ffb5819f4863634bf6aa92c76eb0a98c3d51a9b03493ad2}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Explore candidate result sets}
\label{\detokenize{part2/case-study-C2H4_290723:explore-candidate-result-sets}}
\sphinxAtStartPar
Drill\sphinxhyphen{}down on a candidate set of results, and examine values and spreads. For more details see \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}, especially the \sphinxhref{https://pemtk.readthedocs.io/en/latest/fitting/PEMtk\_fitting\_multiproc\_class\_analysis\_141121-tidy.html}{analysis routines page}. (See also \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}]{Sect.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-pythonecosystem}}} for details on the plotting libaries implemented here.)


\subsection{Raw results}
\label{\detokenize{part2/case-study-C2H4_290723:raw-results}}
\sphinxAtStartPar
Plot spreads in magnitude and phase parameters. Statistical plots are available for Seaborn and Holoviews backends, with some slightly different options.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} From the candidates, select a group for analysis}
\PYG{n}{selGroup} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A}\PYG{l+s+s1}{\PYGZsq{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} paramPlot can be used to check the spread on each parameter.}
\PYG{c+c1}{\PYGZsh{} Plots use Seaborn or Holoviews/Bokeh}
\PYG{c+c1}{\PYGZsh{} Colour\PYGZhy{}mapping is controlled by the \PYGZsq{}hue\PYGZsq{} paramter, additionally pass hRound for sig. fig control.}
\PYG{c+c1}{\PYGZsh{} The remap setting allows for short\PYGZhy{}hand labels as set in data.lmmu}

\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{m}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Set for (m)agnitude or (p)hase parameters}
\PYG{n}{hRound} \PYG{o}{=} \PYG{l+m+mi}{14} \PYG{c+c1}{\PYGZsh{} Set for cmapping, default may be too small (leads to all grey cmap on points)}

\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f04a842a140\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{a041bef482d90dc0e7d761915fbfcac083409405bcbaef47f1913f36d81878a8}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{p}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} Set for (m)agnitude or (p)hase parameters}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;} 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f04a82a8910\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{49d401fa47ca97182795db0adbb92d902f46322d109a95b4af101b07d6411eb1}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Phases, phase shifts \& corrections}
\label{\detokenize{part2/case-study-C2H4_290723:phases-phase-shifts-corrections}}
\sphinxAtStartPar
Depending on how the fit was configured, phases may be defined in different ways. To set the phases relative to a speific parameter, and wrap to a specified range, use the \sphinxcode{\sphinxupquote{phaseCorrection()}} method. This defaults to using the first parameter as a reference phase, and wraps to \(-\pi:\pi\). The phase\sphinxhyphen{}corrected values are output to a new Type, ‘pc’, and a set of normalised magnitudes to ‘n’. Additional settings can be passed for more control, as shown below.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run phase correction routine}
\PYG{c+c1}{\PYGZsh{} Set absFlag=True for unsigned phases (mapped to 0:pi)}
\PYG{c+c1}{\PYGZsh{} Set useRef=False to set ref phase as 0, otherwise the reference value is set.}
\PYG{n}{phaseCorrParams}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{absFlag}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{k+kc}{True}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{useRef}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{k+kc}{False}\PYG{p}{\PYGZcb{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{phaseCorrection}\PYG{p}{(}\PYG{o}{*}\PYG{o}{*}\PYG{n}{phaseCorrParams}\PYG{p}{)}  
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Examine new data types…

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{kind}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{box}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f04a842a140\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{0dd81e21bbfc51b88933f6970a9ab635aec846e2911b4bc17cfca7385317a5d9}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{paramType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pc}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramPlot}\PYG{p}{(}\PYG{n}{selectors}\PYG{o}{=}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{paramType}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{,} \PYG{n}{hue} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} 
               \PYG{n}{backend}\PYG{o}{=}\PYG{n}{paramPlotBackend}\PYG{p}{,} \PYG{n}{hvType}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{violin}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{kind}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{box}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
               \PYG{n}{returnFlag} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{hRound}\PYG{o}{=}\PYG{n}{hRound}\PYG{p}{,} \PYG{n}{remap} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
*** Warning: found MultiIndex for DataFrame data.index \PYGZhy{} checkDims may have issues with Pandas MultiIndex, but will try anyway.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}seaborn.axisgrid.FacetGrid at 0x7f04a8333d00\PYGZgt{}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{e6f57d7946ffde2d3c75ce3ff29ae4f2a63501ce5eafccef1e7e86073cee7704}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Parameter estimation \& fidelity}
\label{\detokenize{part2/case-study-C2H4_290723:parameter-estimation-fidelity}}
\sphinxAtStartPar
For case studies, the fit results can be directly compared to the known input parameters. This should give a feel for how well the data defines the matrix elements (parameters) in this case. In general, probing the correlations and spread of results, and comparing to other (unfitted) results is required to estimate fidelity, see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} for further discussion.


\subsection{Best values and statistics}
\label{\detokenize{part2/case-study-C2H4_290723:best-values-and-statistics}}
\sphinxAtStartPar
To get a final parameter set and associated statistics, based on a subset of the fit results, the \sphinxcode{\sphinxupquote{paramsReport()}} method is available. If reference data is available, as for the case studies herein, the \sphinxcode{\sphinxupquote{paramsCompare()}} method can also be used to compare with the reference case.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Parameter summary}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsReport}\PYG{p}{(}\PYG{n}{inds} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{redchiGroup}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{n}{selGroup}\PYG{p}{\PYGZcb{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Parameter comparison}
\PYG{c+c1}{\PYGZsh{} Note this uses phaseCorrParams as set previously for consistency}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsCompare}\PYG{p}{(}\PYG{n}{phaseCorrParams}\PYG{o}{=}\PYG{n}{phaseCorrParams}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Display above results With column name remapping to (l,m) labels only}

\PYG{c+c1}{\PYGZsh{} With Pandas functionality}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsSummaryComp}\PYG{o}{.}\PYG{n}{rename}\PYG{p}{(}\PYG{n}{columns}\PYG{o}{=}\PYG{n}{data}\PYG{o}{.}\PYG{n}{lmmu}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{lmMap}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} With utility method}
\PYG{c+c1}{\PYGZsh{} summaryRenamed = pemtk.fit.\PYGZus{}util.renameParams(data.paramsSummaryComp, data.lmmu[\PYGZsq{}lmMap\PYGZsq{}]) }
\PYG{c+c1}{\PYGZsh{} summaryRenamed}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lllrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}
\toprule
   &          & Param &      0,0 &      0,0 &      2,0 &      2,0 &      2,2 &      2,2 &     2,-2 &     2,-2 &      4,0 &      4,0 &      4,2 &      4,2 &       4,4 &      4,4 &     4,-2 &     4,-2 &      4,-4 &     4,-4 &       6,0 &      6,0 &      2,2 &      2,2 &     2,-2 &     2,-2 &      4,2 &      4,2 &       4,4 &       4,4 &     4,-2 &     4,-2 &      4,-4 &      4,-4 &      2,1 &     2,-1 &      4,1 &      4,3 &     4,-1 &     4,-3 \\
Type & Source & dType &          &          &          &          &          &          &          &          &          &          &          &          &           &          &          &          &           &          &           &          &          &          &          &          &          &          &           &           &          &          &           &           &          &          &          &          &          &          \\
\midrule
m & mean & num &    1.179 &    1.179 &    0.859 &    0.859 &    1.635 &    1.635 &    1.635 &    1.635 &    0.756 &    0.756 &    0.539 &    0.539 &     0.765 &    0.765 &    0.539 &    0.539 &     0.765 &    0.765 &     1.127 &    1.127 &    0.993 &    0.993 &    0.993 &    0.993 &    0.127 &    0.127 &     0.326 &     1.295 &    0.127 &    0.127 &     0.326 &     0.326 &    0.788 &    0.788 &    0.457 &    0.837 &    0.457 &    0.837 \\
   & ref & num &    1.366 &    1.366 &    1.299 &    1.299 &    1.386 &    1.386 &    1.386 &    1.386 &    0.400 &    0.400 &    0.300 &    0.300 &     0.050 &    0.050 &    0.300 &    0.300 &     0.050 &    0.050 &     0.013 &    0.013 &    1.563 &    1.563 &    1.563 &    1.563 &    0.154 &    0.154 &     0.035 &     0.035 &    0.154 &    0.154 &     0.035 &     0.035 &    0.521 &    0.521 &    0.162 &    0.074 &    0.162 &    0.074 \\
   & diff & \% &   15.900 &   15.900 &   51.143 &   51.143 &   15.198 &   15.198 &   15.198 &   15.198 &   47.063 &   47.063 &   44.338 &   44.338 &    93.490 &   93.490 &   44.338 &   44.338 &    93.490 &   93.490 &    98.811 &   98.811 &   57.489 &   57.489 &   57.489 &   57.489 &   20.847 &   20.847 &    89.145 &    97.270 &   20.847 &   20.847 &    89.145 &    89.145 &   33.939 &   33.939 &   64.476 &   91.112 &   64.476 &   91.112 \\
   &          & num &   -0.187 &   -0.187 &   -0.439 &   -0.439 &    0.248 &    0.248 &    0.248 &    0.248 &    0.356 &    0.356 &    0.239 &    0.239 &     0.716 &    0.716 &    0.239 &    0.239 &     0.716 &    0.716 &     1.114 &    1.114 &   -0.571 &   -0.571 &   -0.571 &   -0.571 &   -0.027 &   -0.027 &     0.290 &     1.260 &   -0.027 &   -0.027 &     0.290 &     0.290 &    0.267 &    0.267 &    0.295 &    0.762 &    0.295 &    0.762 \\
   & std & \% &   85.738 &   85.738 &   79.694 &   79.694 &   10.684 &   10.684 &   10.684 &   10.684 &   76.209 &   76.209 &  129.566 &  129.566 &   106.113 &  106.113 &  129.566 &  129.566 &   106.113 &  106.113 &    53.719 &   53.719 &   88.014 &   88.014 &   88.014 &   88.014 &  175.285 &  175.285 &   124.290 &    63.182 &  175.285 &  175.285 &   124.290 &   124.290 &   62.750 &   62.750 &   67.565 &   84.633 &   67.565 &   84.633 \\
   &          & num &    1.011 &    1.011 &    0.685 &    0.685 &    0.175 &    0.175 &    0.175 &    0.175 &    0.576 &    0.576 &    0.698 &    0.698 &     0.812 &    0.812 &    0.698 &    0.698 &     0.812 &    0.812 &     0.605 &    0.605 &    0.874 &    0.874 &    0.874 &    0.874 &    0.223 &    0.223 &     0.405 &     0.818 &    0.223 &    0.223 &     0.405 &     0.405 &    0.494 &    0.494 &    0.309 &    0.708 &    0.309 &    0.708 \\
   & diff/std & \% &   18.545 &   18.545 &   64.173 &   64.173 &  142.256 &  142.256 &  142.256 &  142.256 &   61.755 &   61.755 &   34.220 &   34.220 &    88.104 &   88.104 &   34.220 &   34.220 &    88.104 &   88.104 &   183.942 &  183.942 &   65.319 &   65.319 &   65.319 &   65.319 &   11.893 &   11.893 &    71.723 &   153.953 &   11.893 &   11.893 &    71.723 &    71.723 &   54.086 &   54.086 &   95.429 &  107.655 &   95.429 &  107.655 \\
n & mean & num &    0.187 &    0.187 &    0.130 &    0.130 &    0.254 &    0.254 &    0.254 &    0.254 &    0.124 &    0.124 &    0.075 &    0.075 &     0.124 &    0.124 &    0.075 &    0.075 &     0.124 &    0.124 &     0.166 &    0.166 &    0.139 &    0.139 &    0.139 &    0.139 &    0.022 &    0.022 &     0.048 &     0.198 &    0.022 &    0.022 &     0.048 &     0.048 &    0.128 &    0.128 &    0.067 &    0.121 &    0.067 &    0.121 \\
   & ref & num &    0.268 &    0.268 &    0.255 &    0.255 &    0.272 &    0.272 &    0.272 &    0.272 &    0.079 &    0.079 &    0.059 &    0.059 &     0.010 &    0.010 &    0.059 &    0.059 &     0.010 &    0.010 &     0.003 &    0.003 &    0.307 &    0.307 &    0.307 &    0.307 &    0.030 &    0.030 &     0.007 &     0.007 &    0.030 &    0.030 &     0.007 &     0.007 &    0.102 &    0.102 &    0.032 &    0.015 &    0.032 &    0.015 \\
   & diff & \% &   43.240 &   43.240 &   95.963 &   95.963 &    6.979 &    6.979 &    6.979 &    6.979 &   36.651 &   36.651 &   21.732 &   21.732 &    92.098 &   92.098 &   21.732 &   21.732 &    92.098 &   92.098 &    98.419 &   98.419 &  120.398 &  120.398 &  120.398 &  120.398 &   34.531 &   34.531 &    85.449 &    96.489 &   34.531 &   34.531 &    85.449 &    85.449 &   19.929 &   19.929 &   52.096 &   87.952 &   52.096 &   87.952 \\
   &          & num &   -0.081 &   -0.081 &   -0.125 &   -0.125 &   -0.018 &   -0.018 &   -0.018 &   -0.018 &    0.045 &    0.045 &    0.016 &    0.016 &     0.114 &    0.114 &    0.016 &    0.016 &     0.114 &    0.114 &     0.164 &    0.164 &   -0.168 &   -0.168 &   -0.168 &   -0.168 &   -0.008 &   -0.008 &     0.041 &     0.191 &   -0.008 &   -0.008 &     0.041 &     0.041 &    0.025 &    0.025 &    0.035 &    0.107 &    0.035 &    0.107 \\
   & std & \% &   88.166 &   88.166 &   76.703 &   76.703 &   18.057 &   18.057 &   18.057 &   18.057 &   78.802 &   78.802 &  121.307 &  121.307 &   111.570 &  111.570 &  121.307 &  121.307 &   111.570 &  111.570 &    40.666 &   40.666 &   80.492 &   80.492 &   80.492 &   80.492 &  179.484 &  179.484 &   113.665 &    63.960 &  179.484 &  179.484 &   113.665 &   113.665 &   71.017 &   71.017 &   54.975 &   78.110 &   54.975 &   78.110 \\
   &          & num &    0.165 &    0.165 &    0.100 &    0.100 &    0.046 &    0.046 &    0.046 &    0.046 &    0.098 &    0.098 &    0.091 &    0.091 &     0.138 &    0.138 &    0.091 &    0.091 &     0.138 &    0.138 &     0.068 &    0.068 &    0.112 &    0.112 &    0.112 &    0.112 &    0.040 &    0.040 &     0.054 &     0.126 &    0.040 &    0.040 &     0.054 &     0.054 &    0.091 &    0.091 &    0.037 &    0.095 &    0.037 &    0.095 \\
   & diff/std & \% &   49.044 &   49.044 &  125.111 &  125.111 &   38.647 &   38.647 &   38.647 &   38.647 &   46.511 &   46.511 &   17.915 &   17.915 &    82.547 &   82.547 &   17.915 &   17.915 &    82.547 &   82.547 &   242.015 &  242.015 &  149.579 &  149.579 &  149.579 &  149.579 &   19.239 &   19.239 &    75.176 &   150.859 &   19.239 &   19.239 &    75.176 &    75.176 &   28.062 &   28.062 &   94.763 &  112.600 &   94.763 &  112.600 \\
p & mean & num &    1.357 &   -2.978 &    1.648 &   -1.497 &   -0.357 &    0.413 &   -0.357 &    0.413 &    0.792 &    1.156 &    0.366 &    0.552 &    -0.060 &    1.382 &    0.366 &    0.552 &    -0.060 &    1.382 &     0.196 &    0.708 &    0.453 &    0.453 &    0.574 &    0.574 &   -1.190 &   -1.190 &    -0.260 &    -0.260 &    0.618 &    0.618 &     0.082 &     0.082 &    0.187 &    0.778 &   -0.706 &    0.273 &   -1.739 &   -0.442 \\
   & ref & num &    0.163 &   -2.978 &   -2.385 &    0.756 &    0.802 &   -2.340 &    0.802 &   -2.340 &    2.494 &   -0.647 &   -2.930 &    0.212 &    -0.102 &    3.040 &   -2.930 &    0.212 &    -0.102 &    3.040 &    -0.062 &    3.080 &   -2.149 &   -2.149 &    0.993 &    0.993 &    1.117 &    1.117 &    -3.104 &    -3.104 &   -2.025 &   -2.025 &     0.037 &     0.037 &   -0.646 &    2.495 &   -1.079 &   -1.168 &    2.063 &    1.974 \\
   & diff & \% &   87.971 &    0.000 &  244.712 &  150.525 &  324.612 &  666.272 &  324.612 &  666.272 &  214.888 &  156.011 &  900.498 &   61.663 &    69.605 &  119.952 &  900.498 &   61.663 &    69.605 &  119.952 &   131.377 &  334.739 &  574.256 &  574.256 &   72.786 &   72.786 &  193.803 &  193.803 &  1093.407 &  1093.407 &  427.780 &  427.780 &    54.802 &    54.802 &  445.431 &  220.565 &   52.709 &  528.291 &  218.631 &  546.921 \\
   &          & num &    1.194 &    0.000 &    4.033 &   -2.253 &   -1.159 &    2.753 &   -1.159 &    2.753 &   -1.702 &    1.803 &    3.296 &    0.341 &     0.042 &   -1.658 &    3.296 &    0.341 &     0.042 &   -1.658 &     0.258 &   -2.372 &    2.602 &    2.602 &   -0.418 &   -0.418 &   -2.307 &   -2.307 &     2.844 &     2.844 &    2.643 &    2.643 &     0.045 &     0.045 &    0.833 &   -1.717 &    0.372 &    1.441 &   -3.802 &   -2.415 \\
   & std & \% &  131.140 &    0.000 &   71.415 &  104.662 &  599.642 &  567.657 &  599.642 &  567.657 &  219.427 &  201.629 &  707.323 &  518.118 &  4536.492 &  105.037 &  707.323 &  518.118 &  4536.492 &  105.037 &  1338.858 &  299.192 &  384.006 &  384.006 &  399.792 &  399.792 &  181.782 &  181.782 &  1031.989 &  1031.989 &  392.707 &  392.707 &  2745.660 &  2745.660 &  882.005 &  278.258 &  197.085 &  941.927 &   76.940 &  409.308 \\
   &          & num &    1.780 &    0.000 &    1.177 &    1.567 &    2.140 &    2.346 &    2.140 &    2.346 &    1.738 &    2.331 &    2.589 &    2.862 &     2.724 &    1.452 &    2.589 &    2.862 &     2.724 &    1.452 &     2.625 &    2.120 &    1.740 &    1.740 &    2.297 &    2.297 &    2.164 &    2.164 &     2.684 &     2.684 &    2.426 &    2.426 &     2.260 &     2.260 &    1.650 &    2.166 &    1.392 &    2.569 &    1.338 &    1.808 \\
   & diff/std & \% &   67.082 &      NaN &  342.663 &  143.820 &   54.134 &  117.372 &   54.134 &  117.372 &   97.931 &   77.375 &  127.311 &   11.901 &     1.534 &  114.200 &  127.311 &   11.901 &     1.534 &  114.200 &     9.813 &  111.881 &  149.544 &  149.544 &   18.206 &   18.206 &  106.613 &  106.613 &   105.951 &   105.951 &  108.931 &  108.931 &     1.996 &     1.996 &   50.502 &   79.266 &   26.744 &   56.086 &  284.156 &  133.621 \\
pc & mean & num &    0.000 &    1.483 &    2.132 &    0.747 &    1.267 &    1.682 &    1.267 &    1.682 &    0.727 &    1.762 &    1.662 &    1.378 &     2.062 &    1.406 &    1.662 &    1.378 &     2.062 &    1.406 &     1.431 &    2.133 &    2.561 &    2.561 &    0.910 &    0.910 &    1.015 &    1.015 &     1.241 &     1.241 &    1.354 &    1.354 &     0.960 &     0.960 &    1.193 &    2.093 &    1.496 &    2.341 &    1.719 &    1.473 \\
   & ref & num &    0.000 &    3.142 &    2.548 &    0.593 &    0.639 &    2.503 &    0.639 &    2.503 &    2.331 &    0.811 &    3.093 &    0.049 &     0.265 &    2.877 &    3.093 &    0.049 &     0.265 &    2.877 &     0.225 &    2.917 &    2.312 &    2.312 &    0.829 &    0.829 &    0.953 &    0.953 &     3.016 &     3.016 &    2.188 &    2.188 &     0.126 &     0.126 &    0.810 &    2.332 &    1.242 &    1.331 &    1.900 &    1.810 \\
   & diff & \% &      NaN &  111.866 &   19.526 &   20.602 &   49.590 &   48.847 &   49.590 &   48.847 &  220.734 &   53.987 &   86.077 &   96.477 &    87.142 &  104.562 &   86.077 &   96.477 &    87.142 &  104.562 &    84.295 &   36.754 &    9.726 &    9.726 &    8.841 &    8.841 &    6.014 &    6.014 &   142.986 &   142.986 &   61.648 &   61.648 &    86.869 &    86.869 &   32.142 &   11.431 &   16.986 &   43.135 &   10.477 &   22.948 \\
   &          & num &    0.000 &   -1.659 &   -0.416 &    0.154 &    0.628 &   -0.821 &    0.628 &   -0.821 &   -1.604 &    0.951 &   -1.431 &    1.330 &     1.796 &   -1.470 &   -1.431 &    1.330 &     1.796 &   -1.470 &     1.206 &   -0.784 &    0.249 &    0.249 &    0.080 &    0.080 &    0.061 &    0.061 &    -1.775 &    -1.775 &   -0.834 &   -0.834 &     0.834 &     0.834 &    0.383 &   -0.239 &    0.254 &    1.010 &   -0.180 &   -0.338 \\
   & std & \% &      NaN &   82.832 &   34.350 &   80.295 &   70.160 &   60.024 &   70.160 &   60.024 &  106.441 &   62.469 &   48.294 &   98.847 &    61.086 &   64.292 &   48.294 &   98.847 &    61.086 &   64.292 &   106.173 &   36.913 &   18.593 &   18.593 &  119.282 &  119.282 &   86.950 &   86.950 &    80.164 &    80.164 &   48.116 &   48.116 &    93.246 &    93.246 &   68.031 &   26.168 &   55.780 &   40.939 &   68.636 &   86.683 \\
   &          & num &    0.000 &    1.228 &    0.732 &    0.600 &    0.889 &    1.009 &    0.889 &    1.009 &    0.774 &    1.101 &    0.803 &    1.362 &     1.259 &    0.904 &    0.803 &    1.362 &     1.259 &    0.904 &     1.519 &    0.787 &    0.476 &    0.476 &    1.085 &    1.085 &    0.882 &    0.882 &     0.995 &     0.995 &    0.651 &    0.651 &     0.895 &     0.895 &    0.812 &    0.548 &    0.835 &    0.958 &    1.180 &    1.276 \\
   & diff/std & \% &      NaN &  135.051 &   56.845 &   25.658 &   70.681 &   81.378 &   70.681 &   81.378 &  207.378 &   86.422 &  178.234 &   97.602 &   142.656 &  162.635 &  178.234 &   97.602 &   142.656 &  162.635 &    79.394 &   99.569 &   52.308 &   52.308 &    7.412 &    7.412 &    6.917 &    6.917 &   178.367 &   178.367 &  128.125 &  128.125 &    93.161 &    93.161 &   47.247 &   43.683 &   30.453 &  105.364 &   15.264 &   26.474 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Using the reconstructed matrix elements}
\label{\detokenize{part2/case-study-C2H4_290723:using-the-reconstructed-matrix-elements}}
\sphinxAtStartPar
The results tables are accessible directly, and there are also methods to reformat the best fit results for use in further calculations.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} self.paramsSummary contains the results above as Pandas Dataframe, usual Pandas methods can be applied.}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{paramsSummary}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{describe}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}\begin{equation*}
\begin{split}\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}
\toprule
Param &  AG\_B3U\_B3U\_0\_0\_1\_1 &  AG\_B3U\_B3U\_0\_0\_n1\_1 &  AG\_B3U\_B3U\_2\_0\_1\_1 &  AG\_B3U\_B3U\_2\_0\_n1\_1 &  AG\_B3U\_B3U\_2\_2\_1\_1 &  AG\_B3U\_B3U\_2\_2\_n1\_1 &  AG\_B3U\_B3U\_2\_n2\_1\_1 &  AG\_B3U\_B3U\_2\_n2\_n1\_1 &  AG\_B3U\_B3U\_4\_0\_1\_1 &  AG\_B3U\_B3U\_4\_0\_n1\_1 &  AG\_B3U\_B3U\_4\_2\_1\_1 &  AG\_B3U\_B3U\_4\_2\_n1\_1 &  AG\_B3U\_B3U\_4\_4\_1\_1 &  AG\_B3U\_B3U\_4\_4\_n1\_1 &  AG\_B3U\_B3U\_4\_n2\_1\_1 &  AG\_B3U\_B3U\_4\_n2\_n1\_1 &  AG\_B3U\_B3U\_4\_n4\_1\_1 &  AG\_B3U\_B3U\_4\_n4\_n1\_1 &  AG\_B3U\_B3U\_6\_0\_1\_1 &  AG\_B3U\_B3U\_6\_0\_n1\_1 &  B1G\_B3U\_B2U\_2\_2\_1\_1 &  B1G\_B3U\_B2U\_2\_2\_n1\_1 &  B1G\_B3U\_B2U\_2\_n2\_1\_1 &  B1G\_B3U\_B2U\_2\_n2\_n1\_1 &  B1G\_B3U\_B2U\_4\_2\_1\_1 &  B1G\_B3U\_B2U\_4\_2\_n1\_1 &  B1G\_B3U\_B2U\_4\_4\_1\_1 &  B1G\_B3U\_B2U\_4\_4\_n1\_1 &  B1G\_B3U\_B2U\_4\_n2\_1\_1 &  B1G\_B3U\_B2U\_4\_n2\_n1\_1 &  B1G\_B3U\_B2U\_4\_n4\_1\_1 &  B1G\_B3U\_B2U\_4\_n4\_n1\_1 &  B2G\_B3U\_B1U\_2\_1\_0\_1 &  B2G\_B3U\_B1U\_2\_n1\_0\_1 &  B2G\_B3U\_B1U\_4\_1\_0\_1 &  B2G\_B3U\_B1U\_4\_3\_0\_1 &  B2G\_B3U\_B1U\_4\_n1\_0\_1 &  B2G\_B3U\_B1U\_4\_n3\_0\_1 \\
\midrule
count &              20.000 &               20.000 &           2.000e+01 &               20.000 &              20.000 &               20.000 &               20.000 &                20.000 &              20.000 &               20.000 &              20.000 &               20.000 &           2.000e+01 &               20.000 &               20.000 &                20.000 &            2.000e+01 &                20.000 &              20.000 &               20.000 &               20.000 &                20.000 &                20.000 &                 20.000 &               20.000 &                20.000 &            2.000e+01 &                20.000 &                20.000 &                 20.000 &             2.000e+01 &              2.000e+01 &               20.000 &                20.000 &               20.000 &               20.000 &                20.000 &                20.000 \\
mean  &               0.681 &               -0.032 &           1.192e+00 &                0.060 &               0.700 &                0.996 &                0.700 &                 0.996 &               0.600 &                0.950 &               0.661 &                0.636 &           7.226e-01 &                0.919 &                0.661 &                 0.636 &            7.226e-01 &                 0.919 &               0.730 &                1.034 &                1.037 &                 1.037 &                 0.654 &                  0.654 &               -0.007 &                -0.007 &            3.386e-01 &                 0.618 &                 0.530 &                  0.530 &             3.539e-01 &              3.539e-01 &                0.574 &                 0.947 &                0.328 &                0.893 &                 0.126 &                 0.497 \\
std   &               1.122 &                1.956 &           1.058e+00 &                1.275 &               1.341 &                1.358 &                1.341 &                 1.358 &               0.956 &                1.358 &               1.425 &                1.566 &           1.663e+00 &                1.025 &                1.425 &                 1.566 &            1.663e+00 &                 1.025 &               1.531 &                1.304 &                1.327 &                 1.327 &                 1.281 &                  1.281 &                1.345 &                 1.345 &            1.446e+00 &                 1.530 &                 1.277 &                  1.277 &             1.192e+00 &              1.192e+00 &                0.985 &                 1.281 &                1.113 &                1.581 &                 1.518 &                 1.299 \\
min   &              -0.523 &               -2.978 &           1.742e-05 &               -3.142 &              -2.239 &               -3.028 &               -2.239 &                -3.028 &              -1.147 &               -2.611 &              -2.570 &               -3.139 &          -3.030e+00 &               -0.891 &               -2.570 &                -3.139 &           -3.030e+00 &                -0.891 &              -3.141 &               -2.199 &               -1.306 &                -1.306 &                -3.050 &                 -3.050 &               -3.141 &                -3.141 &           -3.142e+00 &                -3.142 &                -2.510 &                 -2.510 &            -2.675e+00 &             -2.675e+00 &               -1.628 &                -2.865 &               -1.842 &               -2.838 &                -3.136 &                -3.142 \\
25\%   &               0.000 &               -0.743 &           2.197e-01 &                0.002 &               0.224 &                0.255 &                0.224 &                 0.255 &               0.084 &                0.094 &               0.045 &                0.006 &           3.230e-04 &                0.061 &                0.045 &                 0.006 &            3.230e-04 &                 0.061 &               0.142 &                0.189 &                0.107 &                 0.107 &                 0.054 &                  0.054 &                0.001 &                 0.001 &            3.668e-04 &                 0.017 &                 0.003 &                  0.003 &             3.668e-04 &              3.668e-04 &                0.076 &                 0.242 &                0.041 &                0.106 &                -0.046 &                 0.039 \\
50\%   &               0.077 &                0.167 &           1.122e+00 &                0.217 &               0.619 &                1.308 &                0.619 &                 1.308 &               0.314 &                0.816 &               0.342 &                0.242 &           2.689e-01 &                0.592 &                0.342 &                 0.242 &            2.689e-01 &                 0.592 &               0.511 &                0.903 &                0.575 &                 0.575 &                 0.361 &                  0.361 &                0.017 &                 0.017 &            9.805e-02 &                 0.376 &                 0.089 &                  0.089 &             1.911e-01 &              1.911e-01 &                0.437 &                 0.848 &                0.218 &                0.545 &                 0.103 &                 0.227 \\
75\%   &               1.461 &                1.841 &           1.830e+00 &                0.670 &               1.634 &                1.852 &                1.634 &                 1.852 &               0.827 &                1.678 &               1.914 &                1.513 &           1.925e+00 &                1.689 &                1.914 &                 1.513 &            1.925e+00 &                 1.689 &               1.638 &                2.037 &                2.060 &                 2.060 &                 1.469 &                  1.469 &                0.588 &                 0.588 &            1.116e+00 &                 1.676 &                 1.224 &                  1.224 &             5.559e-01 &              5.559e-01 &                1.331 &                 1.666 &                0.952 &                2.346 &                 0.711 &                 1.172 \\
max   &               3.139 &                2.665 &           3.141e+00 &                1.773 &               3.082 &                3.076 &                3.082 &                 3.076 &               3.051 &                3.140 &               2.452 &                3.142 &           3.125e+00 &                3.142 &                2.452 &                 3.142 &            3.125e+00 &                 3.142 &               3.072 &                2.924 &                3.115 &                 3.115 &                 2.737 &                  2.737 &                2.038 &                 2.038 &            3.138e+00 &                 3.138 &                 3.142 &                  3.142 &             2.846e+00 &              2.846e+00 &                2.395 &                 2.899 &                2.314 &                3.103 &                 2.775 &                 2.762 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To set matrix elements from aggregate fit results, use `seetAggMatE` for Pandas}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{setAggMatE}\PYG{p}{(}\PYG{n}{simpleForm} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{agg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matEpd}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Set reformatted aggregate data to self.data[agg][matEpd].
\end{sphinxVerbatim}
\begin{equation*}
\begin{split}\begin{tabular}{llllrrrrrrl}
\toprule
    &   &    & Type &      m &      n &      p &     pc &          comp &         compC & labels \\
Cont & l & m & mu &        &        &        &        &               &               &        \\
\midrule
AG & 0 &  0 & -1 &  1.179 &  0.187 &  1.357 &  0.000 &  0.250+1.152j &  0.187+0.000j &    0,0 \\
    &   &    &  1 &  1.179 &  0.187 & -2.978 &  1.483 & -1.163-0.192j &  0.016+0.186j &    0,0 \\
    & 2 &  0 & -1 &  0.859 &  0.130 &  1.648 &  2.132 & -0.066+0.857j & -0.069+0.110j &    2,0 \\
    &   &    &  1 &  0.859 &  0.130 & -1.497 &  0.747 &  0.063-0.857j &  0.095+0.088j &    2,0 \\
    &   & -2 & -1 &  1.635 &  0.254 & -0.357 &  1.267 &  1.532-0.571j &  0.076+0.243j &   2,-2 \\
    &   &    &  1 &  1.635 &  0.254 &  0.413 &  1.682 &  1.497+0.656j & -0.028+0.253j &   2,-2 \\
    &   &  2 & -1 &  1.635 &  0.254 & -0.357 &  1.267 &  1.532-0.571j &  0.076+0.243j &    2,2 \\
    &   &    &  1 &  1.635 &  0.254 &  0.413 &  1.682 &  1.497+0.656j & -0.028+0.253j &    2,2 \\
    & 4 &  0 & -1 &  0.756 &  0.124 &  0.792 &  0.727 &  0.531+0.538j &  0.093+0.082j &    4,0 \\
    &   &    &  1 &  0.756 &  0.124 &  1.156 &  1.762 &  0.305+0.692j & -0.024+0.122j &    4,0 \\
    &   & -2 & -1 &  0.539 &  0.075 &  0.366 &  1.662 &  0.503+0.193j & -0.007+0.075j &   4,-2 \\
    &   &    &  1 &  0.539 &  0.075 &  0.552 &  1.378 &  0.459+0.283j &  0.014+0.074j &   4,-2 \\
    &   &  2 & -1 &  0.765 &  0.124 & -0.060 &  2.062 &  0.764-0.046j & -0.058+0.109j &    4,2 \\
    &   &    &  1 &  0.765 &  0.124 &  1.382 &  1.406 &  0.144+0.752j &  0.020+0.122j &    4,2 \\
    &   & -4 & -1 &  0.539 &  0.075 &  0.366 &  1.662 &  0.503+0.193j & -0.007+0.075j &   4,-4 \\
    &   &    &  1 &  0.539 &  0.075 &  0.552 &  1.378 &  0.459+0.283j &  0.014+0.074j &   4,-4 \\
    &   &  4 & -1 &  0.765 &  0.124 & -0.060 &  2.062 &  0.764-0.046j & -0.058+0.109j &    4,4 \\
    &   &    &  1 &  0.765 &  0.124 &  1.382 &  1.406 &  0.144+0.752j &  0.020+0.122j &    4,4 \\
    & 6 &  0 & -1 &  1.127 &  0.166 &  0.196 &  1.431 &  1.105+0.220j &  0.023+0.165j &    6,0 \\
    &   &    &  1 &  1.127 &  0.166 &  0.708 &  2.133 &  0.856+0.733j & -0.089+0.141j &    6,0 \\
B1G & 2 & -2 & -1 &  0.993 &  0.139 &  0.453 &  2.561 &  0.892+0.435j & -0.116+0.076j &   2,-2 \\
    &   &    &  1 &  0.993 &  0.139 &  0.453 &  2.561 &  0.892+0.435j & -0.116+0.076j &   2,-2 \\
    &   &  2 & -1 &  0.993 &  0.139 &  0.574 &  0.910 &  0.833+0.539j &  0.085+0.110j &    2,2 \\
    &   &    &  1 &  0.993 &  0.139 &  0.574 &  0.910 &  0.833+0.539j &  0.085+0.110j &    2,2 \\
    & 4 & -2 & -1 &  0.127 &  0.022 & -1.190 &  1.015 &  0.047-0.118j &  0.012+0.019j &   4,-2 \\
    &   &    &  1 &  0.127 &  0.022 & -1.190 &  1.015 &  0.047-0.118j &  0.012+0.019j &   4,-2 \\
    &   &  2 & -1 &  0.326 &  0.048 & -0.260 &  1.241 &  0.315-0.084j &  0.015+0.045j &    4,2 \\
    &   &    &  1 &  1.295 &  0.198 & -0.260 &  1.241 &  1.251-0.333j &  0.064+0.187j &    4,2 \\
    &   & -4 & -1 &  0.127 &  0.022 &  0.618 &  1.354 &  0.104+0.074j &  0.005+0.022j &   4,-4 \\
    &   &    &  1 &  0.127 &  0.022 &  0.618 &  1.354 &  0.104+0.074j &  0.005+0.022j &   4,-4 \\
    &   &  4 & -1 &  0.326 &  0.048 &  0.082 &  0.960 &  0.325+0.027j &  0.027+0.039j &    4,4 \\
    &   &    &  1 &  0.326 &  0.048 &  0.082 &  0.960 &  0.325+0.027j &  0.027+0.039j &    4,4 \\
B2G & 2 & -1 &  0 &  0.788 &  0.128 &  0.187 &  1.193 &  0.774+0.147j &  0.047+0.119j &   2,-1 \\
    &   &  1 &  0 &  0.788 &  0.128 &  0.778 &  2.093 &  0.561+0.553j & -0.064+0.111j &    2,1 \\
    & 4 & -1 &  0 &  0.457 &  0.067 & -0.706 &  1.496 &  0.348-0.297j &  0.005+0.066j &   4,-1 \\
    &   &  1 &  0 &  0.837 &  0.121 &  0.273 &  2.341 &  0.806+0.225j & -0.084+0.087j &    4,1 \\
    &   & -3 &  0 &  0.457 &  0.067 & -1.739 &  1.719 & -0.076-0.451j & -0.010+0.066j &   4,-3 \\
    &   &  3 &  0 &  0.837 &  0.121 & -0.442 &  1.473 &  0.757-0.358j &  0.012+0.121j &    4,3 \\
\bottomrule
\end{tabular}\end{split}
\end{equation*}
\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} To set matrix elements from aggregate fit results, use `aggToXR` for Xarray}
\PYG{c+c1}{\PYGZsh{} data.aggToXR(refKey = \PYGZsq{}orb5\PYGZsq{}, returnType = \PYGZsq{}ds\PYGZsq{}, conformDims=True)   \PYGZsh{} use full ref dataset}
\PYG{n}{data}\PYG{o}{.}\PYG{n}{aggToXR}\PYG{p}{(}\PYG{n}{refKey} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{subset}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{returnType} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ds}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{conformDims}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Subselected matE}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Added dim Total
Added dim Targ
Added dim Total
Added dim Targ
Set XR dataset for self.data[\PYGZsq{}agg\PYGZsq{}][\PYGZsq{}matE\PYGZsq{}]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Density matrices}
\label{\detokenize{part2/case-study-C2H4_290723:density-matrices}}
\sphinxAtStartPar
New (experimental) code for density matrix plots and comparison. See \hyperref[\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}]{Sect.\@ \ref{\detokenize{part1/theory_density_matrices_190723:sec-density-mat-basic}}} for discussion. Code adapted from the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/matrix\_element\_extraction\_MFrecon\_PEMtk\_180722-dist.html\#Density-matrix-plotting}{MF reconstruction page}, original analysis for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case. If the reconstruction is good, the differences (fidelity) should be on the order of the experimental noise level/reconstruction uncertainty, around 10\% in the case studies herein; in general the values and patterns of the matrices can also indicate aspects of the retrieval that worked well, or areas where values are poorly defined/recovered from the given dataset.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{26053d4d7f77d52e4326cb288bdc93286956ecf44bc5f6b383151aba129eeb3c}.png}
\caption{Density matrix comparison \sphinxhyphen{} rows show (a) reference case (with signs of phases removed), (b) reconstructed case, (c) differences. Columns are (left) imaginary component, (right) real component. If the reconstruction is good, the differences (fidelity) should be on the order of the experimental noise level/reconstruction uncertainty, around 10\% in the case studies herein.}\label{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-densitycomp}}\end{figure}


\subsection{Plot MF PADs}
\label{\detokenize{part2/case-study-C2H4_290723:plot-mf-pads}}
\sphinxAtStartPar
Routines below adapted from the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]} \sphinxhref{https://pemtk.readthedocs.io/en/latest/topical\_review\_case\_study/MFPAD\_replotting\_from\_file\_190722-dist.html}{MF reconstruction data processing page} (original analysis page for Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]}, illustrating the \(N_2\) case). The routines include calls to \sphinxcode{\sphinxupquote{self.mfpadNumeric()}} for numerical expansion of the MF\sphinxhyphen{}PADs, and \sphinxcode{\sphinxupquote{self.padPlot()}} for plotting. Results are illustrated for the retrieved and reference cases in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-compc}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-compc}}} and \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-ref}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-ref}}} respectively, and the differential results (reference minus fitted results) in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-diff}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{48ca57c7b50c98d080989dbd2feb380c87c919274c43d9b2370076bb01a3f948}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} computed from retrieved matrix elements for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis.}\label{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-compc}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{f90bb1c80a48c6f8fba1b31453b6bd01c0db398fb34def215d60495af4d8da97}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} computed from reference \sphinxstyleemphasis{ab initio} matrix elements for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis.}\label{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-ref}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{9420008f5a9dd5416a51dfba8fea03ff3245f897f534505ccf7141a51f29d54a}.png}
\caption{{\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} differences between retrieved and reference cases for \((x,y,z,d)\) polarization geometries, where \(d\) is the “diagonal” case with the polarization axis as 45 degrees to the \(z\)\sphinxhyphen{}axis. Note diffs are normalised to emphasize the shape, but not mangnitudes, of the differences \sphinxhyphen{} see the density matrix comparisons for a more rigourous fidelity analysis.}\label{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-diff}}\end{figure}

\sphinxstepscope


\chapter{Case studies: summaries, conclusions and outlook}
\label{\detokenize{part2/case-study-summaries_240723:case-studies-summaries-conclusions-and-outlook}}\label{\detokenize{part2/case-study-summaries_240723:chpt-case-study-summaries}}\label{\detokenize{part2/case-study-summaries_240723::doc}}
\sphinxAtStartPar
In the preceding chapters, three case studies were demonstrated. As already noted elsewhere (\hyperref[\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}]{Chpt.\@ \ref{\detokenize{part2/extracting_matrix_elements_overview_270423:chpt-extracting-matrix-elements-overview}}}), the \(N_2\) case has already been demonstrated to be successful for a range of energies and ionization channels (orbitals), see Refs. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}, \hyperlink{cite.backmatter/bibliography:id686}{3}{]} for further details. However, it is included here as a benchmark case, useful for testing the methodology, computational routines and limitations and so forth. In particular, it represents a case of a reasonable level of complexity for method development, without an excessive number of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}/fitting parameters to deal with.

\sphinxAtStartPar
The other two case studies (\hyperref[\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}]{Chpt.\@ \ref{\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}}} \& \hyperref[\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}]{Chpt.\@ \ref{\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}}}) are presented in a more experimental/preliminary capacity. In both cases, a much larger number of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} are required, and a higher\sphinxhyphen{}information content dataset with 3D alignment (as tested) and/or multiple polarization geometries, is expected to be required for a high\sphinxhyphen{}fidelity {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} to be successful. In the current cases as presented, some progress towards this has been achieved, although further work remains to improve on the current results. Nonetheless, as stated previously, these new results are interesting and present a stepping\sphinxhyphen{}stone for studies on {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval in complex systems, and a launching point for similar studies.


\section{General notes on fitting methodologies for the case studies}
\label{\detokenize{part2/case-study-summaries_240723:general-notes-on-fitting-methodologies-for-the-case-studies}}
\sphinxAtStartPar
As discussed elsewhere, the general {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} is quite flexible. In the case studies, much of this flexibility is yet to be explored! This is, primarily, a question of the time and effort available: for the \(N_2\) case obtaining a set of 1000 fit results takes approximately 2 hours on a workstation.%
\begin{footnote}[1]\sphinxAtStartFootnote
Running on 20 (logical) cores of an AMD Threadripper 2950X based workstation, this required 5 GB of RAM and took on the order of 2 hours, although note that the time per fit cycle had large variance, since convergence time depends on the start parameters. Further benchmarks for the current codebase can be found in the \sphinxhref{https://pemtk.readthedocs.io}{PEMtk documentation} {[}\hyperlink{cite.backmatter/bibliography:id681}{20}{]}.
%
\end{footnote} However, scaling up to more complex cases is significantly more costly, with \(OCS\) and \(C_2H_4\) results requiring approximately 1\sphinxhyphen{}2 orders of magnitude more computational time \sphinxhyphen{} on the order of days per few hundred fits. Work towards speeding up fitting, e.g. using GPU\sphinxhyphen{}based routines and/or lower\sphinxhyphen{}level code for speed, is ongoing. Deployment to high\sphinxhyphen{}performance computing (HPC) resources, e.g. clusters, is also ongoing. The results herein, therefore, represent only the preliminary stages of testing and tuning the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} for these more complex cases, but already appear quite promising.

\sphinxAtStartPar
In each case, as detailed in \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}} \& \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chpt.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}}, the fitting basis sets were created based on \sphinxstyleemphasis{ab initio} results, with all {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} greater than a threshold value of 0.01 used for both simulated data generation and fitting, and automatic parameter constraints applied to reduce the effective number of “free” or “floated” terms in the fitting. Fitting was only tested for single energy\sphinxhyphen{}points. The overall size of the problems as run in this manner were:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
System
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Symmetry
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Energy (eV)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Complex matrix elements
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Fitting params
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Floated params (magnitude, phase)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(t\)\sphinxhyphen{}points
\\
\hline
\sphinxAtStartPar
\(N_2\)
&
\sphinxAtStartPar
\(D_{\infty h}\)
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
6
&
\sphinxAtStartPar
12
&
\sphinxAtStartPar
4,3
&
\sphinxAtStartPar
13
\\
\hline
\sphinxAtStartPar
\(OCS\)
&
\sphinxAtStartPar
\(C_{\infty v}\)
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
22
&
\sphinxAtStartPar
44
&
\sphinxAtStartPar
15,14
&
\sphinxAtStartPar
51
\\
\hline
\sphinxAtStartPar
\(C_2H_4\)
&
\sphinxAtStartPar
\(C_{2h}\)
&
\sphinxAtStartPar
6
&
\sphinxAtStartPar
38
&
\sphinxAtStartPar
76
&
\sphinxAtStartPar
14,25
&
\sphinxAtStartPar
73
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
In both of the more complex cases, the computational testing involved starting with the protocol as used for the \(N_2\) reference case, then adding data points until clustering was observed in the \(\chi^2\) histograms, indicating that multiple minima were successfully located. This is a necessary first step in testing, and signifies that the methodology is working as expected; however, this is not sufficient to guarantee that the information content of the dataset was adequate for complete {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval, nor to guarantee a high\sphinxhyphen{}fidelity retrieval (herein “complete” is used to indicate that a unique set of fit parameters may be found, whilst the “fidelity” is the more stringent test of the veracity of these parameters). In fitting, automatic parameter relations were set, which fixed equivalent parameters (see \hyperref[\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}]{Chpt.\@ \ref{\detokenize{part2/sym-fitting-intro_240723:sect-basis-sets-fitting-intro}}} \& \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chpt \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}} for details). For \(N_2\) and \(OCS\) no additional constraints were imposed; for \(C_2H_4\) some additional magnitude\sphinxhyphen{}only constraints were set for parameters with identical magnitudes which were not set by the automated routine, although corresponding phase relations were \sphinxstyleemphasis{not} set (see tabulations in \hyperref[\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}]{Chpt.\@ \ref{\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}}} for full details) \sphinxhyphen{} this case is therefore an interesting test of whether the correlated phase relations will be correctly recovered by the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}. It is, however, anticipated that for high\sphinxhyphen{}fidelity retrieval, additional constraints may be required on a case\sphinxhyphen{}by\sphinxhyphen{}case basis, and particularly for large problems, e.g. by fixing additional symmetry relations, making use of additional data and so forth \sphinxhyphen{} this is discussed further below.

\sphinxAtStartPar
In each case, the lowest \(\chi^2\) cluster was assumed to be the “best” result, i.e. the true set of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, and further tested for spread and veracity, as compared with the known inputs. This is an easy methodology to implement computationally although, in general, one may wish to inspect several sets of candidate fit parameters in cases with noise and/or large solution spaces, since the lowest \(\chi^2\) may not, in fact, be the best, and a true global minima may not exist. Similarly, the presence of multiple equivalent minima is possible in cases where some quantities are undefined, which may lead to issues with phase retrieval in particular (see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} for further discussion) \sphinxhyphen{} with the current codebase this can be probed by changing the binning of candidate fit results, and examining the spread of parameters for a given choice of binning, as outlined in the case studies. (In the case studies, the retrieved matrix elements are taken as an average over the best cluster of fits, hence large spread in a given parameter for the chosen cluster indicates a case where the given parameter is not well defined \sphinxhyphen{} this is likely to appear as a clear deficiency in the corresponding density matrix and/or {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} when assessing the fidelity of the retrieval.) The likelihood of a good fit result will also depend on the number of data\sphinxhyphen{}points used in fitting, as well as the underlying alignment and molecular symmetry properties \sphinxhyphen{} generally the form of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} as discussed in \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-tensor-formulation}}} \sphinxhyphen{} which have not been carefully investigated in these cases as yet.

\sphinxAtStartPar
For the \(N_2\) case, the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} is as detailed in Refs. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}, \hyperlink{cite.backmatter/bibliography:id686}{3}{]}, which made use of a two\sphinxhyphen{}pulse alignment scheme. Data\sphinxhyphen{}points over the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} half\sphinxhyphen{}revival feature were chosen initially to approximately match the previously published cases (13 \(t\)\sphinxhyphen{}points in the current case, vs. 11 in the original study, although that study also made use of larger datasets up to 89 \(t\)\sphinxhyphen{}points for higher\sphinxhyphen{}fidelity {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}, see Ref. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]} supplementary materials for further details).

\sphinxAtStartPar
For the \(OCS\) case, the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} is as per obtained in recent ultrafast experiments {[}\hyperlink{cite.backmatter/bibliography:id972}{144}{]}, which made use of a single\sphinxhyphen{}pulse alignment scheme to prepare a 1D molecular alignment (no orientation). For testing purposes, an (arbitrary) number of low\sphinxhyphen{}order terms \(Q\neq0\) and \(S\neq0\) were added for the work herein (with a linear ramp in \(t\)), including \(K=1\) terms for orientation (see figures in \hyperref[\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}]{Chpt.\@ \ref{\detokenize{part2/case-study-OCS_290723:chpt-ocs-case-study}}} for full details). Although these are not expected to be physically realistic, they will be indicative of the terms present in a true 3D alignment case. Note that the temporal data used in this case is discontinuous, with \(t\)\sphinxhyphen{}points over both the 1/4 and 1/2 {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} revival features selected.

\sphinxAtStartPar
For the \(C_2H_4\) case, the {\hyperref[\detokenize{backmatter/glossary:term-RWP}]{\sphinxtermref{\DUrole{xref,std,std-term}{RWP}}}} is a realistic case, as used in Ref. {[}\hyperlink{cite.backmatter/bibliography:id636}{98}{]}, which includes \(S\neq0\) terms and even\sphinxhyphen{}\(K\) even\sphinxhyphen{}\(S\) terms (see figures in \hyperref[\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}]{Chpt.\@ \ref{\detokenize{part2/case-study-C2H4_290723:chpt-c2h4-case-study}}} for full details). Interestingly, this case was sufficient for retrieval of {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} using the matrix\sphinxhyphen{}inversion method, so is expected to be successful with the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} provided enough data\sphinxhyphen{}points are incorporated and the fitting is well\sphinxhyphen{}constrained. Note that the temporal axis in this case is in arbitrary units.


\section{Retrieval fidelity}
\label{\detokenize{part2/case-study-summaries_240723:retrieval-fidelity}}
\sphinxAtStartPar
The continuum density matrices provide a way to quickly assess the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} fidelity in these test cases, without the necessity of consulting rather complex tabulations of {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}/fitting parameters and the associated statistics. In general, it is expected that the \sphinxstyleemphasis{differences} between the true and reconstructed density matrices will be on the order of the experimental noise in a high\sphinxhyphen{}fidelity case. For each case study, such a comparison is given \sphinxhyphen{} see \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-densitycomp}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-densitycomp}}} (\(N_2\) case), \hyperref[\detokenize{part2/case-study-OCS_290723:fig-ocs-densitycomp}]{Fig.\@ \ref{\detokenize{part2/case-study-OCS_290723:fig-ocs-densitycomp}}} (\(OCS\) case), and \hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-densitycomp}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-densitycomp}}} (\(C_2H_4\) case) (see \sphinxhref{https://phockett.github.io/Quantum-Metrology-with-Photoelectrons-Vol3}{\sphinxstyleemphasis{Quantum Metrology} Vol. 3 (HTML version)} for interactive plots). Note that in the comparisons herein the sign of the phases is assumed to be undefined, so phases are remapped to positive values only (i.e. assumed to be in the \(0:\pi\) range). Depending on the symmetry of the problem (hence the form of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}), this may or may not be the case in practice \sphinxhyphen{} in particular cases with multiple polarisation geometries and/or 3D alignment may break this assumption.

\sphinxAtStartPar
For \(N_2\), the recovered and reference density matrices are in good agreement, and differences in both the real and imaginary components are on the order of the noise\sphinxhyphen{}floor in the simulated dataset (\(\approx\pm10\%\)). This indicates a high\sphinxhyphen{}fidelity retrieval from only a small number of data\sphinxhyphen{}points (13 in the example case), and also indicates that improvements may be found here by incorporating additional data into the fitting procedure.

\sphinxAtStartPar
For \(OCS\) (\hyperref[\detokenize{part2/case-study-OCS_290723:fig-ocs-densitycomp}]{Fig.\@ \ref{\detokenize{part2/case-study-OCS_290723:fig-ocs-densitycomp}}}) and \(C_2H_4\) (\hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-densitycomp}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-densitycomp}}}) cases, a number of general comments may be made. Firstly, the overall patterns of values observed in the reconstructed density matrices are in good agreement with the reference cases, however the agreement in the absolute values (hence fidelity) are quite variable. For \(OCS\) differences as large as 0.4 are observed, whilst for \(C_2H_4\) differences as large as 1 are observed. Secondly, some patterns are inverted in the retrieved cases, indicating issues with the signs of the retrieved quantities. This is likely indicative of missing phase relations in the data (i.e. the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} restrict the accessible terms), or indicates that multiple minima exist in the \(\chi^2\) hypersurface with differences in the phases. Thirdly, the retrieved {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} tend to have, in general, larger values in both real and imaginary components for the higher\sphinxhyphen{}order terms (larger \(l\)) than the reference values: this can be seen in the fading (vignetting) of the colourmaps to higher\sphinxhyphen{}order in the reference cases, which is not present in the retrieved maps.

\sphinxAtStartPar
In general, these issues all suggest that the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} is partially working for these cases, but may not yet be complete. A number of avenues remain to be explored here, in particular:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The analysis of other candidate parameter sets to check for uniqueness/equivalence.
\begin{itemize}
\item {} 
\sphinxAtStartPar
This may required deeper analysis of the existing results with finer \(\chi^2\) binning than the current cases, which indicate significant spreading in some parameters (see the \sphinxstyleemphasis{Raw results} and \sphinxstyleemphasis{Phases} subsections in each case study chapter, particularly the paramter plots which indicate the spread in results).

\item {} 
\sphinxAtStartPar
This analysis is not yet automated, but this may be possible by setting preferences on spreading of results to determine optimum grouping of results.

\end{itemize}

\item {} 
\sphinxAtStartPar
Further boostrapping with larger datasets and/or using the existing best fit parameters as seed values to further probe the local \(\chi^2\) surface.

\item {} 
\sphinxAtStartPar
Fitting with reduced parameter sets. These were set based on the reference matrix elements with a threshold for inclusion of 0.01 (see \hyperref[\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}]{Chpt.\@ \ref{\detokenize{part2/basic_fitting_numerics_intro_260723:sect-basic-fit-setup}}}), but raising this to 0.1 would remove many of the higher\sphinxhyphen{}order terms from the fitting, which may result in higher\sphinxhyphen{}fidelity retrieval of the lower\sphinxhyphen{}order terms which then remain.

\item {} 
\sphinxAtStartPar
Fitting with more constraints, e.g.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Setting lower limits on higher\sphinxhyphen{}order terms. Although, in practice, this may not be known \sphinxstyleemphasis{a priori} for a given case, as a general rule\sphinxhyphen{}of\sphinxhyphen{}thumb it should be applicable (as indicated by the \sphinxstyleemphasis{ab initio} results for the cases herein).

\item {} 
\sphinxAtStartPar
Enforcing orthogonality on different continua, as per the symmetrized harmonics defining each case. For the \(C_2H_4\) case in particular, this would add additional phase restrictions which were missing in the current study.

\end{itemize}

\item {} 
\sphinxAtStartPar
Further testing with simulated data with both more and less noise present to evaluate the effect of the noise\sphinxhyphen{}floor in different cases.

\item {} 
\sphinxAtStartPar
Finally, it is of note (and also noted elsewhere) that there may still be bugs or numerical issues with the preliminary results presented herein, since they represent the first trials of the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} and {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} for complex cases. However, given that the same routines are used to generate the simulated data, any issues should, at least, be self\sphinxhyphen{}consistent for these test cases. Eagle\sphinxhyphen{}eyed readers may notice that in the \(C_2H_4\) test case, the \(\beta_{0,0}(t)\) parameters are negative, which is unphysical; this indicates a phase error in the calculation and has since been fixed, but does \sphinxstyleemphasis{not} affect the fitting protocol thanks to the self\sphinxhyphen{}consistent nature of the numerics.

\end{itemize}


\section{MF\sphinxhyphen{}PAD retrieval}
\label{\detokenize{part2/case-study-summaries_240723:mf-pad-retrieval}}
\sphinxAtStartPar
The {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} also provide an interesting observable to test from the retrieved {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} \sphinxhyphen{} they provide less detail than the density matrices, but do give a better indication of the sensitivity of the observables to the retrieved parameters (via the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}) in a given case. For example, some phase relations may not be important for {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} retrieval, or only appear under certain polarization geometries. For both the \(N_2\) and \(C_2H_4\) cases the work in Ref. {[}\hyperlink{cite.backmatter/bibliography:id636}{98}{]} provides an interesting perspective here, since it outlines a direct {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} reconstruction method which bypasses the difficulty of phase\sphinxhyphen{}retrieval and fitting via a matrix\sphinxhyphen{}inversion protocol. This is found to work well for both these cases, although in a similar manner to a fitting approach will be fundamentally limited in any given case by the symmetry of the problem.

\sphinxAtStartPar
For the case studies, the reconstructed {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} are somewhat variable, as may be expected from the preceding discussion on fidelity. For \(N_2\) (\hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-compc}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-compc}}} \sphinxhyphen{} \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-diff}}}), the results are excellent \sphinxhyphen{} as expected from the previous studies in this case. In particular, the good agreement for the diagonally\sphinxhyphen{}polarized case indicates that the relative phase \sphinxstyleemphasis{between} the two continua is defined in this type of data, and successfully retrieved. The normalised difference plots in \hyperref[\detokenize{part2/case-study-N2_290723:fig-n2-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-N2_290723:fig-n2-diff}}} indicate that the main differences between the retrieved and reference cases can be observed in some of the smaller lobes, indicating that the fidelity is high, but not perfect. As discussed in the previous section, adding data and analysing the effect of noise on the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} may improve on the retrieval fidelity, and this was previously explored for \(N_2\) in Ref. {[}\hyperlink{cite.backmatter/bibliography:id776}{1}{]}.

\sphinxAtStartPar
For the more complex cases, the fidelity is lower, and the results generally suggest that, although the dominant continuum is fairly well recovered, the loss of phase information and/or generally lower information content of the data is an issue. For \(OCS\) (\hyperref[\detokenize{part2/case-study-OCS_290723:fig-ocs-compc}]{Fig.\@ \ref{\detokenize{part2/case-study-OCS_290723:fig-ocs-compc}}} \sphinxhyphen{} \hyperref[\detokenize{part2/case-study-OCS_290723:fig-ocs-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-OCS_290723:fig-ocs-diff}}}), the \((x,y)\) {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}}\sphinxhyphen{}{\hyperref[\detokenize{backmatter/glossary:term-PADs}]{\sphinxtermref{\DUrole{xref,std,std-term}{PADs}}}} are close to the reference case, although the lobes are significantly sharper. The \(z\) case, however, is very different, with the main lobe in the \(-z\) direction, as opposed to \(+z\) in the reference case. This indicates that the terms related to breaking up\sphinxhyphen{}down symmetry are not well reproduced in this case, and is most likely an issue with the associated phases; as noted above this may be due to issues with the analysis and binning of the fit results, or a more fundamental limitation due to the dataset and/or symmetry of the problem \sphinxhyphen{} potentially with the choice of additional terms added to the {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}} \sphinxhyphen{} and more work is required here to ascertain this.

\sphinxAtStartPar
For \(C_2H_4\) (\hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-compc}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-compc}}} \sphinxhyphen{} \hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-diff}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-diff}}}), the opposite is true: the \(z\) case is fairly well reproduced, although rotated, whilst the \((x,y)\) cases are in poor agreement with the reference results. Again it is the dominant continuum which is best reproduced; however, in this case the discrepancies in all polarization geometries appear as additional symmetry breaking, which would not be present in the correctly symmetrized (orthogonal continua) case \sphinxhyphen{} as seen in the reference results (\hyperref[\detokenize{part2/case-study-C2H4_290723:fig-c2h4-ref}]{Fig.\@ \ref{\detokenize{part2/case-study-C2H4_290723:fig-c2h4-ref}}}). This indicates that the respective continua are not well\sphinxhyphen{}separated in the recovered {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}}, i.e. the phase relations are such that additional symmetry breaking is seen. As for the \(OCS\) case, this may be due to averaging over multiple minima in the fitting phase space, and/or may relate to a lack of information in the test dataset. In this case, given the results of Ref. {[}\hyperlink{cite.backmatter/bibliography:id636}{98}{]}, it is anticipated that the dataset is sufficient, and that most issues arise from the complexity of the \(\chi^2\) hypersurface and the configuration of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}}, and/or post\sphinxhyphen{}processing of the results. As discussed above, in the current test case some phase relationships between parameters were not constrained, and this is likely the main source of the discrepancy; ideally the fitting should recover these relations in general, but this will, again, depend on the form of the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} and the dataset used, which will ultimately determine which phase relations are defined and therefore recoverable. Probing this behaviour in general, and in this case, in more depth is currently underway. One way to probe this type of issue further is to define specific orthogonality relations in the fitting procedure via symmetrized matrix elements. This would provide a means to enforce the distinction between the continua without the necessity of \sphinxstyleemphasis{ab initio} {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} (this is possible with the current codebase, but has not been explored for this case as yet). This would also be consistent with the success of the approach in  Ref. {[}\hyperlink{cite.backmatter/bibliography:id636}{98}{]}, since symmetry is rigorously enforced in the mathematics of the matrix\sphinxhyphen{}inversion method.

\sphinxAtStartPar
In all cases, the “diagonal” polarization case is another good test of the phase relations, since this is also sensitive to the phase relations between the \(z\) and \((x,y)\) continua. For \(N_2\) the good agreement of the results with the reference case is, again, indicative of the generally good fidelity of the reconstruction in this case. Similarly, the differences in the more complex \(OCS\) and \(C_2H_4\) cases are consistent with the previous discussion: the main difference between these cases is the additional symmetry breaking in the lower\sphinxhyphen{}symmetry \(C_2H_4\) case, leading to the appearance of an overall rotation and additional lobes, particularly directed out of the \((x,z)\) plane, relative to the reference case. Again, this is indicative of continua mixing, arising from incorrect/undefined/low\sphinxhyphen{}fidelity phase terms.


\section{Conclusions and outlook}
\label{\detokenize{part2/case-study-summaries_240723:conclusions-and-outlook}}
\sphinxAtStartPar
Overall, the case studies provide interesting material for a number of reasons. First and foremost, they indicate that the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} method is applicable to larger problems (38 {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} in the largest case), at least in principle. Secondly, they indicate the issues in these cases, which still remain exceedingly complicated retrieval problems, despite the generality and automation of the {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} implemented in the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]}. In these specific cases the route to complete and/or higher\sphinxhyphen{}fidelity {\hyperref[\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}]{\sphinxtermref{\DUrole{xref,std,std-term}{bootstrap retrieval protocol}}}} is clear, but significant efforts are still required to conclusive demonstrate this, and develop more efficient and effective fitting strategies for large solution hyperspaces. Nonetheless, this is an interesting and notable step towards a general method for these problems, and (equivalently) density matrix retrieval and general quantum tomography on larger systems (e.g. 38x38 density matrix retrieval in the \(C_2H_4\) case).

\sphinxAtStartPar
Future work is planned to look at these specific problems in more detail, including different energy regions and ionization channels, and other small molecules. As part of this effort, HPC resources will be used to allow for scaling up of the computational effort available, and development of the \sphinxhref{https://github.com/phockett/PEMtk}{Photoelectron Metrology Toolkit} {[}\hyperlink{cite.backmatter/bibliography:id682}{5}{]} and \sphinxhref{https://epsproc.readthedocs.io}{ePSproc codebase} {[}\hyperlink{cite.backmatter/bibliography:id666}{33}, \hyperlink{cite.backmatter/bibliography:id608}{34}, \hyperlink{cite.backmatter/bibliography:id606}{35}{]} will continue in tandem with these efforts. Fitting strategies, algorithms and methodologies also remain as a large area to be explored, in particular cross\sphinxhyphen{}fertilization from other fields dealing with large computational hyperspaces and complex phase\sphinxhyphen{}retrieval problems is expected to (continue) to prove fruitful (see \sphinxstyleemphasis{Quantum Metrology} Vols. 1 \& 2 {[}\hyperlink{cite.backmatter/bibliography:id677}{4}, \hyperlink{cite.backmatter/bibliography:id678}{9}{]} and Ref. {[}\hyperlink{cite.backmatter/bibliography:id686}{3}{]} for futher discussion along these lines).

\sphinxAtStartPar
As discussed in \hyperref[\detokenize{part1/platform_intro_070723:sect-platform-analysis}]{Chpt.\@ \ref{\detokenize{part1/platform_intro_070723:sect-platform-analysis}}}, it is also hoped that the efforts on the code\sphinxhyphen{}development side of the problem, including the case studies presented herein, the open\sphinxhyphen{}source nature of the work, and the easy deployment of the full software stack via Docker, will all encourage other researchers to make use of these tools, and make further developments to the methodology and platform. Given the complex nature of both the core physics, data processing, simulation and phase retrieval problems, there are still many avenues to explore, but hopefully the barrier to entry is now significantly lowered.


\bigskip\hrule\bigskip


\sphinxstepscope


\part{Backmatter}

\sphinxstepscope


\chapter{Bibliography}
\label{\detokenize{backmatter/bibliography:bibliography}}\label{\detokenize{backmatter/bibliography::doc}}\phantomsection\label{\detokenize{backmatter/bibliography:id1}}
\sphinxstepscope


\chapter{Glossary}
\label{\detokenize{backmatter/glossary:glossary}}\label{\detokenize{backmatter/glossary::doc}}\begin{description}
\sphinxlineitem{MF\index{MF@\spxentry{MF}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-MF}}}
\sphinxAtStartPar
Molecular frame (MF) \sphinxhyphen{} coordinate system referenced to the molecule, usually with the z\sphinxhyphen{}axis corresponding to the highest symmetry axis. See \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}} for further details.

\sphinxlineitem{LF\index{LF@\spxentry{LF}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-LF}}}
\sphinxAtStartPar
Laboratory or lab frame (LF) \sphinxhyphen{} coordinate system referenced to the laboratory frame, usually with the z\sphinxhyphen{}axis corresponding to the laser field polarization. For circularly or elliptically polarized light the propagation direction is conventionally used for the z\sphinxhyphen{}axis. In some cases a different z\sphinxhyphen{}axis may be chosen, e.g. as defined by a detector. See \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}} for further details.

\sphinxlineitem{AF\index{AF@\spxentry{AF}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-AF}}}
\sphinxAtStartPar
Aligned frame (AF) \sphinxhyphen{} coordinate system referenced to molecular alignment axis or axes. For 1D alignment, the z\sphinxhyphen{}axis usually corresponds to the alignment field polarization, and hence may be identical to the standard {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} definition, although is usually reserved for use in cases where there is some molecular alignment. For the limiting case of an isotropic distribution, the {\hyperref[\detokenize{backmatter/glossary:term-AF}]{\sphinxtermref{\DUrole{xref,std,std-term}{AF}}}} and (traditional) {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}} are identical. For high degrees of (3D) alignment the AF may approach the {\hyperref[\detokenize{backmatter/glossary:term-MF}]{\sphinxtermref{\DUrole{xref,std,std-term}{MF}}}} in the ideal case, although will usually be limited by the symmetry of the system. See \hyperref[\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}]{Sect.\@ \ref{\detokenize{part1/theory_tensor_formalism_160723:sec-frame-definitions}}} for further details.

\sphinxlineitem{PADs\index{PADs@\spxentry{PADs}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-PADs}}}
\sphinxAtStartPar
Photoelectron angular distributions (PADs), often with a prefix denoting the reference frame, e.g. LFPADs, MFPADs (sometimes also hypenated, e.g. LF\sphinxhyphen{}PADs). Usage is often synonymous with the associated {\hyperref[\detokenize{backmatter/glossary:term-anisotropy-paramters}]{\sphinxtermref{\DUrole{xref,std,std-term}{anisotropy paramters}}}} (or “betas”).

\sphinxlineitem{anisotropy paramters\index{anisotropy paramters@\spxentry{anisotropy paramters}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-anisotropy-paramters}}}
\sphinxAtStartPar
Expansion parameters \(\beta_{L,M}\) for an expansion in spherical harmonics (or similar basis sets of angular momentum functions in polar coordinates), e.g. Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:AF-PAD-general}. Often referred to simply as “beta parameters”, and may be dependent on various properties, e.g. \(\beta_{L,M}(\epsilon,t...)\). Herein upper\sphinxhyphen{}case \(L,M\) usually refer to observables or the general case, whilst lower\sphinxhyphen{}case \((l,m)\) usually refer specifically to the photoelectron wavefunction partial waves (see {\hyperref[\detokenize{backmatter/glossary:term-partial-wave-expansion}]{\sphinxtermref{\DUrole{xref,std,std-term}{partial\sphinxhyphen{}wave expansion}}}}), and \((l,\lambda)\) usually denote these terms referenced specifically to the molecular frame.

\sphinxlineitem{ADMs\index{ADMs@\spxentry{ADMs}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-ADMs}}}
\sphinxAtStartPar
Expansion parameters \(A_{Q,S}^{K}(t)\) for describing a molecular ensemble alignment described as a set of axis distribution moments, usually expanded as Wigner rotation matrix element, spherical harmonics or Legendre polynomial functions. See \hyperref[\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}]{Sect.\@ \ref{\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}}} for details.

\sphinxlineitem{axis distribution moments\index{axis distribution moments@\spxentry{axis distribution moments}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-axis-distribution-moments}}}
\sphinxAtStartPar
See {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}.

\sphinxlineitem{MS\index{MS@\spxentry{MS}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-MS}}}
\sphinxAtStartPar
Molecular symmetry group. Symmetry group classification of a molecule, isomorphic to the point group in rigid molecules. See Bunker and Jensen {[}\hyperlink{cite.backmatter/bibliography:id548}{89}{]} for discussion.

\sphinxlineitem{PG\index{PG@\spxentry{PG}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-PG}}}
\sphinxAtStartPar
Point group. Symmetry group classification of a molecule, strictly only applicable to rigid systems. See {\hyperref[\detokenize{backmatter/glossary:term-MS}]{\sphinxtermref{\DUrole{xref,std,std-term}{MS}}}} for more general case.

\sphinxlineitem{HOMO\index{HOMO@\spxentry{HOMO}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-HOMO}}}
\sphinxAtStartPar
Highest occupied molecular orbital. Short\sphinxhyphen{}hand for the outermost (highest energy) valence orbital, also often used in the form HOMO\sphinxhyphen{}n to number lower\sphinxhyphen{}lying orbitals in reverse energetic order, e.g. HOMO\sphinxhyphen{}1 for the penultimate valence orbital.

\sphinxlineitem{VMI\index{VMI@\spxentry{VMI}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-VMI}}}
\sphinxAtStartPar
Velocity\sphinxhyphen{}map imaging. Experimental technique for measuring energy and angle\sphinxhyphen{}resolved photoelectron “images”.

\sphinxlineitem{RWP\index{RWP@\spxentry{RWP}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-RWP}}}
\sphinxAtStartPar
Rotational wavepacket. A purely rotational wavepacket (superposition of rotational eigenstates) in a molecular system, typically created via cascaded Raman interaction with a (relatively) strong IR pulse (\(>10^{12}\)\textasciitilde{}Wcm\(^{-2}\)). The resulting time\sphinxhyphen{}dependent molecular axis distribution can be described by a set of {\hyperref[\detokenize{backmatter/glossary:term-ADMs}]{\sphinxtermref{\DUrole{xref,std,std-term}{ADMs}}}}.

\sphinxlineitem{partial\sphinxhyphen{}wave expansion\index{partial\sphinxhyphen{}wave expansion@\spxentry{partial\sphinxhyphen{}wave expansion}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-partial-wave-expansion}}}
\sphinxAtStartPar
General term for an expansion of a wavefunction in a spherical\sphinxhyphen{}wave basis in scattering theory, typically spherical harmonics \(Y_{l,m}\), where the spherical harmonics are the partial wave basis set, and specific \(\psi_{l,m}\) terms can be referred to as partial waves \sphinxhyphen{} see for example Refs. {[}\hyperlink{cite.backmatter/bibliography:id740}{145}, \hyperlink{cite.backmatter/bibliography:id789}{146}, \hyperlink{cite.backmatter/bibliography:id868}{147}{]}. Note conventional use of lower\sphinxhyphen{}case \(l,m\) for these components, whilst upper\sphinxhyphen{}case \(L,M\) are usually used for labelling harmonics pertaining to observable quantities (see {\hyperref[\detokenize{backmatter/glossary:term-anisotropy-paramters}]{\sphinxtermref{\DUrole{xref,std,std-term}{anisotropy paramters}}}}).

\sphinxlineitem{partial\sphinxhyphen{}waves\index{partial\sphinxhyphen{}waves@\spxentry{partial\sphinxhyphen{}waves}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-partial-waves}}}
\sphinxAtStartPar
See {\hyperref[\detokenize{backmatter/glossary:term-partial-wave-expansion}]{\sphinxtermref{\DUrole{xref,std,std-term}{partial\sphinxhyphen{}wave expansion}}}}.

\sphinxlineitem{channel functions\index{channel functions@\spxentry{channel functions}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-channel-functions}}}
\sphinxAtStartPar
Geometric (angular\sphinxhyphen{}momentum) coupling parameters in the tensor formulation of photoionzation, denoted by \(\varUpsilon_{L,M}^{u,\zeta\zeta'}\) herein. See Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}. These can be regarded as an alternative form of the more traditional geometric coupling parameters (Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1}). See also {\hyperref[\detokenize{backmatter/glossary:term-geometric-coupling-parameters}]{\sphinxtermref{\DUrole{xref,std,std-term}{geometric coupling parameters}}}}.

\sphinxlineitem{geometric coupling parameters\index{geometric coupling parameters@\spxentry{geometric coupling parameters}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-geometric-coupling-parameters}}}
\sphinxAtStartPar
Geometric (angular\sphinxhyphen{}momentum) coupling parameters in photoionization, comprising all angular\sphinxhyphen{}momentum coupling terms. Denoted \(\gamma_{l,m}\) herein (Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}), and \(\gamma_{\alpha\alpha_{+}l\lambda ml'\lambda'm'}\) for the coherent square of these terms (Eq. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:I-reduced-LF-2_45-vol1}). See also {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}}.

\sphinxlineitem{radial matrix elements\index{radial matrix elements@\spxentry{radial matrix elements}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-radial-matrix-elements}}}
\sphinxAtStartPar
General term for the radial part of the ionization matrix elements, after separation into radial and angular parts. Although this type of separation may be applied in many cases, herein this term always refers specifically to the radial (or reduced) \sphinxstyleemphasis{photoionization dipole matrix elements}. These are denoted herein as \(\mathbf{r}_{k,l,m}\) (see Eqs. \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam}, \eqref{equation:part1/theory_photoionization_dynamics_140723:eq:r-kllam-integral}), and also appear as \(\mathbb{I}^{\zeta\zeta'}\) for the coherent square of these terms in the {\hyperref[\detokenize{backmatter/glossary:term-channel-functions}]{\sphinxtermref{\DUrole{xref,std,std-term}{channel functions}}}} (tensor) form, see Eq. \eqref{equation:part1/theory_tensor_formalism_160723:eqn:channel-fns}. These complex matrix elements are the unknowns to be determined in quantum metrology with photoelectons fitting or reconstruction problems.

\sphinxlineitem{symmetrized harmonics\index{symmetrized harmonics@\spxentry{symmetrized harmonics}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-symmetrized-harmonics}}}
\sphinxAtStartPar
A basis set of spherical harmonics expanded/defined for a given point\sphinxhyphen{}group symmetry. See \hyperref[\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}]{Sect.\@ \ref{\detokenize{part1/theory_observables_intro_100723:sec-theory-sym-harm-into}}}, particularly Eq. \eqref{equation:part1/theory_observables_intro_100723:eq:symHarm-defn}, for details. Other symmetrized functions may assume such a basis set, or explicitly incorporate symmetry parameters/weightings directly, as is the case for symmetrized {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} which incorporate symmetry parameters \(b_{hl\lambda}^{\Gamma\mu}\) into the value of the matrix elements.

\sphinxlineitem{frame rotation\index{frame rotation@\spxentry{frame rotation}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-frame-rotation}}}
\sphinxAtStartPar
General term for the rotation of one frame of reference (corresponding to a set of \(x,y,z\) axes), e.g. as defined by an electric field vector in the laboratory, to another, e.g. as defined by a molecular axis. Usually specified herein in terms of a set of Euler angles \(R_{\hat{n}}=\{\chi,\Theta,\Phi\}\), and can also be schematically denoted as, e.g., \((x,y,z)\leftarrow(x',y',z')\).

\sphinxlineitem{Euler angles\index{Euler angles@\spxentry{Euler angles}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-Euler-angles}}}
\sphinxAtStartPar
A set of angles \(R_{\hat{n}}=\{\chi,\Theta,\Phi\}\) defining a frame rotation. For \sphinxhref{https://en.wikipedia.org/wiki/Euler\_angles}{discussion see Wikipedia}{[}\hyperlink{cite.backmatter/bibliography:id960}{148}{]} and Zare, Chpt. 3 {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]}.

\sphinxlineitem{Wigner rotation matrix elements\index{Wigner rotation matrix elements@\spxentry{Wigner rotation matrix elements}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-Wigner-rotation-matrix-elements}}}
\sphinxAtStartPar
A function defining a basis set for rotations in three\sphinxhyphen{}dimensions (\(SO(3)\)). Also known as “Wigner D\sphinxhyphen{}matrix elements”. For \sphinxhref{https://en.wikipedia.org/wiki/Wigner\_D-matrix}{discussion see Wikipedia}{[}\hyperlink{cite.backmatter/bibliography:id964}{149}{]} and Zare, Chpt. 3 {[}\hyperlink{cite.backmatter/bibliography:id990}{83}{]}.

\sphinxlineitem{molecular alignment\index{molecular alignment@\spxentry{molecular alignment}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-molecular-alignment}}}
\sphinxAtStartPar
General term for describing the case where molecules have some alignment in the {\hyperref[\detokenize{backmatter/glossary:term-LF}]{\sphinxtermref{\DUrole{xref,std,std-term}{LF}}}}, as compared to an isotropic distribution. Defined herein terms of molecular {\hyperref[\detokenize{backmatter/glossary:term-axis-distribution-moments}]{\sphinxtermref{\DUrole{xref,std,std-term}{axis distribution moments}}}} and associated parameters \(A_{Q,S}^{K}(t)\). See \hyperref[\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}]{Sect.\@ \ref{\detokenize{part1/theory_molecular_alignment_170723:sect-theory-alignment}}} for details.

\sphinxlineitem{bootstrap retrieval protocol\index{bootstrap retrieval protocol@\spxentry{bootstrap retrieval protocol}|spxpagem}\phantomsection\label{\detokenize{backmatter/glossary:term-bootstrap-retrieval-protocol}}}
\sphinxAtStartPar
General term of a retrieval method which determines successively more complex properties of a system in multiple steps, each of which builds on the previous step and adds complexity. Herein, used for the “generalised bootstrapping” method for {\hyperref[\detokenize{backmatter/glossary:term-radial-matrix-elements}]{\sphinxtermref{\DUrole{xref,std,std-term}{radial matrix elements}}}} retrieval from photoionzation data. For general useage, \sphinxhref{https://en.wikipedia.org/wiki/Bootstrapping}{see wikipedia’s \sphinxstyleemphasis{Bootstrapping} page}.

\end{description}

\sphinxstepscope


\part{Builds and versions}

\sphinxstepscope


\chapter{Build versions and config tests}
\label{\detokenize{tests/build_versions_checks:build-versions-and-config-tests}}\label{\detokenize{tests/build_versions_checks::doc}}

\section{Versions}
\label{\detokenize{tests/build_versions_checks:versions}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{scooby}
\PYG{n}{scooby}\PYG{o}{.}\PYG{n}{Report}\PYG{p}{(}\PYG{n}{additional}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pemtk}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{epsproc}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{xarray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pandas}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{scipy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{matplotlib}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{jupyterlab}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{plotly}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{holoviews}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
* sparse not found, sparse matrix forms not available. 
* natsort not found, some sorting functions not available. 
* Setting plotter defaults with epsproc.basicPlotters.setPlotters(). Run directly to modify, or change options in local env.
* Set Holoviews with bokeh.
* pyevtk not found, VTK export not available. 
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
OMP: Info \PYGZsh{}276: omp\PYGZus{}set\PYGZus{}nested routine deprecated, please use omp\PYGZus{}set\PYGZus{}max\PYGZus{}active\PYGZus{}levels instead.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
  Date: Thu Oct 26 06:11:46 2023 EDT

                OS : Linux
            CPU(s) : 64
           Machine : x86\PYGZus{}64
      Architecture : 64bit
               RAM : 62.8 GiB
       Environment : Jupyter
       File system : btrfs

  Python 3.10.11 | packaged by conda\PYGZhy{}forge | (main, May 10 2023, 18:58:44)
  [GCC 11.3.0]

             pemtk : 0.0.1
           epsproc : 1.3.2\PYGZhy{}dev
            xarray : 2022.3.0
            pandas : 1.5.3
             scipy : 1.10.1
        matplotlib : 3.5.3
        jupyterlab : 3.6.3
            plotly : 5.15.0
         holoviews : 1.16.2
             numpy : 1.23.5
           IPython : 8.13.2
            scooby : 0.7.2
\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{!}jupyter\PYGZhy{}book\PYG{+w}{ }\PYGZhy{}\PYGZhy{}version
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Jupyter Book      : 0.15.1
External ToC      : 0.3.1
MyST\PYGZhy{}Parser       : 0.18.1
MyST\PYGZhy{}NB           : 0.17.2
Sphinx Book Theme : 1.0.1
Jupyter\PYGZhy{}Cache     : 0.6.1
NbClient          : 0.7.4
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{!}jupyter\PYG{+w}{ }\PYGZhy{}\PYGZhy{}version
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Selected Jupyter core packages...
IPython          : 8.13.2
ipykernel        : 6.23.0
ipywidgets       : 8.0.6
jupyter\PYGZus{}client   : 8.2.0
jupyter\PYGZus{}core     : 5.3.0
jupyter\PYGZus{}server   : 2.5.0
jupyterlab       : 3.6.3
nbclient         : 0.7.4
nbconvert        : 7.4.0
nbformat         : 5.8.0
notebook         : 6.5.4
qtconsole        : not installed
traitlets        : 5.9.0
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Docker build env}
\label{\detokenize{tests/build_versions_checks:docker-build-env}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Container name from within running container (from https://stackoverflow.com/a/64790547)}
\PYG{o}{!}dig\PYG{+w}{ }\PYGZhy{}x\PYG{+w}{ }\PYG{l+s+sb}{`}ifconfig\PYG{+w}{ }eth0\PYG{+w}{ }\PYG{p}{|}\PYG{+w}{ }grep\PYG{+w}{ }\PYG{l+s+s1}{\PYGZsq{}inet\PYGZsq{}}\PYG{+w}{ }\PYG{p}{|}\PYG{+w}{ }awk\PYG{+w}{ }\PYG{l+s+s1}{\PYGZsq{}\PYGZob{}print \PYGZdl{}2\PYGZcb{}\PYGZsq{}}\PYG{l+s+sb}{`}\PYG{+w}{ }+short\PYG{+w}{ }\PYG{p}{|}\PYG{+w}{ }cut\PYG{+w}{ }\PYGZhy{}d\PYG{l+s+s1}{\PYGZsq{}.\PYGZsq{}}\PYG{+w}{ }\PYGZhy{}f1
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
QM3\PYGZhy{}jupyterlab\PYGZhy{}local\PYGZhy{}190723
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Book versions}
\label{\detokenize{tests/build_versions_checks:book-versions}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{QMpath} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/jovyan/QM3}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{o}{!}git\PYG{+w}{ }\PYGZhy{}C\PYG{+w}{ }\PYG{o}{\PYGZob{}}QMpath\PYG{o}{\PYGZcb{}}\PYG{+w}{ }branch
\PYG{o}{!}git\PYG{+w}{ }\PYGZhy{}C\PYG{+w}{ }\PYG{o}{\PYGZob{}}QMpath\PYG{o}{\PYGZcb{}}\PYG{+w}{ }log\PYG{+w}{ }\PYGZhy{}\PYGZhy{}format\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZpc{}H\PYGZdq{}}\PYG{+w}{ }\PYGZhy{}n\PYG{+w}{ }\PYG{l+m}{1}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
  gh\PYGZhy{}pages
  main
* \PYG{Color+ColorGreen}{postSubmissionUpdates}
  reviewJuly2023
f52dd11e89d97e868f87494654d3f4867c6234dc
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check current remote commits}
\PYG{o}{!}git\PYG{+w}{ }ls\PYGZhy{}remote\PYG{+w}{ }\PYGZhy{}\PYGZhy{}heads\PYG{+w}{ }https://github.com/phockett/Quantum\PYGZhy{}Metrology\PYGZhy{}with\PYGZhy{}Photoelectrons\PYGZhy{}Vol3
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
2ba93b16f2ab0a9426bca953f8829206f4c0501e	refs/heads/gh\PYGZhy{}pages
80324f6465297c07575f214f2f09caf197d40f94	refs/heads/main
230bb9d8ef6ab0a46c306f0e092e424f6ba23a21	refs/heads/postSubmissionUpdates
863f1a92533b5ced778b263cd00f09ae3cfc9eb3	refs/heads/reviewJuly2023
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Github pkg versions}
\label{\detokenize{tests/build_versions_checks:github-pkg-versions}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pathlib} \PYG{k+kn}{import} \PYG{n}{Path}
\PYG{k+kn}{import} \PYG{n+nn}{epsproc} \PYG{k}{as} \PYG{n+nn}{ep}
\PYG{n}{ep}\PYG{o}{.}\PYG{n+nv+vm}{\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsq{}/home/jovyan/github/ePSproc/epsproc/\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pemtk} \PYG{k}{as} \PYG{n+nn}{pm}
\PYG{n}{pm}\PYG{o}{.}\PYG{n+nv+vm}{\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsq{}/home/jovyan/github/PEMtk/pemtk/\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check current Git commit for local ePSproc version \PYGZhy{} NOTE THIS ONLY WORKS FOR INSTALLED FROM GIT CLONES}
\PYG{c+c1}{\PYGZsh{} from pathlib import Path}
\PYG{c+c1}{\PYGZsh{} import epsproc as ep}
\PYG{o}{!}git\PYG{+w}{ }\PYGZhy{}C\PYG{+w}{ }\PYG{o}{\PYGZob{}}Path\PYG{o}{(}ep.\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}\PYG{o}{)}.parent\PYG{o}{\PYGZcb{}}\PYG{+w}{ }branch
\PYG{o}{!}git\PYG{+w}{ }\PYGZhy{}C\PYG{+w}{ }\PYG{o}{\PYGZob{}}Path\PYG{o}{(}ep.\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}\PYG{o}{)}.parent\PYG{o}{\PYGZcb{}}\PYG{+w}{ }log\PYG{+w}{ }\PYGZhy{}\PYGZhy{}format\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZpc{}H\PYGZdq{}}\PYG{+w}{ }\PYGZhy{}n\PYG{+w}{ }\PYG{l+m}{1}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
* \PYG{Color+ColorGreen}{3d\PYGZhy{}AFPAD\PYGZhy{}dev}
c1eedf10631cb17fe33421427c195a2391369c37
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check current remote commits}
\PYG{o}{!}git\PYG{+w}{ }ls\PYGZhy{}remote\PYG{+w}{ }\PYGZhy{}\PYGZhy{}heads\PYG{+w}{ }https://github.com/phockett/ePSproc
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
c1eedf10631cb17fe33421427c195a2391369c37	refs/heads/3d\PYGZhy{}AFPAD\PYGZhy{}dev
897d73392a7b32ffba4ca6b6b4755c61e7c1c8d7	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/certifi\PYGZhy{}2022.12.7
457f8cd85d89bd6474296b6c01e5165a4a7ce7fc	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/cryptography\PYGZhy{}39.0.1
2855573d0f088b45d19acf2fd9a71eeb7af0a29b	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/ipython\PYGZhy{}8.10.0
92c661789a7d2927f2b53d7266f57de70b3834fa	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/mistune\PYGZhy{}2.0.3
fe1e9540c7b91fe571f60562acd31d8e489d491e	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/nbconvert\PYGZhy{}6.5.1
70b80a1e3a54de91c2bfe3b6be82d611fcfd5f43	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/pillow\PYGZhy{}9.3.0
92fc79b09aafedadcb645f88bb7ed771c96d5b52	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/setuptools\PYGZhy{}65.5.1
fa33ed8d63a5c4a4043cc4c261059cc09e4c2bf7	refs/heads/dependabot/pip/notes/envs/envs\PYGZhy{}versioned/wheel\PYGZhy{}0.38.1
41cdfe43750e08c510f98b05e024a9c62da42771	refs/heads/dependabot/pip/setuptools\PYGZhy{}65.5.1
7e4270370d66df44c334675ac487c87d702408da	refs/heads/dev
1c0b8fd409648f07c85f4f20628b5ea7627e0c4e	refs/heads/master
69cd89ce5bc0ad6d465a4bd8df6fba15d3fd1aee	refs/heads/numba\PYGZhy{}tests
ea30878c842f09d525fbf39fa269fa2302a13b57	refs/heads/revert\PYGZhy{}9\PYGZhy{}master
baf0be0c962e8ab3c3df57c8f70f0e939f99cbd7	refs/heads/testDev
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check current Git commit for local ePSproc version \PYGZhy{} NOTE THIS ONLY WORKS FOR INSTALLED FROM GIT CLONES}
\PYG{c+c1}{\PYGZsh{} from pathlib import Path}
\PYG{c+c1}{\PYGZsh{} import epsproc as ep}
\PYG{o}{!}git\PYG{+w}{ }\PYGZhy{}C\PYG{+w}{ }\PYG{o}{\PYGZob{}}Path\PYG{o}{(}pm.\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}\PYG{o}{)}.parent\PYG{o}{\PYGZcb{}}\PYG{+w}{ }branch
\PYG{o}{!}git\PYG{+w}{ }\PYGZhy{}C\PYG{+w}{ }\PYG{o}{\PYGZob{}}Path\PYG{o}{(}pm.\PYGZus{}\PYGZus{}file\PYGZus{}\PYGZus{}\PYG{o}{)}.parent\PYG{o}{\PYGZcb{}}\PYG{+w}{ }log\PYG{+w}{ }\PYGZhy{}\PYGZhy{}format\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}\PYGZpc{}H\PYGZdq{}}\PYG{+w}{ }\PYGZhy{}n\PYG{+w}{ }\PYG{l+m}{1}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
* \PYG{Color+ColorGreen}{master}
465c161ca9d2c2f453a58f16c8f334f5e2c07eaa
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Check current remote commits}
\PYG{o}{!}git\PYG{+w}{ }ls\PYGZhy{}remote\PYG{+w}{ }\PYGZhy{}\PYGZhy{}heads\PYG{+w}{ }https://github.com/phockett/PEMtk
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
465c161ca9d2c2f453a58f16c8f334f5e2c07eaa	refs/heads/master
3f4686dffdbb310f15692f978ba36d6a3d15e8d3	refs/heads/mfFittingDev
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Full conda env}
\label{\detokenize{tests/build_versions_checks:full-conda-env}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{!}conda\PYG{+w}{ }list
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{} packages in environment at /opt/conda:
\PYGZsh{}
\PYGZsh{} Name                    Version                   Build  Channel
\PYGZus{}libgcc\PYGZus{}mutex             0.1                 conda\PYGZus{}forge    conda\PYGZhy{}forge
\PYGZus{}openmp\PYGZus{}mutex             4.5                  2\PYGZus{}kmp\PYGZus{}llvm    conda\PYGZhy{}forge
accessible\PYGZhy{}pygments       0.0.4                    pypi\PYGZus{}0    pypi
aiofiles                  22.1.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
aiosqlite                 0.19.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
alabaster                 0.7.13                   pypi\PYGZus{}0    pypi
alembic                   1.10.4             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
altair                    5.0.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
ansi2html                 1.8.0           py310hff52083\PYGZus{}1    conda\PYGZhy{}forge
anyio                     3.6.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
aom                       3.5.0                h27087fc\PYGZus{}0    conda\PYGZhy{}forge
argon2\PYGZhy{}cffi               21.3.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
argon2\PYGZhy{}cffi\PYGZhy{}bindings      21.2.0          py310h5764c6d\PYGZus{}3    conda\PYGZhy{}forge
arrow                     1.2.3                    pypi\PYGZus{}0    pypi
arrow\PYGZhy{}cpp                 12.0.0           ha770c72\PYGZus{}1\PYGZus{}cpu    conda\PYGZhy{}forge
asteval                   0.9.31             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
astropy                   5.3.1           py310h278f3c1\PYGZus{}0    conda\PYGZhy{}forge
asttokens                 2.2.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
async\PYGZus{}generator           1.10                       py\PYGZus{}0    conda\PYGZhy{}forge
attrs                     23.1.0             pyh71513ae\PYGZus{}1    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}auth                0.6.26               h2c7c9e7\PYGZus{}6    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}cal                 0.5.26               h71eb795\PYGZus{}0    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}common              0.8.17               hd590300\PYGZus{}0    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}compression         0.2.16               h4f47f36\PYGZus{}6    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}event\PYGZhy{}stream        0.2.20               h69ce273\PYGZus{}6    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}http                0.7.7                h7b8353a\PYGZus{}3    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}io                  0.13.21              h2c99d58\PYGZus{}4    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}mqtt                0.8.6               h3a1964a\PYGZus{}15    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}s3                  0.2.8                h0933b68\PYGZus{}4    conda\PYGZhy{}forge
aws\PYGZhy{}c\PYGZhy{}sdkutils            0.1.9                h4f47f36\PYGZus{}1    conda\PYGZhy{}forge
aws\PYGZhy{}checksums             0.1.14               h4f47f36\PYGZus{}6    conda\PYGZhy{}forge
aws\PYGZhy{}crt\PYGZhy{}cpp               0.19.9               h85076f6\PYGZus{}5    conda\PYGZhy{}forge
aws\PYGZhy{}sdk\PYGZhy{}cpp               1.10.57             hf40e4db\PYGZus{}10    conda\PYGZhy{}forge
babel                     2.12.1             pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
backcall                  0.2.0              pyh9f0ad1d\PYGZus{}0    conda\PYGZhy{}forge
backports                 1.0                pyhd8ed1ab\PYGZus{}3    conda\PYGZhy{}forge
backports.functools\PYGZus{}lru\PYGZus{}cache 1.6.4              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
beautifulsoup4            4.12.2             pyha770c72\PYGZus{}0    conda\PYGZhy{}forge
blas                      2.116                  openblas    conda\PYGZhy{}forge
blas\PYGZhy{}devel                3.9.0           16\PYGZus{}linux64\PYGZus{}openblas    conda\PYGZhy{}forge
bleach                    6.0.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
blinker                   1.6.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
blosc                     1.21.3               hafa529b\PYGZus{}0    conda\PYGZhy{}forge
bokeh                     3.1.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
boltons                   23.0.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
boost\PYGZhy{}cpp                 1.78.0               h6582d0a\PYGZus{}3    conda\PYGZhy{}forge
bottleneck                1.3.7           py310h0a54255\PYGZus{}0    conda\PYGZhy{}forge
brotli                    1.0.9                h166bdaf\PYGZus{}8    conda\PYGZhy{}forge
brotli\PYGZhy{}bin                1.0.9                h166bdaf\PYGZus{}8    conda\PYGZhy{}forge
brotlipy                  0.7.0           py310h5764c6d\PYGZus{}1005    conda\PYGZhy{}forge
brunsli                   0.1                  h9c3ff4c\PYGZus{}0    conda\PYGZhy{}forge
bzip2                     1.0.8                h7f98852\PYGZus{}4    conda\PYGZhy{}forge
c\PYGZhy{}ares                    1.18.1               h7f98852\PYGZus{}0    conda\PYGZhy{}forge
c\PYGZhy{}blosc2                  2.8.0                hf91038e\PYGZus{}1    conda\PYGZhy{}forge
ca\PYGZhy{}certificates           2023.7.22            hbcca054\PYGZus{}0    conda\PYGZhy{}forge
cached\PYGZhy{}property           1.5.2                hd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
cached\PYGZus{}property           1.5.2              pyha770c72\PYGZus{}1    conda\PYGZhy{}forge
cairo                     1.16.0            h35add3b\PYGZus{}1015    conda\PYGZhy{}forge
cartopy                   0.21.1          py310h7eb24ba\PYGZus{}1    conda\PYGZhy{}forge
certifi                   2023.7.22          pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
certipy                   0.1.3                      py\PYGZus{}0    conda\PYGZhy{}forge
cffi                      1.15.1          py310h255011f\PYGZus{}3    conda\PYGZhy{}forge
cfitsio                   4.2.0                hd9d235c\PYGZus{}0    conda\PYGZhy{}forge
cftime                    1.6.2           py310hde88566\PYGZus{}1    conda\PYGZhy{}forge
charls                    2.4.1                hcb278e6\PYGZus{}0    conda\PYGZhy{}forge
charset\PYGZhy{}normalizer        3.1.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
click                     8.1.3           unix\PYGZus{}pyhd8ed1ab\PYGZus{}2    conda\PYGZhy{}forge
cloudpickle               2.2.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
colorama                  0.4.6              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
colorcet                  3.0.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
comm                      0.1.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
conda                     23.3.1          py310hff52083\PYGZus{}0    conda\PYGZhy{}forge
conda\PYGZhy{}package\PYGZhy{}handling    2.0.2              pyh38be061\PYGZus{}0    conda\PYGZhy{}forge
conda\PYGZhy{}package\PYGZhy{}streaming   0.7.0              pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
configurable\PYGZhy{}http\PYGZhy{}proxy   4.5.4                h3b247e2\PYGZus{}2    conda\PYGZhy{}forge
contourpy                 1.0.7           py310hdf3cbec\PYGZus{}0    conda\PYGZhy{}forge
cryptography              40.0.2          py310h34c0648\PYGZus{}0    conda\PYGZhy{}forge
curl                      8.0.1                h588be90\PYGZus{}0    conda\PYGZhy{}forge
cycler                    0.11.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
cython                    0.29.34         py310heca2aa9\PYGZus{}0    conda\PYGZhy{}forge
cytoolz                   0.12.0          py310h5764c6d\PYGZus{}1    conda\PYGZhy{}forge
dash                      2.11.1             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
dask                      2023.5.0           pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
dask\PYGZhy{}core                 2023.5.0           pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
dav1d                     1.0.0                h166bdaf\PYGZus{}1    conda\PYGZhy{}forge
dcw\PYGZhy{}gmt                   2.1.1                ha770c72\PYGZus{}0    conda\PYGZhy{}forge
debugpy                   1.6.7           py310heca2aa9\PYGZus{}0    conda\PYGZhy{}forge
decorator                 5.1.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
defusedxml                0.7.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
dill                      0.3.6              pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
distributed               2023.5.0           pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
docutils                  0.18.1                   pypi\PYGZus{}0    pypi
ducc0                     0.31.0          py310hc6cd4ac\PYGZus{}0    conda\PYGZhy{}forge
entrypoints               0.4                pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
et\PYGZus{}xmlfile                1.1.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
exceptiongroup            1.1.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
executing                 1.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
expat                     2.5.0                hcb278e6\PYGZus{}1    conda\PYGZhy{}forge
fftw                      3.3.10          nompi\PYGZus{}hc118613\PYGZus{}108    conda\PYGZhy{}forge
firefox                   115.0                hd3aeb46\PYGZus{}0    conda\PYGZhy{}forge
flask                     2.3.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
flit\PYGZhy{}core                 3.9.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
fmt                       9.1.0                h924138e\PYGZus{}0    conda\PYGZhy{}forge
font\PYGZhy{}ttf\PYGZhy{}dejavu\PYGZhy{}sans\PYGZhy{}mono 2.37                 hab24e00\PYGZus{}0    conda\PYGZhy{}forge
font\PYGZhy{}ttf\PYGZhy{}inconsolata      3.000                h77eed37\PYGZus{}0    conda\PYGZhy{}forge
font\PYGZhy{}ttf\PYGZhy{}source\PYGZhy{}code\PYGZhy{}pro  2.038                h77eed37\PYGZus{}0    conda\PYGZhy{}forge
font\PYGZhy{}ttf\PYGZhy{}ubuntu           0.83                 hab24e00\PYGZus{}0    conda\PYGZhy{}forge
fontconfig                2.14.2               h14ed4e7\PYGZus{}0    conda\PYGZhy{}forge
fonts\PYGZhy{}conda\PYGZhy{}ecosystem     1                             0    conda\PYGZhy{}forge
fonts\PYGZhy{}conda\PYGZhy{}forge         1                             0    conda\PYGZhy{}forge
fonttools                 4.39.4          py310h2372a71\PYGZus{}0    conda\PYGZhy{}forge
fqdn                      1.5.1                    pypi\PYGZus{}0    pypi
freetype                  2.12.1               hca18f0e\PYGZus{}1    conda\PYGZhy{}forge
freexl                    1.0.6                h166bdaf\PYGZus{}1    conda\PYGZhy{}forge
fsspec                    2023.5.0           pyh1a96a4e\PYGZus{}0    conda\PYGZhy{}forge
future                    0.18.3             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
gdal                      3.6.4           py310hf0ca374\PYGZus{}2    conda\PYGZhy{}forge
geckodriver               0.33.0               hd2f7af9\PYGZus{}0    conda\PYGZhy{}forge
geos                      3.11.2               hcb278e6\PYGZus{}0    conda\PYGZhy{}forge
geotiff                   1.7.1                h480ec47\PYGZus{}8    conda\PYGZhy{}forge
gettext                   0.21.1               h27087fc\PYGZus{}0    conda\PYGZhy{}forge
gflags                    2.2.2             he1b5a44\PYGZus{}1004    conda\PYGZhy{}forge
ghostscript               9.54.0               h27087fc\PYGZus{}2    conda\PYGZhy{}forge
ghp\PYGZhy{}import                2.1.0                    pypi\PYGZus{}0    pypi
giflib                    5.2.1                h0b41bf4\PYGZus{}3    conda\PYGZhy{}forge
gitdb                     4.0.10             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
gitpython                 3.1.31             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
glog                      0.6.0                h6f12383\PYGZus{}0    conda\PYGZhy{}forge
gmp                       6.2.1                h58526e2\PYGZus{}0    conda\PYGZhy{}forge
gmpy2                     2.1.2           py310h3ec546c\PYGZus{}1    conda\PYGZhy{}forge
gmt                       6.4.0               h4733502\PYGZus{}10    conda\PYGZhy{}forge
greenlet                  2.0.2           py310hc6cd4ac\PYGZus{}1    conda\PYGZhy{}forge
gshhg\PYGZhy{}gmt                 2.3.7             ha770c72\PYGZus{}1003    conda\PYGZhy{}forge
h11                       0.14.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
h5netcdf                  1.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
h5py                      3.8.0           nompi\PYGZus{}py310ha66b2ad\PYGZus{}101    conda\PYGZhy{}forge
hdf4                      4.2.15               h501b40f\PYGZus{}6    conda\PYGZhy{}forge
hdf5                      1.14.0          nompi\PYGZus{}hb72d44e\PYGZus{}103    conda\PYGZhy{}forge
holoviews                 1.16.2             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
hvplot                    0.8.4                      py\PYGZus{}0    pyviz
icu                       72.1                 hcb278e6\PYGZus{}0    conda\PYGZhy{}forge
idna                      3.4                pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
imagecodecs               2023.1.23       py310h241fb82\PYGZus{}2    conda\PYGZhy{}forge
imageio                   2.28.1             pyh24c5eb1\PYGZus{}0    conda\PYGZhy{}forge
imagesize                 1.4.1                    pypi\PYGZus{}0    pypi
importlib\PYGZhy{}metadata        6.6.0              pyha770c72\PYGZus{}0    conda\PYGZhy{}forge
importlib\PYGZus{}metadata        6.6.0                hd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
importlib\PYGZus{}resources       5.12.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
ipykernel                 6.23.0             pyh210e3f2\PYGZus{}0    conda\PYGZhy{}forge
ipympl                    0.9.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
ipython                   8.13.2             pyh41d4057\PYGZus{}0    conda\PYGZhy{}forge
ipython\PYGZus{}genutils          0.2.0                      py\PYGZus{}1    conda\PYGZhy{}forge
ipywidgets                8.0.6              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
isoduration               20.11.0                  pypi\PYGZus{}0    pypi
itsdangerous              2.1.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jedi                      0.18.2             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jinja2                    3.1.2              pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
joblib                    1.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
json\PYGZhy{}c                    0.16                 hc379101\PYGZus{}0    conda\PYGZhy{}forge
json5                     0.9.5              pyh9f0ad1d\PYGZus{}0    conda\PYGZhy{}forge
jsonpatch                 1.32               pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jsonpointer               2.0                        py\PYGZus{}0    conda\PYGZhy{}forge
jsonschema                4.17.3             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZhy{}book              0.15.1                   pypi\PYGZus{}0    pypi
jupyter\PYGZhy{}cache             0.6.1                    pypi\PYGZus{}0    pypi
jupyter\PYGZhy{}dash              0.4.2              pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
jupyter\PYGZhy{}server\PYGZhy{}mathjax    0.2.6              pyh5bfe37b\PYGZus{}1    conda\PYGZhy{}forge
jupyter\PYGZus{}client            8.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZus{}core              5.3.0           py310hff52083\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZus{}events            0.6.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZus{}server            2.5.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZus{}server\PYGZus{}fileid     0.9.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZus{}server\PYGZus{}terminals  0.4.4              pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
jupyter\PYGZus{}server\PYGZus{}ydoc       0.8.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyter\PYGZus{}telemetry         0.1.0              pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
jupyter\PYGZus{}ydoc              0.2.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyterhub                4.0.0              pyh2a2186d\PYGZus{}0    conda\PYGZhy{}forge
jupyterhub\PYGZhy{}base           4.0.0              pyh2a2186d\PYGZus{}0    conda\PYGZhy{}forge
jupyterlab                3.6.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyterlab\PYGZhy{}git            0.41.0             pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
jupyterlab\PYGZhy{}spellchecker   0.8.3                    pypi\PYGZus{}0    pypi
jupyterlab\PYGZus{}pygments       0.2.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyterlab\PYGZus{}server         2.22.1             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupyterlab\PYGZus{}widgets        3.0.7              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
jupytext                  1.14.7             pyh5da7574\PYGZus{}0    conda\PYGZhy{}forge
jxrlib                    1.1                  h7f98852\PYGZus{}2    conda\PYGZhy{}forge
kaleido\PYGZhy{}core              0.2.1                h3644ca4\PYGZus{}0    conda\PYGZhy{}forge
kealib                    1.5.1                h3845be2\PYGZus{}3    conda\PYGZhy{}forge
keyutils                  1.6.1                h166bdaf\PYGZus{}0    conda\PYGZhy{}forge
kiwisolver                1.4.4           py310hbf28c38\PYGZus{}1    conda\PYGZhy{}forge
krb5                      1.20.1               h81ceb04\PYGZus{}0    conda\PYGZhy{}forge
latexcodec                2.0.1                    pypi\PYGZus{}0    pypi
lazy\PYGZus{}loader               0.2                pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
lcms2                     2.15                 haa2dc70\PYGZus{}1    conda\PYGZhy{}forge
ld\PYGZus{}impl\PYGZus{}linux\PYGZhy{}64          2.40                 h41732ed\PYGZus{}0    conda\PYGZhy{}forge
lerc                      4.0.0                h27087fc\PYGZus{}0    conda\PYGZhy{}forge
libabseil                 20230125.0      cxx17\PYGZus{}hcb278e6\PYGZus{}1    conda\PYGZhy{}forge
libaec                    1.0.6                hcb278e6\PYGZus{}1    conda\PYGZhy{}forge
libarchive                3.6.2                h3d51595\PYGZus{}0    conda\PYGZhy{}forge
libarrow                  12.0.0           h1cdf7b0\PYGZus{}1\PYGZus{}cpu    conda\PYGZhy{}forge
libavif                   0.11.1               h5cdd6b5\PYGZus{}0    conda\PYGZhy{}forge
libblas                   3.9.0           16\PYGZus{}linux64\PYGZus{}openblas    conda\PYGZhy{}forge
libbrotlicommon           1.0.9                h166bdaf\PYGZus{}8    conda\PYGZhy{}forge
libbrotlidec              1.0.9                h166bdaf\PYGZus{}8    conda\PYGZhy{}forge
libbrotlienc              1.0.9                h166bdaf\PYGZus{}8    conda\PYGZhy{}forge
libcblas                  3.9.0           16\PYGZus{}linux64\PYGZus{}openblas    conda\PYGZhy{}forge
libcrc32c                 1.1.2                h9c3ff4c\PYGZus{}0    conda\PYGZhy{}forge
libcurl                   8.0.1                h588be90\PYGZus{}0    conda\PYGZhy{}forge
libdeflate                1.18                 h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
libedit                   3.1.20191231         he28a2e2\PYGZus{}2    conda\PYGZhy{}forge
libev                     4.33                 h516909a\PYGZus{}1    conda\PYGZhy{}forge
libevent                  2.1.12               h3358134\PYGZus{}0    conda\PYGZhy{}forge
libexpat                  2.5.0                hcb278e6\PYGZus{}1    conda\PYGZhy{}forge
libffi                    3.4.2                h7f98852\PYGZus{}5    conda\PYGZhy{}forge
libgcc\PYGZhy{}ng                 12.2.0              h65d4601\PYGZus{}19    conda\PYGZhy{}forge
libgdal                   3.6.4                hada8d5e\PYGZus{}2    conda\PYGZhy{}forge
libgfortran\PYGZhy{}ng            12.2.0              h69a702a\PYGZus{}19    conda\PYGZhy{}forge
libgfortran5              12.2.0              h337968e\PYGZus{}19    conda\PYGZhy{}forge
libglib                   2.76.4               hebfc3b9\PYGZus{}0    conda\PYGZhy{}forge
libgomp                   12.2.0              h65d4601\PYGZus{}19    conda\PYGZhy{}forge
libgoogle\PYGZhy{}cloud           2.10.0               hac9eb74\PYGZus{}0    conda\PYGZhy{}forge
libgrpc                   1.54.2               hcf146ea\PYGZus{}0    conda\PYGZhy{}forge
libiconv                  1.17                 h166bdaf\PYGZus{}0    conda\PYGZhy{}forge
libjpeg\PYGZhy{}turbo             2.1.5.1              h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
libkml                    1.3.0             h37653c0\PYGZus{}1015    conda\PYGZhy{}forge
liblapack                 3.9.0           16\PYGZus{}linux64\PYGZus{}openblas    conda\PYGZhy{}forge
liblapacke                3.9.0           16\PYGZus{}linux64\PYGZus{}openblas    conda\PYGZhy{}forge
libllvm11                 11.1.0               he0ac6c6\PYGZus{}5    conda\PYGZhy{}forge
libmamba                  1.4.2                hcea66bb\PYGZus{}0    conda\PYGZhy{}forge
libmambapy                1.4.2           py310h1428755\PYGZus{}0    conda\PYGZhy{}forge
libnetcdf                 4.9.2           nompi\PYGZus{}hdf9a29f\PYGZus{}104    conda\PYGZhy{}forge
libnghttp2                1.52.0               h61bc06f\PYGZus{}0    conda\PYGZhy{}forge
libnsl                    2.0.0                h7f98852\PYGZus{}0    conda\PYGZhy{}forge
libnuma                   2.0.16               h0b41bf4\PYGZus{}1    conda\PYGZhy{}forge
libopenblas               0.3.21          pthreads\PYGZus{}h78a6416\PYGZus{}3    conda\PYGZhy{}forge
libpng                    1.6.39               h753d276\PYGZus{}0    conda\PYGZhy{}forge
libpq                     15.3                 hbcd7760\PYGZus{}0    conda\PYGZhy{}forge
libprotobuf               3.21.12              h3eb15da\PYGZus{}0    conda\PYGZhy{}forge
librttopo                 1.1.0               h0d5128d\PYGZus{}13    conda\PYGZhy{}forge
libsodium                 1.0.18               h36c2ea0\PYGZus{}1    conda\PYGZhy{}forge
libsolv                   0.7.23               h3eb15da\PYGZus{}0    conda\PYGZhy{}forge
libspatialite             5.0.1               h7d1ca68\PYGZus{}25    conda\PYGZhy{}forge
libsqlite                 3.41.2               h2797004\PYGZus{}1    conda\PYGZhy{}forge
libssh2                   1.10.0               hf14f497\PYGZus{}3    conda\PYGZhy{}forge
libstdcxx\PYGZhy{}ng              12.2.0              h46fd767\PYGZus{}19    conda\PYGZhy{}forge
libthrift                 0.18.1               h8fd135c\PYGZus{}1    conda\PYGZhy{}forge
libtiff                   4.5.0                ha587672\PYGZus{}6    conda\PYGZhy{}forge
libutf8proc               2.8.0                h166bdaf\PYGZus{}0    conda\PYGZhy{}forge
libuuid                   2.38.1               h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
libuv                     1.44.2               h166bdaf\PYGZus{}0    conda\PYGZhy{}forge
libwebp\PYGZhy{}base              1.3.0                h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
libxcb                    1.13              h7f98852\PYGZus{}1004    conda\PYGZhy{}forge
libxml2                   2.10.4               hfdac1af\PYGZus{}0    conda\PYGZhy{}forge
libzip                    1.9.2                hc929e4a\PYGZus{}1    conda\PYGZhy{}forge
libzlib                   1.2.13               h166bdaf\PYGZus{}4    conda\PYGZhy{}forge
libzopfli                 1.0.3                h9c3ff4c\PYGZus{}0    conda\PYGZhy{}forge
linkify\PYGZhy{}it\PYGZhy{}py             2.0.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
llvm\PYGZhy{}openmp               16.0.3               h4dfa4b3\PYGZus{}0    conda\PYGZhy{}forge
llvmlite                  0.39.1          py310h58363a5\PYGZus{}1    conda\PYGZhy{}forge
lmfit                     1.2.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
locket                    1.0.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
lz4                       4.3.2           py310h0cfdcf0\PYGZus{}0    conda\PYGZhy{}forge
lz4\PYGZhy{}c                     1.9.4                hcb278e6\PYGZus{}0    conda\PYGZhy{}forge
lzo                       2.10              h516909a\PYGZus{}1000    conda\PYGZhy{}forge
mako                      1.2.4              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
mamba                     1.4.2           py310h51d5547\PYGZus{}0    conda\PYGZhy{}forge
markdown                  3.4.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
markdown\PYGZhy{}it\PYGZhy{}py            2.2.0                    pypi\PYGZus{}0    pypi
markupsafe                2.1.2           py310h1fa729e\PYGZus{}0    conda\PYGZhy{}forge
mathjax                   2.7.7                ha770c72\PYGZus{}3    conda\PYGZhy{}forge
matplotlib                3.5.3                    pypi\PYGZus{}0    pypi
matplotlib\PYGZhy{}inline         0.1.6              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
mdit\PYGZhy{}py\PYGZhy{}plugins           0.3.5                    pypi\PYGZus{}0    pypi
mdurl                     0.1.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
mistune                   2.0.5              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
mpc                       1.3.1                hfe3b2da\PYGZus{}0    conda\PYGZhy{}forge
mpfr                      4.2.0                hb012696\PYGZus{}0    conda\PYGZhy{}forge
mpmath                    1.3.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
msgpack\PYGZhy{}python            1.0.5           py310hdf3cbec\PYGZus{}0    conda\PYGZhy{}forge
munkres                   1.1.4              pyh9f0ad1d\PYGZus{}0    conda\PYGZhy{}forge
myst\PYGZhy{}nb                   0.17.2                   pypi\PYGZus{}0    pypi
myst\PYGZhy{}parser               0.18.1                   pypi\PYGZus{}0    pypi
nbclassic                 1.0.0              pyhb4ecaf3\PYGZus{}1    conda\PYGZhy{}forge
nbclient                  0.7.4              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nbconvert                 7.4.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nbconvert\PYGZhy{}core            7.4.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nbconvert\PYGZhy{}pandoc          7.4.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nbdime                    3.2.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nbformat                  5.8.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
ncurses                   6.3                  h27087fc\PYGZus{}1    conda\PYGZhy{}forge
nest\PYGZhy{}asyncio              1.5.6              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
netcdf4                   1.6.4           nompi\PYGZus{}py310hde23a83\PYGZus{}100    conda\PYGZhy{}forge
networkx                  3.1                pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nodejs                    16.19.0              h4abf6b9\PYGZus{}1    conda\PYGZhy{}forge
nomkl                     1.0                  h5ca1d4c\PYGZus{}0    conda\PYGZhy{}forge
notebook                  6.5.4              pyha770c72\PYGZus{}0    conda\PYGZhy{}forge
notebook\PYGZhy{}shim             0.2.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
nspr                      4.35                 h27087fc\PYGZus{}0    conda\PYGZhy{}forge
nss                       3.89                 he45b914\PYGZus{}0    conda\PYGZhy{}forge
numba                     0.56.4          py310h0e39c9b\PYGZus{}1    conda\PYGZhy{}forge
numexpr                   2.8.4           py310h690d005\PYGZus{}100    conda\PYGZhy{}forge
numpy                     1.23.5          py310h53a5b5f\PYGZus{}0    conda\PYGZhy{}forge
oauthlib                  3.2.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
openblas                  0.3.21          pthreads\PYGZus{}h320a7e8\PYGZus{}3    conda\PYGZhy{}forge
openjpeg                  2.5.0                hfec8fc6\PYGZus{}2    conda\PYGZhy{}forge
openpyxl                  3.1.2           py310h2372a71\PYGZus{}0    conda\PYGZhy{}forge
openssl                   3.1.1                hd590300\PYGZus{}1    conda\PYGZhy{}forge
orc                       1.8.3                hfdbbad2\PYGZus{}0    conda\PYGZhy{}forge
outcome                   1.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
packaging                 23.1               pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pamela                    1.0.0                      py\PYGZus{}0    conda\PYGZhy{}forge
pandas                    1.5.3           py310h9b08913\PYGZus{}1    conda\PYGZhy{}forge
pandoc                    2.19.2               h32600fe\PYGZus{}2    conda\PYGZhy{}forge
pandocfilters             1.5.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
panel                     1.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
param                     1.13.0             pyh1a96a4e\PYGZus{}0    conda\PYGZhy{}forge
parquet\PYGZhy{}cpp               1.5.1                         2    conda\PYGZhy{}forge
parso                     0.8.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
partd                     1.4.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
patsy                     0.5.3              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pcre                      8.45                 h9c3ff4c\PYGZus{}0    conda\PYGZhy{}forge
pcre2                     10.40                hc3806b6\PYGZus{}0    conda\PYGZhy{}forge
pexpect                   4.8.0              pyh1a96a4e\PYGZus{}2    conda\PYGZhy{}forge
pickleshare               0.7.5                   py\PYGZus{}1003    conda\PYGZhy{}forge
pillow                    9.5.0           py310h065c6d2\PYGZus{}0    conda\PYGZhy{}forge
pip                       23.1.2             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pixman                    0.40.0               h36c2ea0\PYGZus{}0    conda\PYGZhy{}forge
pkgutil\PYGZhy{}resolve\PYGZhy{}name      1.3.10             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
platformdirs              3.5.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
plotly                    5.15.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pluggy                    1.0.0              pyhd8ed1ab\PYGZus{}5    conda\PYGZhy{}forge
pooch                     1.7.0              pyha770c72\PYGZus{}3    conda\PYGZhy{}forge
poppler                   23.05.0              hd18248d\PYGZus{}1    conda\PYGZhy{}forge
poppler\PYGZhy{}data              0.4.12               hd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
postgresql                15.3                 h814edd5\PYGZus{}0    conda\PYGZhy{}forge
proj                      9.2.0                h8ffa02c\PYGZus{}0    conda\PYGZhy{}forge
prometheus\PYGZus{}client         0.16.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
prompt\PYGZhy{}toolkit            3.0.38             pyha770c72\PYGZus{}0    conda\PYGZhy{}forge
prompt\PYGZus{}toolkit            3.0.38               hd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
protobuf                  4.21.12         py310heca2aa9\PYGZus{}0    conda\PYGZhy{}forge
psutil                    5.9.5           py310h1fa729e\PYGZus{}0    conda\PYGZhy{}forge
pthread\PYGZhy{}stubs             0.4               h36c2ea0\PYGZus{}1001    conda\PYGZhy{}forge
ptyprocess                0.7.0              pyhd3deb0d\PYGZus{}0    conda\PYGZhy{}forge
pure\PYGZus{}eval                 0.2.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
py\PYGZhy{}cpuinfo                9.0.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyarrow                   12.0.0          py310he6bfd7f\PYGZus{}1\PYGZus{}cpu    conda\PYGZhy{}forge
pybind11\PYGZhy{}abi              4                    hd8ed1ab\PYGZus{}3    conda\PYGZhy{}forge
pybtex                    0.24.0                   pypi\PYGZus{}0    pypi
pybtex\PYGZhy{}docutils           1.0.2                    pypi\PYGZus{}0    pypi
pycosat                   0.6.4           py310h5764c6d\PYGZus{}1    conda\PYGZhy{}forge
pycparser                 2.21               pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyct                      0.4.6                      py\PYGZus{}0    conda\PYGZhy{}forge
pyct\PYGZhy{}core                 0.4.6                      py\PYGZus{}0    conda\PYGZhy{}forge
pycurl                    7.45.1          py310h60f9ec7\PYGZus{}3    conda\PYGZhy{}forge
pydata\PYGZhy{}sphinx\PYGZhy{}theme       0.13.3                   pypi\PYGZus{}0    pypi
pyerfa                    2.0.0.3         py310h0a54255\PYGZus{}0    conda\PYGZhy{}forge
pygments                  2.15.1             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pygmt                     0.9.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyjwt                     2.7.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyopenssl                 23.1.1             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyparsing                 3.0.9              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyproj                    3.6.0           py310ha254fea\PYGZus{}0    conda\PYGZhy{}forge
pyrsistent                0.19.3          py310h1fa729e\PYGZus{}0    conda\PYGZhy{}forge
pyshp                     2.3.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyshtools                 4.10.3          py310h3e61171\PYGZus{}0    conda\PYGZhy{}forge
pysocks                   1.7.1              pyha2e5f31\PYGZus{}6    conda\PYGZhy{}forge
pytables                  3.8.0           py310hde6a235\PYGZus{}1    conda\PYGZhy{}forge
python                    3.10.11         he550d4f\PYGZus{}0\PYGZus{}cpython    conda\PYGZhy{}forge
python\PYGZhy{}dateutil           2.8.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
python\PYGZhy{}fastjsonschema     2.16.3             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
python\PYGZhy{}json\PYGZhy{}logger        2.0.7              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
python\PYGZhy{}kaleido            0.2.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
python\PYGZhy{}tzdata             2023.3             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
python\PYGZus{}abi                3.10                    3\PYGZus{}cp310    conda\PYGZhy{}forge
pytz                      2023.3             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pyviz\PYGZus{}comms               2.3.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
pywavelets                1.4.1           py310h0a54255\PYGZus{}0    conda\PYGZhy{}forge
pyyaml                    6.0             py310h5764c6d\PYGZus{}5    conda\PYGZhy{}forge
pyzmq                     25.0.2          py310h059b190\PYGZus{}0    conda\PYGZhy{}forge
quaternion                2022.4.3        py310h0a54255\PYGZus{}0    conda\PYGZhy{}forge
qutip                     4.7.2           py310hfb6f7a9\PYGZus{}1    conda\PYGZhy{}forge
re2                       2023.02.02           hcb278e6\PYGZus{}0    conda\PYGZhy{}forge
readline                  8.2                  h8228510\PYGZus{}1    conda\PYGZhy{}forge
reproc                    14.2.4               h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
reproc\PYGZhy{}cpp                14.2.4               hcb278e6\PYGZus{}0    conda\PYGZhy{}forge
requests                  2.29.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
retrying                  1.3.3                      py\PYGZus{}2    conda\PYGZhy{}forge
rfc3339\PYGZhy{}validator         0.1.4              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
rfc3986\PYGZhy{}validator         0.1.1              pyh9f0ad1d\PYGZus{}0    conda\PYGZhy{}forge
ruamel.yaml               0.17.26         py310h2372a71\PYGZus{}0    conda\PYGZhy{}forge
ruamel.yaml.clib          0.2.7           py310h1fa729e\PYGZus{}1    conda\PYGZhy{}forge
s2n                       1.3.44               h06160fa\PYGZus{}0    conda\PYGZhy{}forge
scikit\PYGZhy{}image              0.20.0          py310h9b08913\PYGZus{}1    conda\PYGZhy{}forge
scikit\PYGZhy{}learn              1.2.2           py310h41b6a48\PYGZus{}1    conda\PYGZhy{}forge
scipy                     1.10.1          py310ha4c1d20\PYGZus{}3    conda\PYGZhy{}forge
scooby                    0.7.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
seaborn                   0.9.0                      py\PYGZus{}2    conda\PYGZhy{}forge
seaborn\PYGZhy{}base              0.12.2             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
selenium                  4.10.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
send2trash                1.8.2              pyh41d4057\PYGZus{}0    conda\PYGZhy{}forge
setuptools                67.7.2             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
setuptools\PYGZhy{}scm            7.1.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
shapely                   2.0.1           py310h056c13c\PYGZus{}1    conda\PYGZhy{}forge
six                       1.16.0             pyh6c4a22f\PYGZus{}0    conda\PYGZhy{}forge
smmap                     3.0.5              pyh44b312d\PYGZus{}0    conda\PYGZhy{}forge
snappy                    1.1.10               h9fff704\PYGZus{}0    conda\PYGZhy{}forge
sniffio                   1.3.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
snowballstemmer           2.2.0                    pypi\PYGZus{}0    pypi
sortedcontainers          2.4.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
soupsieve                 2.3.2.post1        pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
spherical\PYGZus{}functions       2022.4.2           pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
sphinx                    5.0.2                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}book\PYGZhy{}theme         1.0.1                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}comments           0.0.3                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}copybutton         0.5.2                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}design             0.3.0                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}external\PYGZhy{}toc       0.3.1                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}jupyterbook\PYGZhy{}latex  0.5.2                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}multitoc\PYGZhy{}numbering 0.1.3                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}thebe              0.2.1                    pypi\PYGZus{}0    pypi
sphinx\PYGZhy{}togglebutton       0.3.2                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}applehelp   1.0.4                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}bibtex      2.5.0                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}devhelp     1.0.2                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}htmlhelp    2.0.1                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}jsmath      1.0.1                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}qthelp      1.0.3                    pypi\PYGZus{}0    pypi
sphinxcontrib\PYGZhy{}serializinghtml 1.1.5                    pypi\PYGZus{}0    pypi
spinsfast                 2022.4.2        py310hc9031d1\PYGZus{}0    conda\PYGZhy{}forge
sqlalchemy                2.0.13          py310h2372a71\PYGZus{}0    conda\PYGZhy{}forge
sqlite                    3.41.2               h2c6b66d\PYGZus{}1    conda\PYGZhy{}forge
stack\PYGZus{}data                0.6.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
statsmodels               0.14.0          py310h278f3c1\PYGZus{}1    conda\PYGZhy{}forge
sympy                     1.11.1          pypyh9d50eac\PYGZus{}103    conda\PYGZhy{}forge
tabulate                  0.9.0                    pypi\PYGZus{}0    pypi
tblib                     1.7.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
tenacity                  8.2.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
terminado                 0.17.1             pyh41d4057\PYGZus{}0    conda\PYGZhy{}forge
threadpoolctl             3.1.0              pyh8a188c0\PYGZus{}0    conda\PYGZhy{}forge
tifffile                  2023.4.12          pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
tiledb                    2.13.2               hd532e3d\PYGZus{}0    conda\PYGZhy{}forge
tinycss2                  1.2.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
tk                        8.6.12               h27826a3\PYGZus{}0    conda\PYGZhy{}forge
toml                      0.10.2             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
tomli                     2.0.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
toolz                     0.12.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
tornado                   6.3             py310h1fa729e\PYGZus{}0    conda\PYGZhy{}forge
tqdm                      4.65.0             pyhd8ed1ab\PYGZus{}1    conda\PYGZhy{}forge
traitlets                 5.9.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
trio                      0.21.0          py310hff52083\PYGZus{}0    conda\PYGZhy{}forge
trio\PYGZhy{}websocket            0.10.3             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
typing\PYGZhy{}extensions         4.5.0                hd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
typing\PYGZus{}extensions         4.5.0              pyha770c72\PYGZus{}0    conda\PYGZhy{}forge
tzcode                    2023c                h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
tzdata                    2023c                h71feb2d\PYGZus{}0    conda\PYGZhy{}forge
uc\PYGZhy{}micro\PYGZhy{}py               1.0.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
ucx                       1.14.0               h3484d09\PYGZus{}2    conda\PYGZhy{}forge
uncertainties             3.1.7              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
unicodedata2              15.0.0          py310h5764c6d\PYGZus{}0    conda\PYGZhy{}forge
uri\PYGZhy{}template              1.3.0                    pypi\PYGZus{}0    pypi
urllib3                   1.26.15            pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
wcwidth                   0.2.6              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
webcolors                 1.13                     pypi\PYGZus{}0    pypi
webencodings              0.5.1                      py\PYGZus{}1    conda\PYGZhy{}forge
websocket\PYGZhy{}client          1.5.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
werkzeug                  2.3.6              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
wget                      3.2                      pypi\PYGZus{}0    pypi
wheel                     0.40.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
widgetsnbextension        4.0.7              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
wsproto                   1.2.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
xarray                    2022.3.0           pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
xerces\PYGZhy{}c                  3.2.4                h8d71039\PYGZus{}2    conda\PYGZhy{}forge
xlrd                      2.0.1              pyhd8ed1ab\PYGZus{}3    conda\PYGZhy{}forge
xorg\PYGZhy{}kbproto              1.0.7             h7f98852\PYGZus{}1002    conda\PYGZhy{}forge
xorg\PYGZhy{}libice               1.1.1                hd590300\PYGZus{}0    conda\PYGZhy{}forge
xorg\PYGZhy{}libsm                1.2.4                h7391055\PYGZus{}0    conda\PYGZhy{}forge
xorg\PYGZhy{}libx11               1.8.4                h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
xorg\PYGZhy{}libxau               1.0.9                h7f98852\PYGZus{}0    conda\PYGZhy{}forge
xorg\PYGZhy{}libxdmcp             1.1.3                h7f98852\PYGZus{}0    conda\PYGZhy{}forge
xorg\PYGZhy{}libxext              1.3.4                h0b41bf4\PYGZus{}2    conda\PYGZhy{}forge
xorg\PYGZhy{}libxrender           0.9.10            h7f98852\PYGZus{}1003    conda\PYGZhy{}forge
xorg\PYGZhy{}renderproto          0.11.1            h7f98852\PYGZus{}1002    conda\PYGZhy{}forge
xorg\PYGZhy{}xextproto            7.3.0             h0b41bf4\PYGZus{}1003    conda\PYGZhy{}forge
xorg\PYGZhy{}xproto               7.0.31            h7f98852\PYGZus{}1007    conda\PYGZhy{}forge
xyzpy                     1.2.1              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
xyzservices               2023.2.0           pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
xz                        5.2.6                h166bdaf\PYGZus{}0    conda\PYGZhy{}forge
y\PYGZhy{}py                      0.5.9           py310h4426083\PYGZus{}0    conda\PYGZhy{}forge
yaml                      0.2.5                h7f98852\PYGZus{}2    conda\PYGZhy{}forge
yaml\PYGZhy{}cpp                  0.7.0                h27087fc\PYGZus{}2    conda\PYGZhy{}forge
ypy\PYGZhy{}websocket             0.8.2              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
zeromq                    4.3.4                h9c3ff4c\PYGZus{}1    conda\PYGZhy{}forge
zfp                       1.0.0                h27087fc\PYGZus{}3    conda\PYGZhy{}forge
zict                      3.0.0              pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
zipp                      3.15.0             pyhd8ed1ab\PYGZus{}0    conda\PYGZhy{}forge
zlib                      1.2.13               h166bdaf\PYGZus{}4    conda\PYGZhy{}forge
zlib\PYGZhy{}ng                   2.0.7                h0b41bf4\PYGZus{}0    conda\PYGZhy{}forge
zstandard                 0.19.0          py310hdeb6495\PYGZus{}1    conda\PYGZhy{}forge
zstd                      1.5.2                h3eb15da\PYGZus{}6    conda\PYGZhy{}forge
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxthebibliography}{100}
\bibitem[1]{backmatter/bibliography:id776}
\sphinxAtStartPar
Claude Marceau, Varun Makhija, Dominique Platzer, A. \textbackslash{}relax Yu. Naumov, P. B. Corkum, Albert Stolow, D. M. Villeneuve, and Paul Hockett. Molecular Frame Reconstruction Using Time\sphinxhyphen{}Domain Photoionization Interferometry. \sphinxstyleemphasis{Physical Review Letters}, 119(8):083401, August 2017. URL: \sphinxurl{https://link.aps.org/doi/10.1103/PhysRevLett.119.083401}, \sphinxhref{https://doi.org/10.1103/PhysRevLett.119.083401}{doi:10.1103/PhysRevLett.119.083401}.
\bibitem[2]{backmatter/bibliography:id685}
\sphinxAtStartPar
Paul Hockett and Varun Makhija. Topical Review: Extracting Molecular Frame Photoionization Dynamics from Experimental Data (Preprint). September 2022. URL: \sphinxurl{https://www.authorea.com/users/71114/articles/447808-extracting-molecular-frame-photoionization-dynamics-from-experimental-data} (visited on 2022\sphinxhyphen{}09\sphinxhyphen{}15), \sphinxhref{https://arxiv.org/abs/2209.04301}{arXiv:2209.04301}, \sphinxhref{https://doi.org/10.48550/arXiv.2209.04301}{doi:10.48550/arXiv.2209.04301}.
\bibitem[3]{backmatter/bibliography:id686}
\sphinxAtStartPar
Paul Hockett and Varun Makhija. Topical Review: Extracting molecular frame photoionization dynamics from experimental data. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 56(11):112001, May 2023. URL: \sphinxurl{https://dx.doi.org/10.1088/1361-6455/acd03e} (visited on 2023\sphinxhyphen{}05\sphinxhyphen{}12), \sphinxhref{https://arxiv.org/abs/2209.04301}{arXiv:2209.04301}, \sphinxhref{https://doi.org/10.1088/1361-6455/acd03e}{doi:10.1088/1361\sphinxhyphen{}6455/acd03e}.
\bibitem[4]{backmatter/bibliography:id677}
\sphinxAtStartPar
Paul Hockett. \sphinxstyleemphasis{Quantum Metrology with Photoelectrons, Volume 1: Foundations}. IOP Publishing, 2018. ISBN 978\sphinxhyphen{}1\sphinxhyphen{}68174\sphinxhyphen{}684\sphinxhyphen{}5. URL: \sphinxurl{http://iopscience.iop.org/book/978-1-6817-4684-5}, \sphinxhref{https://doi.org/10.1088/978-1-6817-4684-5}{doi:10.1088/978\sphinxhyphen{}1\sphinxhyphen{}6817\sphinxhyphen{}4684\sphinxhyphen{}5}.
\bibitem[5]{backmatter/bibliography:id682}
\sphinxAtStartPar
Paul Hockett. Photoelectron Metrology Toolkit (PEMtk) Github repository. 2021. URL: \sphinxurl{https://github.com/phockett/PEMtk} (visited on 2022\sphinxhyphen{}02\sphinxhyphen{}18).
\bibitem[6]{backmatter/bibliography:id674}
\sphinxAtStartPar
Paul Hockett. Phase\sphinxhyphen{}sensitive Photoelectron Metrology (DAMOP 2017). June 2017. URL: \sphinxurl{https://vimeo.com/223603377} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}06), \sphinxhref{https://doi.org/10.6084/m9.figshare.5049142.v1}{doi:10.6084/m9.figshare.5049142.v1}.
\bibitem[7]{backmatter/bibliography:id676}
\sphinxAtStartPar
Paul Hockett. Bootstrapping (Ultrafast) Photoionization Dynamics. January 2018. URL: \sphinxurl{https://vimeo.com/252040672} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}06), \sphinxhref{https://doi.org/10.6084/m9.figshare.5645509.v3}{doi:10.6084/m9.figshare.5645509.v3}.
\bibitem[8]{backmatter/bibliography:id670}
\sphinxAtStartPar
Paul Hockett. Presentations archive: ultrafast light\sphinxhyphen{}matter interactions. \sphinxstyleemphasis{Figshare}, 2016. URL: \sphinxurl{https://figshare.com/collections/Presentations/3312291} (visited on 2022\sphinxhyphen{}02\sphinxhyphen{}16), \sphinxhref{https://doi.org/10.6084/m9.figshare.c.3312291}{doi:10.6084/m9.figshare.c.3312291}.
\bibitem[9]{backmatter/bibliography:id678}
\sphinxAtStartPar
Paul Hockett. \sphinxstyleemphasis{Quantum Metrology with Photoelectrons, Volume 2: Applications and Advances}. IOP Publishing, 2018. ISBN 978\sphinxhyphen{}1\sphinxhyphen{}68174\sphinxhyphen{}688\sphinxhyphen{}3. URL: \sphinxurl{http://iopscience.iop.org/book/978-1-6817-4688-3}, \sphinxhref{https://doi.org/10.1088/978-1-6817-4688-3}{doi:10.1088/978\sphinxhyphen{}1\sphinxhyphen{}6817\sphinxhyphen{}4688\sphinxhyphen{}3}.
\bibitem[10]{backmatter/bibliography:id773}
\sphinxAtStartPar
Varun Makhija, Xiaoming Ren, Drue Gockel, Ahn\sphinxhyphen{}Thu Le, and Vinod Kumarappan. Orientation Resolution through Rotational Coherence Spectroscopy. \sphinxstyleemphasis{arXiv}, pages 1–6, 2016. URL: \sphinxurl{http://arxiv.org/abs/1611.06476}, \sphinxhref{https://arxiv.org/abs/1611.06476}{arXiv:1611.06476}, \sphinxhref{https://doi.org/10.48550/arXiv.1611.06476}{doi:10.48550/arXiv.1611.06476}.
\bibitem[11]{backmatter/bibliography:id774}
\sphinxAtStartPar
Varun Makhija, Kevin Veyrinas, Andrey E. Boguslavskiy, Ruaridh Forbes, Iain Wilkinson, Rune Lausten, Simon P. Neville, Stephen T. Pratt, Michael S. Schuurman, and Albert Stolow. Ultrafast molecular frame electronic coherences from lab frame scattering anisotropies. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 53(11):114001, May 2020. URL: \sphinxurl{https://dx.doi.org/10.1088/1361-6455/ab7a84} (visited on 2023\sphinxhyphen{}06\sphinxhyphen{}14), \sphinxhref{https://doi.org/10.1088/1361-6455/ab7a84}{doi:10.1088/1361\sphinxhyphen{}6455/ab7a84}.
\bibitem[12]{backmatter/bibliography:id797}
\sphinxAtStartPar
Luna Morrigan, Simon P. Neville, Margaret Gregory, Andrey E. Boguslavskiy, Ruaridh Forbes, Iain Wilkinson, Rune Lausten, Albert Stolow, Michael S. Schuurman, Paul Hockett, and Varun Makhija. Ultrafast Molecular Frame Quantum Tomography. March 2023. URL: \sphinxurl{http://arxiv.org/abs/2303.03558} (visited on 2023\sphinxhyphen{}03\sphinxhyphen{}08), \sphinxhref{https://arxiv.org/abs/2303.03558}{arXiv:2303.03558}, \sphinxhref{https://doi.org/10.48550/arXiv.2303.03558}{doi:10.48550/arXiv.2303.03558}.
\bibitem[13]{backmatter/bibliography:id829}
\sphinxAtStartPar
Project Jupyter. URL: \sphinxurl{https://jupyter.org} (visited on 2023\sphinxhyphen{}01\sphinxhyphen{}16).
\bibitem[14]{backmatter/bibliography:id831}
\sphinxAtStartPar
Python.org. July 2023. URL: \sphinxurl{https://www.python.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}07).
\bibitem[15]{backmatter/bibliography:id712}
\sphinxAtStartPar
Jupyter Book Project. URL: \sphinxurl{https://jupyterbook.org}.
\bibitem[16]{backmatter/bibliography:id566}
\sphinxAtStartPar
Executable Books Community. Jupyter Book. Zenodo, February 2020. URL: \sphinxurl{https://zenodo.org/record/4539666} (visited on 2023\sphinxhyphen{}01\sphinxhyphen{}16), \sphinxhref{https://doi.org/10.5281/zenodo.4539666}{doi:10.5281/zenodo.4539666}.
\bibitem[17]{backmatter/bibliography:id803}
\sphinxAtStartPar
MyST Markdown \sphinxhyphen{} Tools for the future of technical communication. URL: \sphinxurl{https://mystmd.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}07).
\bibitem[18]{backmatter/bibliography:id901}
\sphinxAtStartPar
Sphinx documentation. URL: \sphinxurl{https://www.sphinx-doc.org} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}07).
\bibitem[19]{backmatter/bibliography:id687}
\sphinxAtStartPar
Paul Hockett. Open Photoionization Docker Stacks. URL: \sphinxurl{https://github.com/phockett/open-photoionization-docker-stacks} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}04).
\bibitem[20]{backmatter/bibliography:id681}
\sphinxAtStartPar
Paul Hockett. PEMtk \sphinxhyphen{} the Photoelectron Metrology Toolkit \sphinxhyphen{} documentation. 2021. URL: \sphinxurl{https://pemtk.readthedocs.io} (visited on 2022\sphinxhyphen{}02\sphinxhyphen{}18).
\bibitem[21]{backmatter/bibliography:id942}
\sphinxAtStartPar
Jake VanderPlas. \sphinxstyleemphasis{Python Data Science Handbook}. O'Reilly Media, Inc., 2016. ISBN 978\sphinxhyphen{}1\sphinxhyphen{}4919\sphinxhyphen{}1205\sphinxhyphen{}8. URL: \sphinxurl{https://www.oreilly.com/library/view/python-data-science/9781491912126/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}07).
\bibitem[22]{backmatter/bibliography:id943}
\sphinxAtStartPar
Jake VanderPlas. Python Data Science Handbook. July 2023. URL: \sphinxurl{https://github.com/jakevdp/PythonDataScienceHandbook} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}07).
\bibitem[23]{backmatter/bibliography:id519}
\sphinxAtStartPar
Nick Barnes. Publish your computer code: it is good enough. \sphinxstyleemphasis{Nature}, 467(7317):753, October 2010. URL: \sphinxurl{http://www.nature.com/news/2010/101013/full/467753a.html} (visited on 2016\sphinxhyphen{}04\sphinxhyphen{}18), \sphinxhref{https://doi.org/10.1038/467753a}{doi:10.1038/467753a}.
\bibitem[24]{backmatter/bibliography:id786}
\sphinxAtStartPar
Marcia McNutt. Taking up TOP. \sphinxstyleemphasis{Science}, 2016. URL: \sphinxurl{http://science.sciencemag.org/content/352/6290/1147.full} (visited on 2017\sphinxhyphen{}04\sphinxhyphen{}04).
\bibitem[25]{backmatter/bibliography:id809}
\sphinxAtStartPar
B. A. Nosek, G. Alter, G. C. Banks, D. Borsboom, S. D. Bowman, S. J. Breckler, S. Buck, C. D. Chambers, G. Chin, G. Christensen, M. Contestabile, A. Dafoe, E. Eich, J. Freese, R. Glennerster, D. Goroff, D. P. Green, B. Hesse, M. Humphreys, J. Ishiyama, D. Karlan, A. Kraut, A. Lupia, P. Mabry, T. Madon, N. Malhotra, E. Mayo\sphinxhyphen{}Wilson, M. McNutt, E. Miguel, E. Levy Paluck, U. Simonsohn, C. Soderberg, B. A. Spellman, J. Turitto, G. VandenBos, S. Vazire, E. J. Wagenmakers, R. Wilson, and T. Yarkoni. Promoting an open research culture. \sphinxstyleemphasis{Science}, 348(6242):1422–1425, June 2015. URL: \sphinxurl{http://science.sciencemag.org.proxy.bib.uottawa.ca/content/348/6242/1422.full} (visited on 2017\sphinxhyphen{}04\sphinxhyphen{}04), \sphinxhref{https://doi.org/10.1126/science.aab2374}{doi:10.1126/science.aab2374}.
\bibitem[26]{backmatter/bibliography:id904}
\sphinxAtStartPar
Jon Treadway, Mark Hahnel, Sabina Leonelli, Dan Penny, David Groenewegen, Nobuko Miyairi, Kazuhiro Hayashi, Daniel O'Donnell, Digital Science, and Daniel Hook. The State of Open Data Report. Report, Digital Science, October 2016. URL: \sphinxurl{https://figshare.com/articles/report/The\_State\_of\_Open\_Data\_Report/4036398/1} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}31), \sphinxhref{https://doi.org/10.6084/m9.figshare.4036398.v1}{doi:10.6084/m9.figshare.4036398.v1}.
\bibitem[27]{backmatter/bibliography:id906}
\sphinxAtStartPar
Victoria Stodden and Sheila Miguez. Best Practices for Computational Science: Software Infrastructure and Environments for Reproducible and Extensible Research. \sphinxstyleemphasis{Journal of Open Research Software}, 2(1):e21, July 2014. URL: \sphinxurl{http://openresearchsoftware.metajnl.com/articles/10.5334/jors.ay/} (visited on 2016\sphinxhyphen{}03\sphinxhyphen{}17), \sphinxhref{https://doi.org/10.5334/jors.ay}{doi:10.5334/jors.ay}.
\bibitem[28]{backmatter/bibliography:id595}
\sphinxAtStartPar
Robert R. Downs, W. Christopher Lenhardt, Erin Robinson, Ethan Davis, and Nicholas Weber. Community Recommendations for Sustainable Scientific Software. \sphinxstyleemphasis{Journal of Open Research Software}, November 2015. URL: \sphinxurl{http://openresearchsoftware.metajnl.com/articles/10.5334/jors.bt/} (visited on 2016\sphinxhyphen{}06\sphinxhyphen{}01), \sphinxhref{https://doi.org/10.5334/jors.bt}{doi:10.5334/jors.bt}.
\bibitem[29]{backmatter/bibliography:id697}
\sphinxAtStartPar
James Howison, Ewa Deelman, Michael J. McLennan, Rafael Ferreira da Silva, and James D. Herbsleb. Understanding the scientific software ecosystem and its impact: Current and future measures. \sphinxstyleemphasis{Research Evaluation}, 24(4):454–470, October 2015. URL: \sphinxurl{https://doi.org/10.1093/reseval/rvv014} (visited on 2022\sphinxhyphen{}03\sphinxhyphen{}12), \sphinxhref{https://doi.org/10.1093/reseval/rvv014}{doi:10.1093/reseval/rvv014}.
\bibitem[30]{backmatter/bibliography:id961}
\sphinxAtStartPar
\textbackslash{}\textbackslash{}Open science\textbackslash{}\textbackslash{}. Open science. \sphinxstyleemphasis{Wikipedia}, May 2023. URL: \sphinxurl{https://en.wikipedia.org/w/index.php?title=Open\_science\&oldid=1155039330} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}07).
\bibitem[31]{backmatter/bibliography:id726}
\sphinxAtStartPar
Thomas Kluyver, Benjamin Ragan\sphinxhyphen{}Kelley, P\&\#233, Fernando Rez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Dami\&\#225 Avila, n, Safia Abdalla, Carol Willing, and Jupyter Development Team. Jupyter Notebooks – a publishing format for reproducible computational workflows. \sphinxstyleemphasis{Positioning and Power in Academic Publishing: Players, Agents and Agendas}, pages 87–90, 2016. URL: \sphinxurl{https://ebooks.iospress.nl/doi/10.3233/978-1-61499-649-1-87} (visited on 2023\sphinxhyphen{}01\sphinxhyphen{}16), \sphinxhref{https://doi.org/10.3233/978-1-61499-649-1-87}{doi:10.3233/978\sphinxhyphen{}1\sphinxhyphen{}61499\sphinxhyphen{}649\sphinxhyphen{}1\sphinxhyphen{}87}.
\bibitem[32]{backmatter/bibliography:id634}
\sphinxAtStartPar
Brian E. Granger and Fernando Pérez. Jupyter: Thinking and Storytelling With Code and Data. \sphinxstyleemphasis{Computing in Science \& Engineering}, 23(2):7–14, March 2021. \sphinxhref{https://doi.org/10.1109/MCSE.2021.3059263}{doi:10.1109/MCSE.2021.3059263}.
\bibitem[33]{backmatter/bibliography:id666}
\sphinxAtStartPar
Paul Hockett. ePSproc: Post\sphinxhyphen{}processing suite for ePolyScat electron\sphinxhyphen{}molecule scattering calculations. \sphinxstyleemphasis{Authorea}, 2016. URL: \sphinxurl{https://www.authorea.com/users/71114/articles/122402/\_show\_article}, \sphinxhref{https://doi.org/10.6084/m9.figshare.3545639}{doi:10.6084/m9.figshare.3545639}.
\bibitem[34]{backmatter/bibliography:id608}
\sphinxAtStartPar
Paul Hockett. ePSproc: Post\sphinxhyphen{}processing for ePolyScat (Github repository). Github, 2016. URL: \sphinxurl{https://github.com/phockett/ePSproc}, \sphinxhref{https://doi.org/10.6084/m9.figshare.3545639}{doi:10.6084/m9.figshare.3545639}.
\bibitem[35]{backmatter/bibliography:id606}
\sphinxAtStartPar
Paul Hockett. ePSproc: Post\sphinxhyphen{}processing for ePolyScat documentation. 2020. URL: \sphinxurl{https://epsproc.readthedocs.io} (visited on 2022\sphinxhyphen{}02\sphinxhyphen{}18).
\bibitem[36]{backmatter/bibliography:id764}
\sphinxAtStartPar
Robert R. Lucchese, Kazuo Takatsuka, and Vincent McKoy. Applications of the Schwinger variational principle to electron\sphinxhyphen{}molecule collisions and molecular photoionization. \sphinxstyleemphasis{Physics Reports}, 131(3):147–221, January 1986. URL: \sphinxurl{http://www.sciencedirect.com/science/article/pii/037015738690147X} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}18), \sphinxhref{https://doi.org/10.1016/0370-1573(86)90147-X}{doi:10.1016/0370\sphinxhyphen{}1573(86)90147\sphinxhyphen{}X}.
\bibitem[37]{backmatter/bibliography:id628}
\sphinxAtStartPar
F. A. Gianturco, R. R. Lucchese, and N. Sanna. Calculation of low\sphinxhyphen{}energy elastic cross sections for electron\sphinxhyphen{}CF4 scattering. \sphinxstyleemphasis{The Journal of Chemical Physics}, 100(9):6464, May 1994. URL: \sphinxurl{http://scitation.aip.org/content/aip/journal/jcp/100/9/10.1063/1.467237} (visited on 2015\sphinxhyphen{}08\sphinxhyphen{}13), \sphinxhref{https://doi.org/10.1063/1.467237}{doi:10.1063/1.467237}.
\bibitem[38]{backmatter/bibliography:id805}
\sphinxAtStartPar
Alexandra P P Natalense and Robert R Lucchese. Cross section and asymmetry parameter calculation for sulfur 1s photoionization of SF{[}sub 6{]}. \sphinxstyleemphasis{The Journal of Chemical Physics}, 111(12):5344, 1999. URL: \sphinxurl{http://link.aip.org/link/JCPSA6/v111/i12/p5344/s1\&Agg=doi} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}18), \sphinxhref{https://doi.org/10.1063/1.479794}{doi:10.1063/1.479794}.
\bibitem[39]{backmatter/bibliography:id767}
\sphinxAtStartPar
R R Lucchese. ePolyScat User's Manual. URL: \sphinxurl{https://epolyscat.droppages.com/} (visited on 2022\sphinxhyphen{}04\sphinxhyphen{}26).
\bibitem[40]{backmatter/bibliography:id545}
\sphinxAtStartPar
Andrew C. Brown, Gregory S. J. Armstrong, Jakub Benda, Daniel D. A. Clarke, Jack Wragg, Kathryn R. Hamilton, Zdeněk Mašín, Jimena D. Gorfinkiel, and Hugo W. van der Hart. RMT: R\sphinxhyphen{}matrix with time\sphinxhyphen{}dependence. Solving the semi\sphinxhyphen{}relativistic, time\sphinxhyphen{}dependent Schrödinger equation for general, multielectron atoms and molecules in intense, ultrashort, arbitrarily polarized laser pulses. \sphinxstyleemphasis{Computer Physics Communications}, 250:107062, May 2020. URL: \sphinxurl{https://www.sciencedirect.com/science/article/pii/S0010465519303856} (visited on 2022\sphinxhyphen{}11\sphinxhyphen{}09), \sphinxhref{https://arxiv.org/abs/1905.06156}{arXiv:1905.06156}, \sphinxhref{https://doi.org/10.1016/j.cpc.2019.107062}{doi:10.1016/j.cpc.2019.107062}.
\bibitem[41]{backmatter/bibliography:id858}
\sphinxAtStartPar
Andrew C. Brown, Gregory S. J. Armstrong, Jakub Benda, Daniel D. A. Clarke, Jack Wragg, Kathryn R. Hamilton, Zdeněk Mašín, Jimena D. Gorfinkiel, and Hugo W. van der Hart. RMT: R\sphinxhyphen{}matrix with time\sphinxhyphen{}dependence (repository). May 2020. URL: \sphinxurl{https://gitlab.com/Uk-amor/RMT/rmt} (visited on 2022\sphinxhyphen{}11\sphinxhyphen{}09), \sphinxhref{https://arxiv.org/abs/1905.06156}{arXiv:1905.06156}.
\bibitem[42]{backmatter/bibliography:id594}
\sphinxAtStartPar
Danielle Dowek and Piero Decleva. Trends in angle\sphinxhyphen{}resolved molecular photoelectron spectroscopy. \sphinxstyleemphasis{Physical Chemistry Chemical Physics}, 24(40):24614–24654, October 2022. URL: \sphinxurl{https://pubs.rsc.org/en/content/articlelanding/2022/cp/d2cp02725a} (visited on 2023\sphinxhyphen{}10\sphinxhyphen{}25), \sphinxhref{https://doi.org/10.1039/D2CP02725A}{doi:10.1039/D2CP02725A}.
\bibitem[43]{backmatter/bibliography:id622}
\sphinxAtStartPar
Michael W Schmidt, Kim K Baldridge, Jerry A Boatz, Steven T Elbert, Mark S Gordon, Jan H Jensen, Shiro Koseki, Nikita Matsunaga, Kiet A Nguyen, Shujun Su, Theresa L Windus, Michel Dupuis, and John A Montgomery. General atomic and molecular electronic structure system. \sphinxstyleemphasis{Journal of Computational Chemistry}, 14(11):1347–1363, 1993. URL: \sphinxurl{http://dx.doi.org/10.1002/jcc.540141112}, \sphinxhref{https://doi.org/10.1002/jcc.540141112}{doi:10.1002/jcc.540141112}.
\bibitem[44]{backmatter/bibliography:id633}
\sphinxAtStartPar
Mark S. Gordon. Gamess website. URL: \sphinxurl{http://www.msg.ameslab.gov/gamess/}.
\bibitem[45]{backmatter/bibliography:id510}
\sphinxAtStartPar
AMOSGateway. URL: \sphinxurl{https://amosgateway.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[46]{backmatter/bibliography:id872}
\sphinxAtStartPar
Barry I. Schneider, Klaus Bartschat, Oleg Zatsarinny, Kathryn R. Hamilton, Igor Bray, Armin Scrinzi, Fernando Martin, Jesus Gonzalez Vasquez, Jonathan Tennyson, Jimena D. Gorfinkiel, Robert Lucchesse, and Sudhakar Pamidighantam. Atomic and Molecular Scattering Applications in an Apache Airavata Science Gateway. In \sphinxstyleemphasis{Practice and Experience in Advanced Research Computing}, PEARC '20, 270–277. New York, NY, USA, July 2020. Association for Computing Machinery. URL: \sphinxurl{https://dl.acm.org/doi/10.1145/3311790.3397342} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10), \sphinxhref{https://doi.org/10.1145/3311790.3397342}{doi:10.1145/3311790.3397342}.
\bibitem[47]{backmatter/bibliography:id873}
\sphinxAtStartPar
Barry I. Schneider, Klaus\textasciitilde{}Bartschat, Oleg Zatsarinny, Igor Bray, Armin Scrinzi, Fernando Martin, Markus Klinker, Jonathan Tennyson, Jimena D. Gorfinkiel, and Sudhakar Pamidighantam. A Science Gateway for Atomic and Molecular Physics. January 2020. URL: \sphinxurl{http://arxiv.org/abs/2001.02286} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10), \sphinxhref{https://arxiv.org/abs/2001.02286}{arXiv:2001.02286}, \sphinxhref{https://doi.org/10.48550/arXiv.2001.02286}{doi:10.48550/arXiv.2001.02286}.
\bibitem[48]{backmatter/bibliography:id679}
\sphinxAtStartPar
Paul Hockett. ePS data: Photoionization calculations archive. 2019. URL: \sphinxurl{https://phockett.github.io/ePSdata/} (visited on 2022\sphinxhyphen{}02\sphinxhyphen{}16).
\bibitem[49]{backmatter/bibliography:id680}
\sphinxAtStartPar
Paul Hockett. ePSdata repositories on Zenodo. 2019. URL: \sphinxurl{https://zenodo.org/search?page=1\&size=20\&q=hockett\&keywords=Data}.
\bibitem[50]{backmatter/bibliography:id811}
\sphinxAtStartPar
NumPy. URL: \sphinxurl{https://numpy.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[51]{backmatter/bibliography:id819}
\sphinxAtStartPar
Pandas \sphinxhyphen{} Python Data Analysis Library. URL: \sphinxurl{https://pandas.pydata.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[52]{backmatter/bibliography:id876}
\sphinxAtStartPar
SciPy. URL: \sphinxurl{https://scipy.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[53]{backmatter/bibliography:id698}
\sphinxAtStartPar
Stephan Hoyer and Joe Hamman. Xarray: N\sphinxhyphen{}D labeled Arrays and Datasets in Python. \sphinxstyleemphasis{Journal of Open Research Software}, 5(1):10, April 2017. URL: \sphinxurl{http://openresearchsoftware.metajnl.com/article/10.5334/jors.148/} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03), \sphinxhref{https://doi.org/10.5334/jors.148}{doi:10.5334/jors.148}.
\bibitem[54]{backmatter/bibliography:id975}
\sphinxAtStartPar
Xarray documentation. URL: \sphinxurl{https://docs.xarray.dev/en/latest/index.html} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[55]{backmatter/bibliography:id540}
\sphinxAtStartPar
Mike Boyle. Spherical Functions Github. April 2022. URL: \sphinxurl{https://github.com/moble/spherical\_functions} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[56]{backmatter/bibliography:id542}
\sphinxAtStartPar
Mike Boyle and Leo C. Stein. Moble/spherical\_functions: Release v2022.4.2. Zenodo, May 2023. URL: \sphinxurl{https://zenodo.org/record/7960723} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10), \sphinxhref{https://doi.org/10.5281/zenodo.7960723}{doi:10.5281/zenodo.7960723}.
\bibitem[57]{backmatter/bibliography:id541}
\sphinxAtStartPar
Mike Boyle, Blair Bonnett, Jon Long, Martin Ling, stiiin, Leo C. Stein, Eric Wieser, Dante A. B. Iozzo, Hunter Haglid, John Belmonte, John Long, Mark Wiebe, Yin Li, Zé Vinícius, James Macfarlane, and odidev. Moble/quaternion: Release v2022.4.3. Zenodo, February 2023. URL: \sphinxurl{https://zenodo.org/record/7636919} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10), \sphinxhref{https://doi.org/10.5281/zenodo.7636919}{doi:10.5281/zenodo.7636919}.
\bibitem[58]{backmatter/bibliography:id796}
\sphinxAtStartPar
Moble/quaternion Github. URL: \sphinxurl{https://github.com/moble/quaternion} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[59]{backmatter/bibliography:id877}
\sphinxAtStartPar
SciPy documentation. URL: \sphinxurl{https://docs.scipy.org/doc/scipy/index.html} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[60]{backmatter/bibliography:id888}
\sphinxAtStartPar
Mark A. Wieczorek and Matthias Meschede. SHtools Github. SHTOOLS, August 2022. URL: \sphinxurl{https://github.com/SHTOOLS/SHTOOLS} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[61]{backmatter/bibliography:id957}
\sphinxAtStartPar
Mark A. Wieczorek and Matthias Meschede. SHTools: Tools for Working with Spherical Harmonics. \sphinxstyleemphasis{Geochemistry, Geophysics, Geosystems}, 19(8):2574–2592, August 2018. URL: \sphinxurl{http://doi.wiley.com/10.1029/2018GC007529} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03), \sphinxhref{https://doi.org/10.1029/2018GC007529}{doi:10.1029/2018GC007529}.
\bibitem[62]{backmatter/bibliography:id958}
\sphinxAtStartPar
Mark Wieczorek, MMesch, Elliott Sales de Andrade, Ilya Oshchepkov, xoviat, Benda Xu, Katrin Leinweber, and Andrew Walker. SHTOOLS/SHTOOLS: Version 4.5. Zenodo, September 2019. URL: \sphinxurl{https://zenodo.org/record/3457861} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10), \sphinxhref{https://doi.org/10.5281/zenodo.3457861}{doi:10.5281/zenodo.3457861}.
\bibitem[63]{backmatter/bibliography:id959}
\sphinxAtStartPar
Mark A. Wieczorek and Matthias Meschede. SHtools Docs. SHTOOLS, August 2022. URL: \sphinxurl{https://shtools.github.io/SHTOOLS/} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[64]{backmatter/bibliography:id708}
\sphinxAtStartPar
Marcus Johansson and Valera Veryazov. Automatic procedure for generating symmetry adapted wavefunctions. \sphinxstyleemphasis{Journal of Cheminformatics}, 9(1):8, February 2017. URL: \sphinxurl{https://doi.org/10.1186/s13321-017-0193-3} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03), \sphinxhref{https://doi.org/10.1186/s13321-017-0193-3}{doi:10.1186/s13321\sphinxhyphen{}017\sphinxhyphen{}0193\sphinxhyphen{}3}.
\bibitem[65]{backmatter/bibliography:id709}
\sphinxAtStartPar
Marcus Johansson. Libmsym Github. July 2022. URL: \sphinxurl{https://github.com/mcodev31/libmsym} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[66]{backmatter/bibliography:id758}
\sphinxAtStartPar
LMFIT documentation. URL: \sphinxurl{https://lmfit.github.io/lmfit-py/intro.html} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03).
\bibitem[67]{backmatter/bibliography:id806}
\sphinxAtStartPar
Matthew Newville, Till Stensitzki, Daniel B. Allen, and Antonino Ingargiola. LMFIT: Non\sphinxhyphen{}Linear Least\sphinxhyphen{}Square Minimization and Curve\sphinxhyphen{}Fitting for Python. Zenodo, September 2014. URL: \sphinxurl{https://zenodo.org/record/11813} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}03), \sphinxhref{https://doi.org/10.5281/zenodo.11813}{doi:10.5281/zenodo.11813}.
\bibitem[68]{backmatter/bibliography:id976}
\sphinxAtStartPar
Xyzpy documentation. URL: \sphinxurl{https://xyzpy.readthedocs.io} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[69]{backmatter/bibliography:id779}
\sphinxAtStartPar
Matplotlib — Visualization with Python. URL: \sphinxurl{https://matplotlib.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[70]{backmatter/bibliography:id693}
\sphinxAtStartPar
HoloViews documentation. URL: \sphinxurl{https://holoviews.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[71]{backmatter/bibliography:id699}
\sphinxAtStartPar
hvPlot documentation. URL: \sphinxurl{https://hvplot.holoviz.org/index.html} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[72]{backmatter/bibliography:id536}
\sphinxAtStartPar
Bokeh. URL: \sphinxurl{https://bokeh.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[73]{backmatter/bibliography:id827}
\sphinxAtStartPar
Plotly. URL: \sphinxurl{https://plotly.com/python/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[74]{backmatter/bibliography:id878}
\sphinxAtStartPar
Seaborn documentation. URL: \sphinxurl{https://seaborn.pydata.org} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[75]{backmatter/bibliography:id954}
\sphinxAtStartPar
Michael Waskom. Seaborn: statistical data visualization. \sphinxstyleemphasis{Journal of Open Source Software}, 6(60):3021, April 2021. URL: \sphinxurl{https://joss.theoj.org/papers/10.21105/joss.03021} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10), \sphinxhref{https://doi.org/10.21105/joss.03021}{doi:10.21105/joss.03021}.
\bibitem[76]{backmatter/bibliography:id810}
\sphinxAtStartPar
Numba: A High Performance Python Compiler. URL: \sphinxurl{https://numba.pydata.org/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[77]{backmatter/bibliography:id588}
\sphinxAtStartPar
Docker: Accelerated, Containerized Application Development. May 2022. URL: \sphinxurl{https://www.docker.com/} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[78]{backmatter/bibliography:id713}
\sphinxAtStartPar
Jupyter Docker Stacks documentation. URL: \sphinxurl{https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[79]{backmatter/bibliography:id940}
\sphinxAtStartPar
Jonathan Underwood. Limapack. March 2021. URL: \sphinxurl{https://github.com/jonathanunderwood/limapack} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}10).
\bibitem[80]{backmatter/bibliography:id884}
\sphinxAtStartPar
Tamar Seideman. Time\sphinxhyphen{}resolved photoelectron angular distributions: concepts, applications, and directions. \sphinxstyleemphasis{Annual review of physical chemistry}, 53:41–65, January 2002. URL: \sphinxurl{http://www.ncbi.nlm.nih.gov/pubmed/11972002} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}17), \sphinxhref{https://arxiv.org/abs/11972002}{arXiv:11972002}, \sphinxhref{https://doi.org/10.1146/annurev.physchem.53.082101.130051}{doi:10.1146/annurev.physchem.53.082101.130051}.
\bibitem[81]{backmatter/bibliography:id883}
\sphinxAtStartPar
Tamar Seideman. Time\sphinxhyphen{}resolved photoelectron angular distributions as a probe of coupled polyatomic dynamics. \sphinxstyleemphasis{Physical Review A}, 64(4):042504, September 2001. URL: \sphinxurl{http://link.aps.org/doi/10.1103/PhysRevA.64.042504} (visited on 2013\sphinxhyphen{}03\sphinxhyphen{}14), \sphinxhref{https://doi.org/10.1103/PhysRevA.64.042504}{doi:10.1103/PhysRevA.64.042504}.
\bibitem[82]{backmatter/bibliography:id832}
\sphinxAtStartPar
Christopher Gerry and Peter Knight. \sphinxstyleemphasis{Introductory Quantum Optics}. Cambridge University Press, 2005. URL: \sphinxurl{https://doi.org/10.1017/CBO9780511791239}, \sphinxhref{https://doi.org/10.1017/CBO9780511791239}{doi:10.1017/CBO9780511791239}.
\bibitem[83]{backmatter/bibliography:id990}
\sphinxAtStartPar
Richard N Zare. \sphinxstyleemphasis{Angular Momentum: Understanding Spatial Aspects in Chemistry and Physics}. John Wiley \& Sons, 1988. ISBN 978\sphinxhyphen{}0\sphinxhyphen{}471\sphinxhyphen{}85892\sphinxhyphen{}8. URL: \sphinxurl{https://www.wiley.com/en-us/Angular+Momentum\%3A+Understanding+Spatial+Aspects+in+Chemistry+and+Physics-p-9780471858928}.
\bibitem[84]{backmatter/bibliography:id837}
\sphinxAtStartPar
Katharine L. Reid, David J. Leahy, and Richard N. Zare. Effect of breaking cylindrical symmetry on photoelectron angular distributions resulting from resonance\sphinxhyphen{}enhanced two\sphinxhyphen{}photon ionization. \sphinxstyleemphasis{The Journal of Chemical Physics}, 95(3):1746, 1991. URL: \sphinxurl{http://scitation.aip.org/content/aip/journal/jcp/95/3/10.1063/1.461023}, \sphinxhref{https://doi.org/10.1063/1.461023}{doi:10.1063/1.461023}.
\bibitem[85]{backmatter/bibliography:id974}
\sphinxAtStartPar
Guorong Wu, Paul Hockett, and Albert Stolow. Time\sphinxhyphen{}resolved photoelectron spectroscopy: from wavepackets to observables. \sphinxstyleemphasis{Physical chemistry chemical physics : PCCP}, 13(41):18447–67, November 2011. URL: \sphinxurl{http://pubs.rsc.org/en/content/articlelanding/2011/cp/c1cp22031d}, \sphinxhref{https://doi.org/10.1039/c1cp22031d}{doi:10.1039/c1cp22031d}.
\bibitem[86]{backmatter/bibliography:id512}
\sphinxAtStartPar
Yasuki Arasaki, Kazuo Takatsuka, Kwanghsi Wang, and Vincent McKoy. Probing wavepacket dynamics with femtosecond energy\sphinxhyphen{} and angle\sphinxhyphen{}resolved photoelectron spectroscopy. \sphinxstyleemphasis{Journal of Electron Spectroscopy and Related Phenomena}, 108(1\sphinxhyphen{}3):89–98, 2000. URL: \sphinxurl{http://www.sciencedirect.com/science/article/B6TGC-40T9H2X-B/2/ea056307101b30df942fc8387a61867d}, \sphinxhref{https://doi.org/DOI: 10.1016/S0368-2048(00)00148-1}{doi:DOI: 10.1016/S0368\sphinxhyphen{}2048(00)00148\sphinxhyphen{}1}.
\bibitem[87]{backmatter/bibliography:id910}
\sphinxAtStartPar
Toshinori Suzuki and Benjamin J. Whitaker. Non\sphinxhyphen{}adiabatic effects in chemistry revealed by time\sphinxhyphen{}resolved charged\sphinxhyphen{}particle imaging. \sphinxstyleemphasis{International Reviews in Physical Chemistry}, 20(3):313–356, July 2001. URL: \sphinxurl{http://www.tandfonline.com/doi/abs/10.1080/01442350110045046} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}17), \sphinxhref{https://doi.org/10.1080/01442350110045046}{doi:10.1080/01442350110045046}.
\bibitem[88]{backmatter/bibliography:id907}
\sphinxAtStartPar
Albert Stolow and Jonathan G. Underwood. Time\sphinxhyphen{}Resolved Photoelectron Spectroscopy of Non\sphinxhyphen{}Adiabatic Dynamics in Polyatomic Molecules. In Stuart A. Rice, editor, \sphinxstyleemphasis{Advances in Chemical Physics}, volume 139, pages 497–584. John Wiley \& Sons, Inc., Hoboken, NJ, USA, March 2008. URL: \sphinxurl{http://doi.wiley.com/10.1002/9780470259498} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}18), \sphinxhref{https://doi.org/10.1002/9780470259498.ch6}{doi:10.1002/9780470259498.ch6}.
\bibitem[89]{backmatter/bibliography:id548}
\sphinxAtStartPar
P R Bunker and P Jensen. \sphinxstyleemphasis{Molecular Symmetry and Spectroscopy}. NRC Research Press, Ottawa, 2nd edition, 1998. URL: \sphinxurl{https://cdnsciencepub.com/doi/book/10.1139/9780660196282}.
\bibitem[90]{backmatter/bibliography:id889}
\sphinxAtStartPar
R Signorell and F Merkt. General symmetry selection rules for the photoionization of polyatomic molecules. \sphinxstyleemphasis{Molecular Physics}, 92(5):793–804, 1997. \sphinxhref{https://doi.org/10.1080/002689797169745}{doi:10.1080/002689797169745}.
\bibitem[91]{backmatter/bibliography:id524}
\sphinxAtStartPar
Uwe Becker. Complete photoionisation experiments. \sphinxstyleemphasis{Journal of Electron Spectroscopy and Related Phenomena}, 96(1\sphinxhyphen{}3):105–115, November 1998. URL: \sphinxurl{http://linkinghub.elsevier.com/retrieve/pii/S0368204898002266} (visited on 2012\sphinxhyphen{}10\sphinxhyphen{}02), \sphinxhref{https://doi.org/10.1016/S0368-2048(98)00226-6}{doi:10.1016/S0368\sphinxhyphen{}2048(98)00226\sphinxhyphen{}6}.
\bibitem[92]{backmatter/bibliography:id842}
\sphinxAtStartPar
Katharine L Reid. Photoelectron angular distributions. \sphinxstyleemphasis{Annual review of physical chemistry}, 54(19):397–424, January 2003. URL: \sphinxurl{http://dx.doi.org/10.1146/annurev.physchem.54.011002.103814} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}17), \sphinxhref{https://doi.org/10.1146/annurev.physchem.54.011002.103814}{doi:10.1146/annurev.physchem.54.011002.103814}.
\bibitem[93]{backmatter/bibliography:id724}
\sphinxAtStartPar
H. Kleinpoppen, B. Lohmann, A. Grum\sphinxhyphen{}Grzhimailo, and U. Becker. Approaches to Perfect/Complete Scattering Experiments in Atomic and Molecular Physics. In H. H. Stroke, editor, \sphinxstyleemphasis{Advances In Atomic, Molecular, and Optical Physics}, volume 51, pages 471–534. Academic Press, January 2005. URL: \sphinxurl{https://www.sciencedirect.com/science/article/pii/S1049250X05510243} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}31), \sphinxhref{https://doi.org/10.1016/S1049-250X(05)51024-3}{doi:10.1016/S1049\sphinxhyphen{}250X(05)51024\sphinxhyphen{}3}.
\bibitem[94]{backmatter/bibliography:id725}
\sphinxAtStartPar
Hans Kleinpoppen, Bernd Lohmann, and Alexei N Grum\sphinxhyphen{}Grzhimailo. \sphinxstyleemphasis{Perfect/Complete Scattering Experiments}. Volume 75. Springer Berlin Heidelberg, Berlin, Heidelberg, 2013. ISBN 978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}40513\sphinxhyphen{}6. URL: \sphinxurl{https://link.springer.com/book/10.1007/978-3-642-40514-3}, \sphinxhref{https://doi.org/10.1007/978-3-642-40514-3}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}40514\sphinxhyphen{}3}.
\bibitem[95]{backmatter/bibliography:id841}
\sphinxAtStartPar
Katharine L. Reid and Jonathan G. Underwood. Extracting molecular axis alignment from photoelectron angular distributions. \sphinxstyleemphasis{The Journal of Chemical Physics}, 112(8):3643, 2000. URL: \sphinxurl{http://link.aip.org/link/JCPSA6/v112/i8/p3643/s1\&Agg=doi}, \sphinxhref{https://doi.org/10.1063/1.480517}{doi:10.1063/1.480517}.
\bibitem[96]{backmatter/bibliography:id937}
\sphinxAtStartPar
Jonathan G. Underwood and Katharine L. Reid. Time\sphinxhyphen{}resolved photoelectron angular distributions as a probe of intramolecular dynamics: Connecting the molecular frame and the laboratory frame. \sphinxstyleemphasis{The Journal of Chemical Physics}, 113(3):1067, 2000. URL: \sphinxurl{http://link.aip.org/link/JCPSA6/v113/i3/p1067/s1\&Agg=doi} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}17), \sphinxhref{https://doi.org/10.1063/1.481918}{doi:10.1063/1.481918}.
\bibitem[97]{backmatter/bibliography:id535}
\sphinxAtStartPar
Karl Blum. \sphinxstyleemphasis{Density Matrix Theory and Applications}. Number 64 in Springer Series on Atomic, Optical, and Plasma Physics. Springer Berlin Heidelberg, Berlin, Heidelberg, 3rd edition edition, 2012. ISBN 978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}20560\sphinxhyphen{}6. URL: \sphinxurl{http://link.springer.com/10.1007/978-3-642-20561-3}, \sphinxhref{https://doi.org/10.1007/978-3-642-20561-3}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}20561\sphinxhyphen{}3}.
\bibitem[98]{backmatter/bibliography:id636}
\sphinxAtStartPar
Margaret Gregory, Paul Hockett, Albert Stolow, and Varun Makhija. Towards molecular frame photoelectron angular distributions in polyatomic molecules from lab frame coherent rotational wavepacket evolution. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 54(14):145601, July 2021. URL: \sphinxurl{https://doi.org/10.1088/1361-6455/ac135f} (visited on 2021\sphinxhyphen{}08\sphinxhyphen{}17), \sphinxhref{https://arxiv.org/abs/2012.04561}{arXiv:2012.04561}, \sphinxhref{https://doi.org/10.1088/1361-6455/ac135f}{doi:10.1088/1361\sphinxhyphen{}6455/ac135f}.
\bibitem[99]{backmatter/bibliography:id663}
\sphinxAtStartPar
Paul Hockett, Matthias Wollenhaupt, Christian Lux, and Thomas Baumert. Complete photoionization experiments via ultrafast coherent control with polarization multiplexing. II. Numerics and analysis methodologies. \sphinxstyleemphasis{Physical Review A}, 92(1):013411, July 2015. URL: \sphinxurl{http://link.aps.org/doi/10.1103/PhysRevA.92.013411}, \sphinxhref{https://doi.org/10.1103/PhysRevA.92.013411}{doi:10.1103/PhysRevA.92.013411}.
\bibitem[100]{backmatter/bibliography:id637}
\sphinxAtStartPar
Margaret Gregory, Simon Neville, Michael Schuurman, and Varun Makhija. A laboratory frame density matrix for ultrafast quantum molecular dynamics. \sphinxstyleemphasis{The Journal of Chemical Physics}, 157(16):164301, October 2022. URL: \sphinxurl{https://aip.scitation.org/doi/10.1063/5.0109607} (visited on 2022\sphinxhyphen{}10\sphinxhyphen{}31), \sphinxhref{https://doi.org/10.1063/5.0109607}{doi:10.1063/5.0109607}.
\bibitem[101]{backmatter/bibliography:id782}
\sphinxAtStartPar
G. Mauro D'Ariano, Matteo G.A. Paris, and Massimiliano F. Sacchi. Quantum Tomography. In \sphinxstyleemphasis{Advances in Imaging and Electron Physics, Vol. 128}, pages 205–308. 2003. URL: \sphinxurl{http://linkinghub.elsevier.com/retrieve/pii/S1076567003800654} (visited on 2017\sphinxhyphen{}09\sphinxhyphen{}11), \sphinxhref{https://doi.org/10.1016/S1076-5670(03)80065-4}{doi:10.1016/S1076\sphinxhyphen{}5670(03)80065\sphinxhyphen{}4}.
\bibitem[102]{backmatter/bibliography:id922}
\sphinxAtStartPar
Malte C Tichy, Florian Mintert, and Andreas Buchleitner. Essential entanglement for atomic and molecular physics. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 44(19):192001, October 2011. URL: \sphinxurl{http://stacks.iop.org/0953-4075/44/i=19/a=192001?key=crossref.18d3f3352e48809821ebdd35c6d00cb6} (visited on 2014\sphinxhyphen{}08\sphinxhyphen{}19), \sphinxhref{https://doi.org/10.1088/0953-4075/44/19/192001}{doi:10.1088/0953\sphinxhyphen{}4075/44/19/192001}.
\bibitem[103]{backmatter/bibliography:id986}
\sphinxAtStartPar
Joel Yuen\sphinxhyphen{}Zhou, Jacob J Krich, Ivan Kassal, Allan S Johnson, and Alán Aspuru\sphinxhyphen{}Guzik. \sphinxstyleemphasis{Ultrafast Spectroscopy: Quantum Information and Wavepackets}. IOP Publishing, 2014. ISBN 978\sphinxhyphen{}0\sphinxhyphen{}7503\sphinxhyphen{}1062\sphinxhyphen{}8. URL: \sphinxurl{http://iopscience.iop.org/book/978-0-750-31062-8} (visited on 2017\sphinxhyphen{}09\sphinxhyphen{}25), \sphinxhref{https://doi.org/10.1088/978-0-750-31062-8}{doi:10.1088/978\sphinxhyphen{}0\sphinxhyphen{}750\sphinxhyphen{}31062\sphinxhyphen{}8}.
\bibitem[104]{backmatter/bibliography:id706}
\sphinxAtStartPar
J. R. Johansson, P. D. Nation, and Franco Nori. QuTiP: An open\sphinxhyphen{}source Python framework for the dynamics of open quantum systems. \sphinxstyleemphasis{Computer Physics Communications}, 183(8):1760–1772, August 2012. URL: \sphinxurl{https://www.sciencedirect.com/science/article/pii/S0010465512000835} (visited on 2023\sphinxhyphen{}02\sphinxhyphen{}25), \sphinxhref{https://doi.org/10.1016/j.cpc.2012.02.021}{doi:10.1016/j.cpc.2012.02.021}.
\bibitem[105]{backmatter/bibliography:id707}
\sphinxAtStartPar
J. R. Johansson, P. D. Nation, and Franco Nori. QuTiP 2: A Python framework for the dynamics of open quantum systems. \sphinxstyleemphasis{Computer Physics Communications}, 184(4):1234–1240, April 2013. URL: \sphinxurl{https://www.sciencedirect.com/science/article/pii/S0010465512003955} (visited on 2023\sphinxhyphen{}02\sphinxhyphen{}25), \sphinxhref{https://doi.org/10.1016/j.cpc.2012.11.019}{doi:10.1016/j.cpc.2012.11.019}.
\bibitem[106]{backmatter/bibliography:id833}
\sphinxAtStartPar
QuTiP \sphinxhyphen{} Quantum Toolbox in Python. URL: \sphinxurl{https://qutip.org/} (visited on 2023\sphinxhyphen{}02\sphinxhyphen{}25).
\bibitem[107]{backmatter/bibliography:id527}
\sphinxAtStartPar
Fabio Benatti, Mark Fannes, Roberto Floreanini, and Dimitri Petritis, editors. \sphinxstyleemphasis{Quantum Information, Computation and Cryptography: An Introductory Survey of Theory, Technology and Experiments}. Volume 808 of Lecture Notes in Physics. Springer, Berlin, Heidelberg, 2010. ISBN 978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}11913\sphinxhyphen{}2 978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}11914\sphinxhyphen{}9. URL: \sphinxurl{https://link.springer.com/10.1007/978-3-642-11914-9} (visited on 2023\sphinxhyphen{}02\sphinxhyphen{}25), \sphinxhref{https://doi.org/10.1007/978-3-642-11914-9}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}642\sphinxhyphen{}11914\sphinxhyphen{}9}.
\bibitem[108]{backmatter/bibliography:id807}
\sphinxAtStartPar
Michael A. Nielsen and Isaac L. Chuang. \sphinxstyleemphasis{Quantum Computation and Quantum Information: 10th Anniversary Edition}. Cambridge University Press, 2010. ISBN 978\sphinxhyphen{}0\sphinxhyphen{}511\sphinxhyphen{}97666\sphinxhyphen{}7. URL: \sphinxurl{https://www.cambridge.org/highereducation/books/quantum-computation-and-quantum-information/01E10196D0A682A6AEFFEA52D53BE9AE}, \sphinxhref{https://doi.org/10.1017/CBO9780511976667}{doi:10.1017/CBO9780511976667}.
\bibitem[109]{backmatter/bibliography:id903}
\sphinxAtStartPar
Henrik Stapelfeldt and Tamar Seideman. Colloquium: Aligning molecules with strong laser pulses. \sphinxstyleemphasis{Reviews of Modern Physics}, 75(2):543–557, April 2003. URL: \sphinxurl{http://rmp.aps.org/abstract/RMP/v75/i2/p543\_1} (visited on 2013\sphinxhyphen{}01\sphinxhyphen{}28), \sphinxhref{https://doi.org/10.1103/RevModPhys.75.543}{doi:10.1103/RevModPhys.75.543}.
\bibitem[110]{backmatter/bibliography:id645}
\sphinxAtStartPar
Hirokazu Hasegawa and Yasuhiro Ohshima. Nonadiabatic Molecular Alignment and Orientation. In Kaoru Yamanouchi, Luis Roso, Ruxin Li, Deepak Mathur, and Didier Normand, editors, \sphinxstyleemphasis{Progress in Ultrafast Intense Laser Science XII}, Springer Series in Chemical Physics, pages 45–64. Springer International Publishing, Cham, 2015. URL: \sphinxurl{https://doi.org/10.1007/978-3-319-23657-5\_3} (visited on 2022\sphinxhyphen{}08\sphinxhyphen{}26), \sphinxhref{https://doi.org/10.1007/978-3-319-23657-5\_3}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}319\sphinxhyphen{}23657\sphinxhyphen{}5\_3}.
\bibitem[111]{backmatter/bibliography:id728}
\sphinxAtStartPar
Christiane P Koch, Mikhail Lemeshko, and Dominique Sugny. Quantum control of molecular rotation. \sphinxstyleemphasis{Reviews of Modern Physics}, 91(3):035005, 2019. \sphinxhref{https://doi.org/10.1103/RevModPhys.91.035005}{doi:10.1103/RevModPhys.91.035005}.
\bibitem[112]{backmatter/bibliography:id1002}
\sphinxAtStartPar
Jens H Nielsen, Dominik Pentlehner, Lars Christiansen, Benjamin Shepperson, Anders A Søndergaard, Adam S Chatterley, James D Pickering, Constant A Schouder, Alberto Viñas Muñoz, Lorenz Kranabetter, and others. Laser\sphinxhyphen{}induced alignment of molecules in helium nanodroplets. In \sphinxstyleemphasis{Molecules in Superfluid Helium Nanodroplets: Spectroscopy, Structure, and Dynamics}, pages 381–445. Springer International Publishing Cham, 2022.
\bibitem[113]{backmatter/bibliography:id835}
\sphinxAtStartPar
S Ramakrishna and Tamar Seideman. On the information content of time\sphinxhyphen{} and angle\sphinxhyphen{}resolved photoelectron spectroscopy. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 45(19):194012, October 2012. URL: \sphinxurl{http://stacks.iop.org/0953-4075/45/i=19/a=194012?key=crossref.68faa78abc832ed11020afde085ac486} (visited on 2012\sphinxhyphen{}11\sphinxhyphen{}06), \sphinxhref{https://doi.org/10.1088/0953-4075/45/19/194012}{doi:10.1088/0953\sphinxhyphen{}4075/45/19/194012}.
\bibitem[114]{backmatter/bibliography:id836}
\sphinxAtStartPar
S. Ramakrishna and Tamar Seideman. Rotational wave\sphinxhyphen{}packet imaging of molecules. \sphinxstyleemphasis{Physical Review A}, 87(2):023411, February 2013. URL: \sphinxurl{http://link.aps.org/doi/10.1103/PhysRevA.87.023411} (visited on 2014\sphinxhyphen{}02\sphinxhyphen{}10), \sphinxhref{https://doi.org/10.1103/PhysRevA.87.023411}{doi:10.1103/PhysRevA.87.023411}.
\bibitem[115]{backmatter/bibliography:id664}
\sphinxAtStartPar
Paul Hockett. General phenomenology of ionization from aligned molecular ensembles. \sphinxstyleemphasis{New Journal of Physics}, 17(2):023069, February 2015. URL: \sphinxurl{http://dx.doi.org/10.1088/1367-2630/17/2/023069 http://stacks.iop.org/1367-2630/17/i=2/a=023069?key=crossref.bdbb6f53e1f801f11c6bfeca01330fde}, \sphinxhref{https://doi.org/10.1088/1367-2630/17/2/023069}{doi:10.1088/1367\sphinxhyphen{}2630/17/2/023069}.
\bibitem[116]{backmatter/bibliography:id772}
\sphinxAtStartPar
Varun Makhija. \sphinxstyleemphasis{Laser\sphinxhyphen{}Induced Rotational Dynamics As a Route To Molecular Frame Measurements}. PhD thesis, Kansas State University, 2014. URL: \sphinxurl{http://hdl.handle.net/2097/18522}.
\bibitem[117]{backmatter/bibliography:id980}
\sphinxAtStartPar
C. Yang. On the Angular Distribution in Nuclear Reactions and Coincidence Measurements. \sphinxstyleemphasis{Physical Review}, 74(7):764–772, October 1948. URL: \sphinxurl{http://link.aps.org/doi/10.1103/PhysRev.74.764} (visited on 2015\sphinxhyphen{}01\sphinxhyphen{}15), \sphinxhref{https://doi.org/10.1103/PhysRev.74.764}{doi:10.1103/PhysRev.74.764}.
\bibitem[118]{backmatter/bibliography:id582}
\sphinxAtStartPar
D Dill. Fixed\sphinxhyphen{}molecule photoelectron angular distributions. \sphinxstyleemphasis{The Journal of Chemical Physics}, 65(3):1130–1133, 1976. URL: \sphinxurl{http://scitation.aip.org/content/aip/journal/jcp/65/3/10.1063/1.433187} (visited on 2014\sphinxhyphen{}04\sphinxhyphen{}03), \sphinxhref{https://doi.org/10.1063/1.433187}{doi:10.1063/1.433187}.
\bibitem[119]{backmatter/bibliography:id508}
\sphinxAtStartPar
S. L. Altmann and C. J. Bradley. On the Symmetries of Spherical Harmonics. \sphinxstyleemphasis{Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences}, 255(1054):199–215, January 1963. URL: \sphinxurl{http://rsta.royalsocietypublishing.org/cgi/doi/10.1098/rsta.1963.0002} (visited on 2012\sphinxhyphen{}07\sphinxhyphen{}17), \sphinxhref{https://doi.org/10.1098/rsta.1963.0002}{doi:10.1098/rsta.1963.0002}.
\bibitem[120]{backmatter/bibliography:id509}
\sphinxAtStartPar
\textbackslash{}relax SL Altmann and \textbackslash{}relax AP Cracknell. Lattice harmonics I. Cubic groups. \sphinxstyleemphasis{Reviews of Modern Physics}, 37(1):19–32, 1965. URL: \sphinxurl{http://rmp.aps.org/abstract/RMP/v37/i1/p19\_1} (visited on 2013\sphinxhyphen{}06\sphinxhyphen{}12).
\bibitem[121]{backmatter/bibliography:id555}
\sphinxAtStartPar
N Chandra. Photoelectron spectroscopic studies of polyatomic molecules. I. Theory. \sphinxstyleemphasis{Journal of Physics B: Atomic and Molecular Physics}, 20(14):3405–3415, July 1987. URL: \sphinxurl{http://stacks.iop.org/0022-3700/20/i=14/a=013?key=crossref.84d7b9236af8a867d51605ee407558b9}, \sphinxhref{https://doi.org/10.1088/0022-3700/20/14/013}{doi:10.1088/0022\sphinxhyphen{}3700/20/14/013}.
\bibitem[122]{backmatter/bibliography:id839}
\sphinxAtStartPar
Katharine L. Reid and Ivan Powis. Symmetry considerations in molecular photoionization: Fixed molecule photoelectron angular distributions in C3v molecules as observed in photoelectron–photoion coincidence experiments. \sphinxstyleemphasis{The Journal of Chemical Physics}, 100(2):1066, 1994. URL: \sphinxurl{http://scitation.aip.org/content/aip/journal/jcp/100/2/10.1063/1.466638}, \sphinxhref{https://doi.org/10.1063/1.466638}{doi:10.1063/1.466638}.
\bibitem[123]{backmatter/bibliography:id963}
\sphinxAtStartPar
\textbackslash{}\textbackslash{}Spherical harmonics\textbackslash{}\textbackslash{}. Spherical harmonics. \sphinxstyleemphasis{Wikipedia}, June 2023. URL: \sphinxurl{https://en.wikipedia.org/w/index.php?title=Spherical\_harmonics\&oldid=1159615082} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}13).
\bibitem[124]{backmatter/bibliography:id870}
\sphinxAtStartPar
B Schmidtke, M Drescher, N a Cherepkov, and U Heinzmann. On the impossibility to perform a complete valence\sphinxhyphen{}shell photoionization experiment with closed\sphinxhyphen{}shell atoms. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 33(13):2451–2465, July 2000. URL: \sphinxurl{http://stacks.iop.org/0953-4075/33/i=13/a=306?key=crossref.ec62c50a4abb6a8ccb8209c7b3c89478}, \sphinxhref{https://doi.org/10.1088/0953-4075/33/13/306}{doi:10.1088/0953\sphinxhyphen{}4075/33/13/306}.
\bibitem[125]{backmatter/bibliography:id661}
\sphinxAtStartPar
P. Hockett, M. Wollenhaupt, C. Lux, and T. Baumert. Complete Photoionization Experiments via Ultrafast Coherent Control with Polarization Multiplexing. \sphinxstyleemphasis{Physical Review Letters}, 112(22):223001, June 2014. URL: \sphinxurl{http://link.aps.org/doi/10.1103/PhysRevLett.112.223001}, \sphinxhref{https://doi.org/10.1103/PhysRevLett.112.223001}{doi:10.1103/PhysRevLett.112.223001}.
\bibitem[126]{backmatter/bibliography:id662}
\sphinxAtStartPar
P Hockett, M Wollenhaupt, and T Baumert. Coherent control of photoelectron wavepacket angular interferograms. \sphinxstyleemphasis{Journal of Physics B: Atomic, Molecular and Optical Physics}, 48(21):214004, November 2015. URL: \sphinxurl{http://stacks.iop.org/0953-4075/48/i=21/a=214004?key=crossref.8f534585af9180a499934cb25c9994c1}, \sphinxhref{https://doi.org/10.1088/0953-4075/48/21/214004}{doi:10.1088/0953\sphinxhyphen{}4075/48/21/214004}.
\bibitem[127]{backmatter/bibliography:id929}
\sphinxAtStartPar
Rick Trebino. \sphinxstyleemphasis{Frequency\sphinxhyphen{}Resolved Optical Gating: The Measurement of Ultrashort Laser Pulses}. Springer New York, NY, 2000. ISBN 978\sphinxhyphen{}1\sphinxhyphen{}4613\sphinxhyphen{}5432\sphinxhyphen{}1. URL: \sphinxurl{https://link.springer.com/book/10.1007/978-1-4615-1181-6} (visited on 2022\sphinxhyphen{}05\sphinxhyphen{}02).
\bibitem[128]{backmatter/bibliography:id996}
\sphinxAtStartPar
Varun Makhija, Xiaoming Ren, Drue Gockel, Anh\sphinxhyphen{}Thu Le, and Vinod Kumarappan. Orientation resolution through rotational coherence spectroscopy. \sphinxstyleemphasis{arXiv preprint arXiv:1611.06476}, 2016.
\bibitem[129]{backmatter/bibliography:id995}
\sphinxAtStartPar
Xu Wang, Anh\sphinxhyphen{}Thu Le, Zhaoyan Zhou, Hui Wei, and CD Lin. Theory of retrieving orientation\sphinxhyphen{}resolved molecular information using time\sphinxhyphen{}domain rotational coherence spectroscopy. \sphinxstyleemphasis{Physical Review A}, 96(2):023424, 2017.
\bibitem[130]{backmatter/bibliography:id997}
\sphinxAtStartPar
Péter Sándor, Adonay Sissay, François Mauger, Paul M Abanador, Timothy T Gorman, Timothy D Scarborough, Mette B Gaarde, Kenneth Lopata, Kenneth J Schafer, and Robert R Jones. Angle dependence of strong\sphinxhyphen{}field single and double ionization of carbonyl sulfide. \sphinxstyleemphasis{Physical Review A}, 98(4):043425, 2018.
\bibitem[131]{backmatter/bibliography:id998}
\sphinxAtStartPar
Péter Sándor, Adonay Sissay, François Mauger, Mark W Gordon, TT Gorman, TD Scarborough, Mette B Gaarde, Kenneth Lopata, KJ Schafer, and RR Jones. Angle\sphinxhyphen{}dependent strong\sphinxhyphen{}field ionization of halomethanes. \sphinxstyleemphasis{The Journal of chemical physics}, 151(19):194308, 2019.
\bibitem[132]{backmatter/bibliography:id1001}
\sphinxAtStartPar
Tomthin Nganba Wangjam, Huynh Van Sa Lam, and Vinod Kumarappan. Strong\sphinxhyphen{}field ionization of the triplet ground state of o 2. \sphinxstyleemphasis{Physical Review A}, 104(4):043112, 2021.
\bibitem[133]{backmatter/bibliography:id1000}
\sphinxAtStartPar
Huynh Van Sa Lam, Suresh Yarlagadda, Anbu Venkatachalam, Tomthin Nganba Wangjam, Rajesh K Kushawaha, Chuan Cheng, Peter Svihra, Andrei Nomerotski, Thomas Weinacht, Daniel Rolles, and others. Angle\sphinxhyphen{}dependent strong\sphinxhyphen{}field ionization and fragmentation of carbon dioxide measured using rotational wave packets. \sphinxstyleemphasis{Physical Review A}, 102(4):043119, 2020.
\bibitem[134]{backmatter/bibliography:id999}
\sphinxAtStartPar
Huynh Van Sa Lam, Tomthin Nganba Wangjam, and Vinod Kumarappan. Alignment dependence of photoelectron angular distributions in the few\sphinxhyphen{}photon ionization of molecules by ultraviolet pulses. \sphinxstyleemphasis{Physical Review A}, 105(5):053109, 2022.
\bibitem[135]{backmatter/bibliography:id939}
\sphinxAtStartPar
Jonathan G. Underwood, I. Procino, L. Christiansen, J. Maurer, and H. Stapelfeldt. Velocity map imaging with non\sphinxhyphen{}uniform detection: Quantitative molecular axis alignment measurements via Coulomb explosion imaging. \sphinxstyleemphasis{Review of Scientific Instruments}, 86(7):073101, July 2015. URL: \sphinxurl{https://aip.scitation.org/doi/10.1063/1.4922137} (visited on 2022\sphinxhyphen{}09\sphinxhyphen{}08), \sphinxhref{https://arxiv.org/abs/1502.04007}{arXiv:1502.04007}, \sphinxhref{https://doi.org/10.1063/1.4922137}{doi:10.1063/1.4922137}.
\bibitem[136]{backmatter/bibliography:id646}
\sphinxAtStartPar
Lixin He, Pengfei Lan, Anh\sphinxhyphen{}Thu Le, Baoning Wang, Bincheng Wang, Xiaosong Zhu, Peixiang Lu, and C. D. Lin. Real\sphinxhyphen{}Time Observation of Molecular Spinning with Angular High\sphinxhyphen{}Harmonic Spectroscopy. \sphinxstyleemphasis{Physical Review Letters}, 121(16):163201, October 2018. URL: \sphinxurl{https://link.aps.org/doi/10.1103/PhysRevLett.121.163201} (visited on 2023\sphinxhyphen{}03\sphinxhyphen{}09), \sphinxhref{https://doi.org/10.1103/PhysRevLett.121.163201}{doi:10.1103/PhysRevLett.121.163201}.
\bibitem[137]{backmatter/bibliography:id647}
\sphinxAtStartPar
Yanqing He, Lixin He, Pu Wang, Bincheng Wang, Siqi Sun, Ruxuan Liu, Baoning Wang, Pengfei Lan, and Peixiang Lu. Measuring the rotational temperature and pump intensity in molecular alignment experiments via high harmonic generation. \sphinxstyleemphasis{Optics Express}, 28(14):21182–21191, July 2020. URL: \sphinxurl{https://opg.optica.org/oe/abstract.cfm?uri=oe-28-14-21182} (visited on 2023\sphinxhyphen{}03\sphinxhyphen{}09), \sphinxhref{https://doi.org/10.1364/OE.397560}{doi:10.1364/OE.397560}.
\bibitem[138]{backmatter/bibliography:id760}
\sphinxAtStartPar
V. Loriot, R. Tehini, E. Hertz, B. Lavorel, and O. Faucher. Snapshot imaging of postpulse transient molecular alignment revivals. \sphinxstyleemphasis{Physical Review A}, 78(1):013412, July 2008. URL: \sphinxurl{http://link.aps.org/doi/10.1103/PhysRevA.78.013412} (visited on 2013\sphinxhyphen{}02\sphinxhyphen{}27), \sphinxhref{https://doi.org/10.1103/PhysRevA.78.013412}{doi:10.1103/PhysRevA.78.013412}.
\bibitem[139]{backmatter/bibliography:id953}
\sphinxAtStartPar
Pu Wang, Lixin He, Yanqing He, Jianchang Hu, Siqi Sun, Pengfei Lan, and Peixiang Lu. Rotational echo spectroscopy for accurate measurement of molecular alignment. \sphinxstyleemphasis{Optics Letters}, 47(5):1033–1036, March 2022. URL: \sphinxurl{https://opg.optica.org/ol/abstract.cfm?uri=ol-47-5-1033} (visited on 2023\sphinxhyphen{}03\sphinxhyphen{}09), \sphinxhref{https://doi.org/10.1364/OL.451011}{doi:10.1364/OL.451011}.
\bibitem[140]{backmatter/bibliography:id515}
\sphinxAtStartPar
By P W Atkins, M S Child, and C S G Phillips. \sphinxstyleemphasis{Tables for Group Theory}. Oxford University Press, 2006. URL: \sphinxurl{https://global.oup.com/uk/orc/chemistry/qchem2e/student/tables/}.
\bibitem[141]{backmatter/bibliography:id625}
\sphinxAtStartPar
Achim Gelessus. Character tables for chemically important point groups. URL: \sphinxurl{http://symmetry.jacobs-university.de/} (visited on 2023\sphinxhyphen{}04\sphinxhyphen{}23).
\bibitem[142]{backmatter/bibliography:id718}
\sphinxAtStartPar
Gernot Katzer. Character Tables for Point Groups Cn, Cnv, Cnh, Dn, Dnh, Dnd, S2n etc. URL: \sphinxurl{http://www.gernot-katzers-spice-pages.com/character\_tables/index.html} (visited on 2023\sphinxhyphen{}04\sphinxhyphen{}23).
\bibitem[143]{backmatter/bibliography:id673}
\sphinxAtStartPar
Paul Hockett. Molecular Frame Reconstruction using Time\sphinxhyphen{}domain Photoionization Interferometry (Figshare). \sphinxstyleemphasis{Figshare}, May 2017. URL: \sphinxurl{https://doi.org/10.6084/m9.figshare.4480349} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}27), \sphinxhref{https://doi.org/10.6084/m9.figshare.4480349.v10}{doi:10.6084/m9.figshare.4480349.v10}.
\bibitem[144]{backmatter/bibliography:id972}
\sphinxAtStartPar
Jo Woodhose. OCS experimental work (personal communication, manuscript in preparation). 2022.
\bibitem[145]{backmatter/bibliography:id740}
\sphinxAtStartPar
L D Landau and E M Lifshitz. \sphinxstyleemphasis{Quantum Mechanics (Non\sphinxhyphen{}relativistic Theory)}. Pergamon Press, 3 edition, 1977.
\bibitem[146]{backmatter/bibliography:id789}
\sphinxAtStartPar
Albert Messiah. \sphinxstyleemphasis{Quantum Mechanics Volume I}. North\sphinxhyphen{}Holland Publishing Company, 1970.
\bibitem[147]{backmatter/bibliography:id868}
\sphinxAtStartPar
Jun John Sakurai. \sphinxstyleemphasis{Modern Quantum Mechanics}. Addison\sphinxhyphen{}Wesley, Reading, MA, revised edition edition, 1994. URL: \sphinxurl{https://cds.cern.ch/record/1167961}.
\bibitem[148]{backmatter/bibliography:id960}
\sphinxAtStartPar
\textbackslash{}\textbackslash{}Euler angles\textbackslash{}\textbackslash{}. Euler angles. \sphinxstyleemphasis{Wikipedia}, June 2023. URL: \sphinxurl{https://en.wikipedia.org/w/index.php?title=Euler\_angles\&oldid=1160186404} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}17).
\bibitem[149]{backmatter/bibliography:id964}
\sphinxAtStartPar
\textbackslash{}\textbackslash{}Wigner D\sphinxhyphen{}matrix\textbackslash{}\textbackslash{}. Wigner D\sphinxhyphen{}matrix. \sphinxstyleemphasis{Wikipedia}, June 2023. URL: \sphinxurl{https://en.wikipedia.org/w/index.php?title=Wigner\_D-matrix\&oldid=1160193091} (visited on 2023\sphinxhyphen{}07\sphinxhyphen{}17).
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}