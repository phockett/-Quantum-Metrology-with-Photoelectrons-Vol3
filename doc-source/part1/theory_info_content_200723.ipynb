{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21394f78-8862-4739-958d-d6498ba41c4a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Info content theory subsection.\n",
    "\n",
    "May ditch this unless it can be extended usefully? Should recon section be before this?\n",
    "\n",
    "- 22/11/22 Basics in place. Needs work.\n",
    "- For updates, see dev work http://jake:9966/lab/tree/code-share/jupyter-shared/PEMtk_dev_2022/basisSets/PEMtk_fitting_basis-set_demo_050621-full-revisit-Jake_040822.ipynb\n",
    "- 15/02/23 revisiting and expanding...\n",
    "- 20/07/23 revisiting\n",
    "    - NOT WORKING IN CURRENT BUILDS... getting null values for all BLMs?  Change in defaults/assumptions somewhere to fix.\n",
    "    - Added thres=None, but doesn't seem to fix.\n",
    "    - Results in fitting notebook (file:///mnt/jakeSSHFS/home/paul/buildTmp/2023-07-19_15-19-50/html-build/part2/sym-fitting-intro_220423.html) seem OK, so maybe issue with subselection or sym choice here? Could also be phase cons... TBC...\n",
    "    - 27/07/23: Now debugged. Issue was missing labels in (old-style) conversion to matrix elements. Now updated with full symmetry selection routines in 'scripts/setup_symmetry_basis_tensors.py'.\n",
    "    - 31/07/23: Tidied up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf98f8-f5fa-4c60-b4fd-8df2845f9cf5",
   "metadata": {},
   "source": [
    "(sec:info-content)= \n",
    "# Information content & sensitivity\n",
    "\n",
    "A useful tool in considering the possibility of matrix element retrieval is the response, or sensitivity, of the experimental observables to the matrix elements of interest. Aspects of this have already been explored in {numref}`Sect. %s <sec:tensor-formulation>`, where consideration of the various geometric tensors (or geometric basis set) provided a route to investigating the coupling - hence sensitivity - of various parameters into product terms. In particular the tensor products discussed in {numref}`Sect. %s <sec:theory:tensor-products>`, including the full channel (response) functions $\\varUpsilon_{L,M}^{u,\\zeta\\zeta'}$ ({eq}`eq:channelFunc-MF-defn` and {eq}`eq:channelFunc-AF-defn`), can be used to examine the overall sensitivity of a given measurement to the underlying observables. By careful consideration of the problem at hand, experiments may then be tailored for particular cases based on these sensitivities. A related question, is how a given experimental sensitivity might be more readily quantified, and interpreted, for reconstruction problems, in a simpler manner. In general, this can be termed as the _information content_ of the measurement(s); an important aspect of such a metric is that it should be readily interpretable and, ideally, related to whether a reconstruction will be possible in a given case (this has, for example, been considered by other authors for specific cases, e.g. Refs. {cite}`Schmidtke2000,Ramakrishna2012`).\n",
    "%, and ideally without too much theoretical study. \n",
    "Work in this direction is ongoing, and some thoughts are given below. In particular, the use of the observable $\\beta_{L,M}$ presents an experimental route to (roughly) define a form of information content, whilst metrics derived from channel functions or density matrices may present a more rigorous theoretical route to a useful parameterization of information content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f62e5-f1c9-427f-bf56-c3be9f20ad76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Numerical setup\n",
    "\n",
    "This follows the setup in {numref}`Sect. %s <sec:tensor-formulation>` {ref}`sec:tensor-formulation`, using a symmetry-based set of basis functions for demonstration purposes. (Repeated code is hidden in PDF version.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c95114-c6d4-409b-8c31-ebf3e14826f5",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Run default config - may need to set full path here\n",
    "%run '../scripts/setup_notebook.py'\n",
    "\n",
    "# Override plotters backend?\n",
    "# plotBackend = 'pl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b86c3a-a1a1-47c7-a6f0-dc9d346c2d49",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup symmetry-defined matrix elements using PEMtk\n",
    "\n",
    "%run '../scripts/setup_symmetry_basis_tensors.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f883cdb-8760-4d2a-a30c-181a3374d997",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# May need this in some build envs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b241fe28-e0fb-4d92-9731-fcac3687358c",
   "metadata": {
    "tags": []
   },
   "source": [
    "(sec:expt-info-content)=\n",
    "## Experimental information content\n",
    "\n",
    "As discussed in {{ QM2 }}, the information content of a single observable might be regarded as simply the number of contributing $\\beta_{L,M}$ parameters. In set notation:\n",
    "\n",
    "$$M=\\mathrm{n}\\{\\beta_{L,M}\\}$$ (eq:BLM-set)\n",
    "\n",
    "where $M$ is the information content of the measurement, defined as\n",
    "$\\mathrm{n}\\{...\\}$ the cardinality (number of elements) of the set of\n",
    "contributing parameters. A set of measurements, made for some\n",
    "experimental variable $u$, will then have a total information content:\n",
    "\n",
    "$$M_{u}=\\sum_{u}\\mathrm{n}\\{\\beta_{L,M}^{u}\\}$$\n",
    "\n",
    "In the case where a single measurement contains multiple $\\beta_{L,M}$,\n",
    "e.g. as a function of energy $\\epsilon$ or time $t$, the information\n",
    "content will naturally be larger:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "M_{u,\\epsilon,t} & = & \\sum_{u,\\epsilon,t}\\mathrm{n}\\{\\beta_{L,M}^{u}(\\epsilon,t)\\}\\\\\n",
    " & = & M_{u}\\times M_{\\epsilon,t}\\end{aligned}$$\n",
    "\n",
    "where the second line pertains if each measurement has the same native\n",
    "information content, independent of $u$. It may be that the variable $k$\n",
    "is continuous (e.g. photoelectron energy), but in practice it will\n",
    "usually be discretized in some fashion by the measurement.\n",
    "\n",
    "In terms of purely experimental methodologies, a larger $M_{u}$ clearly\n",
    "defines a richer experimental measurement which explores more of the\n",
    "total measurement space spanned by the full set of\n",
    "$\\{\\beta_{L,M}^{u}(k,t)\\}$. However, in this basic definition a larger\n",
    "$M_{u}$ does not necessarily indicate a higher information content for\n",
    "quantum retrieval applications. The reason for this is simply down to\n",
    "the complexity of the problem (cf. Eq. {eq}`eqn:channel-fns`), in which many couplings define the sensitivity of the observable to the underlying system properties of\n",
    "interest. In this sense, more measurements, and larger $M$, may only add\n",
    "redundancy, rather than new information.\n",
    "\n",
    "From a set of numerical results, it is relatively trivial to investigate some of these properties as a function of various constraints, using standard Python functionality, as shown in the code blocks below. For example, $M$ can be determined numerically as the number of elements in the dataset, the number of _unique_ elements, the number of elements within a certain range or above a threshold, and so on.\n",
    "\n",
    "% These make use of the demo cases (defined by symmetry) as previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6530b-a980-4512-81ec-788466672667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the basic case, the data (Xarray object) can be queried, \n",
    "# and relevant dimensions investigated\n",
    "\n",
    "print(f\"Available dimensions: {BetaNorm.dims}\")\n",
    "\n",
    "# Show BLM dimension details from Xarray dataset\n",
    "display(BetaNorm.BLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44118c7-9428-4248-9f10-1fd0b1def24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, however, that the indexes may not always be physical, \n",
    "# depending on how the data has been composed and cleaned up.\n",
    "# For example, the above has l=0, m=+/-1 cases, which are non-physical.\n",
    "\n",
    "# Clean array to remove terms |m|>l, and display\n",
    "cleanBLMs(BetaNorm).BLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17fae5c-441f-4af8-b961-6386d9600b9f",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Clean array to remove terms |m|>l, and display - Xarray native version\n",
    "# BetaNorm.BLM.where(np.abs(BetaNorm.BLM.m)<=BetaNorm.BLM.l,drop=True)\n",
    "# BetaNorm.where(np.abs(BetaNorm.m)<=BetaNorm.l,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81114b-d80a-4777-8fcd-28dfb5151764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding can also be used to reduce the results\n",
    "ep.matEleSelector(BetaNorm, thres=1e-4).BLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2434693-7419-4a83-9ffb-6c6a4376e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index can be returned as a Pandas object, and statistical routines applied...\n",
    "# For example, nunique() will provide the number of unique values.\n",
    "\n",
    "thres=1e-4\n",
    "\n",
    "print(f\"Original array M={BetaNorm.BLM.indexes['BLM'].nunique()}\")\n",
    "print(f\"Cleaned array M={cleanBLMs(BetaNorm).BLM.size}\")\n",
    "print(f\"Thresholded array (thres={thres}), \\\n",
    "      M={ep.matEleSelector(BetaNorm, thres=thres).BLM.indexes['BLM'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9c64e-fa3d-44f3-b15d-816945708c03",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# PD stats from multi-index... \n",
    "# Note this is not particularly useful for coords only\n",
    "BetaNorm.BLM.indexes['BLM'].to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ef0fc-e97d-43c5-b209-93b500cd7385",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert full dataset to PD dataframe and describe.\n",
    "BetaNormPD,_ = ep.util.multiDimXrToPD(BetaNorm.squeeze().real, thres=None, colDims='t', dropna=False)   #colDims={'BLM':['l','m']})  #, squeeze=True)\n",
    "BetaNormPD.describe().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca01fde-be6e-400a-87e3-7cce798402dd",
   "metadata": {},
   "source": [
    "For more complicated cases, with $u>1$, e.g. time-dependent measurements, interrogating the statistics of the observables may also be an interesting avenue to explore. The examples below investigate this for the example \"linear ramp\" {{ ADMs }} case. Here the statistical analysis is, potentially, a measure of the useful/non-redundant information content, for instance the range or variance in a particular observable can be analysed, as can the number of unique values and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e422e2-99bc-40e9-bc29-b8a2ae9567b3",
   "metadata": {
    "tags": [
     "hide-cell",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "BetaNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffff9e9-fe1a-4efc-9fe6-608b02bde9cb",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Compute AFBLMs - now in setup script\n",
    "# Note choice of phaseCons may affect results.\n",
    "# BetaNormLinearADMs, basisProductLinearADMs = data.afblmMatEfit(selDims={}, sqThres=False, phaseCons='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee1591-b0c0-479f-82f5-180c231635bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PD and tabulate with epsproc functionality\n",
    "# Note restack along 't' dimension\n",
    "BetaNormLinearADMsPD, _ = ep.util.multiDimXrToPD(BetaNormLinearADMs.squeeze().real, \n",
    "                                                 thres=1e-4, colDims='t')\n",
    "\n",
    "# Basic describe with Pandas, \n",
    "# see https://pandas.pydata.org/docs/user_guide/basics.html#summarizing-data-describe\n",
    "# This will give properties per t\n",
    "BetaNormLinearADMsPD.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c6027-5dac-4b7b-9f82-2bd74159468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic describe with Pandas, \n",
    "# see https://pandas.pydata.org/docs/user_guide/basics.html#summarizing-data-describe\n",
    "# By transposing the input array, this will give properties per BLM\n",
    "BetaNormLinearADMsPD.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4949b19b-0442-48bc-89ff-5359f97b60d8",
   "metadata": {},
   "source": [
    "For further insight and control, specific aggregation functions and criteria can be specified. For instance, it may be interesting to look at the number of unique values to a certain precision (e.g. depending on experimental uncertainties), or consider deviation of values from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab939e17-6e76-475f-88b4-4aa41249aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round values to 2 d.p., then apply statistical methods\n",
    "ndp = 2\n",
    "BetaNormLinearADMsPD.round(ndp).agg(['min','max','var','count','nunique']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31e688-ff70-4c2e-936f-f87ccc2840c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define demean function and apply (from https://stackoverflow.com/a/26110278)\n",
    "demean = lambda x: x - x.mean()\n",
    "\n",
    "# Compute differences from mean\n",
    "BetaNormLinearADMsPD.transform(demean,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c37eb6-4d1e-4daa-9b2d-5fe411d2e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply statistical functions to differences from mean.\n",
    "BetaNormLinearADMsPD.transform(demean,axis='columns'). \\\n",
    "        round(ndp).agg(['min','max','var','count','nunique']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72702a-edec-45c6-a047-8e1f1ec2eaf8",
   "metadata": {},
   "source": [
    "In this case the analysis suggests that $t=2 - 5$ contain minimal information (low variance), and $t=4,5$ potentially redundant information (low nunique), whilst $t=1,7 - 9$ show a greater total information content and number of unique values. However, this analysis is not necessarily absolutely definitive, since some nuances may be lost in this basic statistical analysis, particularly for weaker channels.\n",
    "\n",
    "For a more detailed analysis, other standard analysis tools can be deployed. For instance, the covariance matrix can be investigated, given by $K_{i,j}=\\textrm{cov}[X_{i},X_{j}]=\\langle(X_{i}-\\langle X_{i}\\rangle)(X_{j}-\\langle X_{j}\\rangle)\\rangle$. For the linear ramp case this analysis is not particularly useful, but will become more informative for more complicated cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8cf41-2c41-488b-87f7-6b2f37eb2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute covariance matrix with Pandas\n",
    "# Note this is the pairwise covariance of the columns, \n",
    "# see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cov.html\n",
    "covMat = BetaNormLinearADMsPD.cov()\n",
    "\n",
    "# Plot with holoviews\n",
    "figObj = covMat.hvplot.heatmap(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22998789-1fad-4b17-a5f2-cf303287dacf",
   "metadata": {
    "tags": [
     "hide-cell",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Glue figure\n",
    "glue(\"covMatBLMExample\", figObj)   #covMat.hvplot.heatmap(cmap='viridis'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4a676-41ee-46ac-a5d6-b22b9a36a8b8",
   "metadata": {},
   "source": [
    "```{glue:figure} covMatBLMExample\n",
    "---\n",
    "name: \"fig-covMatBLMExample\"\n",
    "---\n",
    "Example $\\beta_{L,M}(t)$ covariance matrix, see text for details.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b2f0d-0753-4ef6-880d-e1c5b8b5855b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Seaborn also has nice cluster plotting routines, which include sorting by similarity\n",
    "import seaborn as sns\n",
    "sns.clustermap(covMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510a68d-3256-40b2-af3b-061d5ce5748f",
   "metadata": {},
   "source": [
    "## Information content from channel functions\n",
    "\n",
    "A more complete accounting of information content would, therefore, also\n",
    "include the channel couplings, i.e. sensitivity/dependence of the\n",
    "observable to a given system property, in some manner. For the case of a\n",
    "time-dependent measurement, arising from a rotational wavepacket, this\n",
    "can be written as:\n",
    "\n",
    "$$M_{u}=\\mathrm{n}\\{\\varUpsilon_{L,M}^{u}(\\epsilon,t)\\}$$\n",
    "\n",
    "In this case, each $(\\epsilon,t)$ is treated as an independent\n",
    "measurement with unique information content, although there may be\n",
    "redundancy as a function of $t$ depending on the nature of the\n",
    "rotational wavepacket and channel functions.\n",
    "% - this is explored further in Sect. [\\[sec:bootstrapping-info-sensitivity\\]](#sec:bootstrapping-info-sensitivity){reference-type=\"ref\" reference=\"sec:bootstrapping-info-sensitivity\"}. \n",
    "(Note this is in\n",
    "distinction to previously demonstrated cases where the time-dependence\n",
    "was created from a shaped laser-field, and was integrated over in the\n",
    "measurements, which provided a coherently-multiplexed case, see refs.\n",
    "{cite}`hockett2014CompletePhotoionizationExperiments,hockett2015CompletePhotoionizationExperiments,hockett2015CoherentControlPhotoelectron` for details.)\n",
    "\n",
    "In the numerical examples below, this is considered in terms of the full channel (response) functions $\\varUpsilon_{L,M}^{u,\\zeta\\zeta'}$ as defined in {eq}`eq:channelFunc-MF-defn` and {eq}`eq:channelFunc-AF-defn` (see {numref}`Sect. %s <sec:theory:tensor-products>`). Numerically, the routines follow from those already introduced above for exploring the information content of $\\beta_{L,M}$ terms, with the caveat that there are more dimensions to handle in the channel functions, indexed by the relevant set of quantum numbers $\\{\\zeta,\\zeta'\\}$ - these can be included in the criteria for determination of $M$, or selected or summed over as desired.\n",
    "\n",
    "% Numerical example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcff632-28e9-4df9-914e-fe4eded3ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of channel functions to test\n",
    "channelFuncs = (basisProductLinearADMs['BLMtableResort'] * basisProductLinearADMs['polProd'])\n",
    "\n",
    "# For illustrative purposes, define a subset to use for analysis\n",
    "channelFuncsSubset = channelFuncs.sel(Labels='A').sel({'S-Rp':0,'mu':0,'mup':0})  #.sel(L=2)\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"Available dimensions: {channelFuncs.dims}\")\n",
    "print(f\"Subset dimensions: {channelFuncsSubset.dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66297c38-d096-4648-bff8-e7a3782e5480",
   "metadata": {
    "tags": []
   },
   "source": [
    "````{margin}\n",
    "```{note}\n",
    "Full tabulations of the parameters available in HTML or notebook formats only.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd33337-a080-49fe-bf08-68e16cc49b35",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert to PD and tabulate with epsproc functionality\n",
    "# Note restack along 't' dimension\n",
    "channelFuncsSubsetPD, _ = ep.util.multiDimXrToPD(channelFuncsSubset.squeeze().real, \n",
    "                                                 thres=1e-4, colDims='t')\n",
    "\n",
    "# Round values to 1 d.p., then apply statistical methods\n",
    "# Compute per basis index and display\n",
    "channelFuncsSubsetPD.T.round(2).agg(['min','max','var','count','nunique']).T  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69dac50-7b0c-4c70-a67c-7245a0ebb515",
   "metadata": {},
   "source": [
    "For the higher-dimensional case, it is useful to plot terms relative to all quantum numbers. For example, in a similar manner to the basis set explorations of {numref}`Sect. %s <sec:theory:tensor-products>`, related properties such as the distance from the mean can be examined with `lmPlot()`. And, as previously demonstrated, other properties, such as the covariance, may be examined and plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f02718-22b2-4570-898c-e2c184edf444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channelFuncsSubsetPD.transform(demean,axis='columns') \n",
    "# cmap=None   # cmap = None for default. 'vlag' good?\n",
    "# cmap = 'vlag'\n",
    "\n",
    "# De-meaned channel functions\n",
    "channelFuncsDemean = channelFuncsSubsetPD.transform(demean,axis='columns')\n",
    "\n",
    "# Plot using lmPlot routine - note this requires conversion to Xarray data type first.\n",
    "daPlot, daPlotpd, legendList, gFig =  ep.lmPlot(channelFuncsDemean.to_xarray().to_array('t')\n",
    "                                                , xDim='t', cmap=cmap, mDimLabel='m'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a609fe2-ec5f-4969-848f-3108d8950017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full covariance mapping along all dims\n",
    "%matplotlib inline\n",
    "sns.clustermap(channelFuncsSubsetPD.T.cov().fillna(0))  #.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76f1dc-ae03-411a-862f-937d37ab1bbc",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c752c8a-25a3-4688-90a7-74f4bf963697",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "channelFuncsSubsetPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba89597-b8e2-48dc-aded-2eac80512c5e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "channelFuncsSubsetPD.transform(demean,axis='columns').to_xarray().to_array('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9230ea8-6bcc-4ad2-9b88-363ca8ee2b95",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Information content from density matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1e06c-0c35-44f7-a4c2-04acd2f0094b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
